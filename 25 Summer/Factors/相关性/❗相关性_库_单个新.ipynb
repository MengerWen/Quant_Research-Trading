{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ff1c643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/public/src')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "from factor_evaluation_server import FactorEvaluation, DataService\n",
    "ds = DataService()\n",
    "df = ds['ETHUSDT_15m_2020_2025']['2021-10-01':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03219a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FilterCorrelationAnalyzer:\n",
    "    def __init__(self, factor_data_path, start_date='2021-10-01'):\n",
    "        self.factor_data_path = factor_data_path\n",
    "        self.start_date = start_date\n",
    "        self.factor_data = None\n",
    "        self.filter_values = {}\n",
    "        self.correlation_results = None\n",
    "        \n",
    "    def load_factor_data(self):\n",
    "        \"\"\"加载因子库数据\"\"\"\n",
    "        print(f\"Loading factor data from {self.factor_data_path}...\")\n",
    "        # 因子库数据是txt格式，包含日期索引\n",
    "        self.factor_data = pd.read_table(\n",
    "            self.factor_data_path, \n",
    "            sep='|'\n",
    "        )\n",
    "        # 筛选起始日期\n",
    "        self.factor_data = self.factor_data.loc[self.start_date:]\n",
    "        print(f\"Loaded {len(self.factor_data.columns)} factors with {len(self.factor_data)} records\")\n",
    "        \n",
    "    def calculate_filters(self, df):\n",
    "        \"\"\"计算所有filter的值\"\"\"\n",
    "        print(\"Calculating filter values...\")\n",
    "        \n",
    "        # 定义所有filter函数\n",
    "        def filter_001_1(df):\n",
    "            log_ratio = np.log(df['close'] / df['close'].shift(1))\n",
    "            return log_ratio.rolling(20).std()\n",
    "        \n",
    "        def filter_001_2(df):\n",
    "            high_low = df['high'] - df['low']\n",
    "            high_close = abs(df['high'] - df['close'].shift(1))\n",
    "            low_close = abs(df['low'] - df['close'].shift(1))\n",
    "            true_range = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)\n",
    "            return true_range.rolling(14).mean()\n",
    "        \n",
    "        def filter_001_3_keltner_channels(df, ema_period=20, atr_period=10, multiplier=2):\n",
    "            ema = df['close'].ewm(span=ema_period, adjust=False).mean()\n",
    "            high_low = df['high'] - df['low']\n",
    "            high_close = abs(df['high'] - df['close'].shift(1))\n",
    "            low_close = abs(df['low'] - df['close'].shift(1))\n",
    "            true_range = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)\n",
    "            atr = true_range.ewm(span=atr_period, adjust=False).mean()\n",
    "            channel_width = multiplier * atr\n",
    "            return (df['close'] - (ema - channel_width)) / (2 * channel_width)\n",
    "        \n",
    "        def filter_002_1(df):\n",
    "            volume_mean = df['volume'].rolling(20).mean()\n",
    "            return (df['volume'] - volume_mean) / volume_mean\n",
    "        \n",
    "        def filter_002_2_obv(df):\n",
    "            obv = (np.sign(df['close'].diff()) * df['volume'])\n",
    "            return obv.cumsum()\n",
    "        \n",
    "        def filter_002_3_vwap(df):\n",
    "            typical_price = (df['high'] + df['low'] + df['close']) / 3\n",
    "            vwap = (typical_price * df['volume']).cumsum() / df['volume'].cumsum()\n",
    "            return vwap\n",
    "        \n",
    "        def filter_003(df):\n",
    "            up = df['high'].rolling(20).max()\n",
    "            down = df['low'].rolling(20).min()\n",
    "            return (df['close'] - down) / (up - down)\n",
    "        \n",
    "        def filter_004(df):\n",
    "            std_5 = df['close'].rolling(5).std()\n",
    "            std_30 = df['close'].rolling(30).std()\n",
    "            return std_5 / std_30\n",
    "        \n",
    "        def filter_005(df):\n",
    "            return 2 * df['taker_buy_volume'] / df['volume'] - 1\n",
    "        \n",
    "        def filter_006(df):\n",
    "            return df['volume'] / df['trade_count']\n",
    "        \n",
    "        def filter_007(df):\n",
    "            body = abs(df['close'] - df['open'])\n",
    "            range_ = df['high'] - df['low']\n",
    "            return body / range_\n",
    "        \n",
    "        def filter_008(df):\n",
    "            upper_wick = df['high'] - df[['open', 'close']].max(axis=1)\n",
    "            range_ = df['high'] - df['low']\n",
    "            return upper_wick / range_\n",
    "        \n",
    "        def filter_009(df):\n",
    "            lower_wick = df[['open', 'close']].min(axis=1) - df['low']\n",
    "            range_ = df['high'] - df['low']\n",
    "            return lower_wick / range_\n",
    "        \n",
    "        def filter_010_1(df, period=14):\n",
    "            delta = df['close'].diff()\n",
    "            gain = delta.where(delta > 0, 0)\n",
    "            loss = -delta.where(delta < 0, 0)\n",
    "            avg_gain = gain.ewm(alpha=1/period, adjust=False).mean()\n",
    "            avg_loss = loss.ewm(alpha=1/period, adjust=False).mean()\n",
    "            rs = avg_gain / avg_loss.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "            return 100 - (100 / (1 + rs))\n",
    "        \n",
    "        def filter_010_2_mfi(df, period=14):\n",
    "            typical_price = (df['high'] + df['low'] + df['close']) / 3\n",
    "            raw_money_flow = typical_price * df['volume']\n",
    "            money_flow_direction = np.where(typical_price > typical_price.shift(1), 1, -1)\n",
    "            positive_flow = raw_money_flow.where(money_flow_direction > 0, 0)\n",
    "            negative_flow = raw_money_flow.where(money_flow_direction < 0, 0)\n",
    "            money_ratio = positive_flow.rolling(period).sum() / negative_flow.rolling(period).sum()\n",
    "            money_ratio = money_ratio.replace([np.inf, -np.inf], np.nan).fillna(1)\n",
    "            return 100 - (100 / (1 + money_ratio))\n",
    "        \n",
    "        def filter_011(df, short_period=12, long_period=26):\n",
    "            short_ema = df['close'].ewm(span=short_period, adjust=False).mean()\n",
    "            long_ema = df['close'].ewm(span=long_period, adjust=False).mean()\n",
    "            return short_ema - long_ema\n",
    "        \n",
    "        def filter_012_aroon_up(df, period=14):\n",
    "            high_idx = df['high'].rolling(period).apply(lambda x: x.argmax(), raw=True)\n",
    "            return 100 * (period - high_idx) / period\n",
    "        \n",
    "        def filter_013_aroon_down(df, period=14):\n",
    "            low_idx = df['low'].rolling(period).apply(lambda x: x.argmin(), raw=True)\n",
    "            return 100 * (period - low_idx) / period\n",
    "        \n",
    "        def filter_014_aroon_oscillator(df, period=14):\n",
    "            aroon_up = filter_012_aroon_up(df, period)\n",
    "            aroon_down = filter_013_aroon_down(df, period)\n",
    "            return aroon_up - aroon_down\n",
    "        \n",
    "        def filter_015_chaikin_money_flow(df, period=20):\n",
    "            money_flow_multiplier = ((df['close'] - df['low']) - (df['high'] - df['close'])) / (df['high'] - df['low'])\n",
    "            money_flow_multiplier = money_flow_multiplier.replace([np.inf, -np.inf], 0).fillna(0)\n",
    "            money_flow_volume = money_flow_multiplier * df['volume']\n",
    "            return money_flow_volume.rolling(period).sum() / df['volume'].rolling(period).sum()\n",
    "        \n",
    "        def filter_020_volume_price_trend(df):\n",
    "            price_change = df['close'].pct_change()\n",
    "            return (price_change * df['volume']).cumsum()\n",
    "        \n",
    "        # 计算所有filter的值\n",
    "        filters = {\n",
    "            'filter_001_1': filter_001_1,\n",
    "            'filter_001_2': filter_001_2,\n",
    "            'filter_001_3': lambda d: filter_001_3_keltner_channels(d),\n",
    "            'filter_002_1': filter_002_1,\n",
    "            'filter_002_2': filter_002_2_obv,\n",
    "            'filter_002_3': filter_002_3_vwap,\n",
    "            'filter_003': filter_003,\n",
    "            'filter_004': filter_004,\n",
    "            'filter_005': filter_005,\n",
    "            'filter_006': filter_006,\n",
    "            'filter_007': filter_007,\n",
    "            'filter_008': filter_008,\n",
    "            'filter_009': filter_009,\n",
    "            'filter_010_1': lambda d: filter_010_1(d, 14),\n",
    "            'filter_010_2': lambda d: filter_010_2_mfi(d, 14),\n",
    "            'filter_011': lambda d: filter_011(d, 12, 26),\n",
    "            'filter_012': lambda d: filter_012_aroon_up(d, 14),\n",
    "            'filter_013': lambda d: filter_013_aroon_down(d, 14),\n",
    "            'filter_014': lambda d: filter_014_aroon_oscillator(d, 14),\n",
    "            'filter_015': lambda d: filter_015_chaikin_money_flow(d, 20),\n",
    "            'filter_020': filter_020_volume_price_trend\n",
    "        }\n",
    "        \n",
    "        for name, func in tqdm(filters.items()):\n",
    "            try:\n",
    "                self.filter_values[name] = func(df)\n",
    "            except Exception as e:\n",
    "                print(f\"Error calculating {name}: {str(e)}\")\n",
    "                self.filter_values[name] = pd.Series(np.nan, index=df.index)\n",
    "        \n",
    "        print(\"Filter calculation completed.\")\n",
    "    \n",
    "\n",
    "    def calculate_correlations(self):\n",
    "        \"\"\"计算每个filter与因子库中所有因子的相关性\"\"\"\n",
    "        if self.factor_data is None:\n",
    "            raise ValueError(\"Factor data not loaded. Call load_factor_data() first.\")\n",
    "        \n",
    "        if not self.filter_values:\n",
    "            raise ValueError(\"Filter values not calculated. Call calculate_filters() first.\")\n",
    "        \n",
    "        print(\"Calculating correlations...\")\n",
    "        # 创建结果DataFrame\n",
    "        results = []\n",
    "        \n",
    "        # 转换filter值为DataFrame并与因子库数据对齐\n",
    "        filter_df = pd.DataFrame(self.filter_values)\n",
    "        aligned_data = pd.merge(\n",
    "            self.factor_data, \n",
    "            filter_df, \n",
    "            left_index=True, \n",
    "            right_index=True,\n",
    "            how='inner'\n",
    "        )\n",
    "        \n",
    "        # 分离因子和filter列\n",
    "        factor_cols = self.factor_data.columns\n",
    "        filter_cols = list(self.filter_values.keys())\n",
    "        \n",
    "        # 计算所有filter与所有因子的相关性\n",
    "        for filter_col in tqdm(filter_cols):\n",
    "            for factor_col in factor_cols:\n",
    "                # 移除NaN值\n",
    "                valid_data = aligned_data[[filter_col, factor_col]].dropna()\n",
    "                if len(valid_data) < 10:  # 至少需要10个有效点\n",
    "                    continue\n",
    "                \n",
    "                series1 = valid_data[filter_col]\n",
    "                series2 = valid_data[factor_col]\n",
    "                \n",
    "                # 计算Pearson相关系数\n",
    "                try:\n",
    "                    corr, p_value = pearsonr(series1, series2)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error calculating correlation between {filter_col} and {factor_col}: {str(e)}\")\n",
    "                    continue\n",
    "                \n",
    "                results.append({\n",
    "                    'filter': filter_col,\n",
    "                    'factor': factor_col,\n",
    "                    'correlation': corr,\n",
    "                    'abs_correlation': abs(corr),\n",
    "                    'p_value': p_value\n",
    "                })\n",
    "        \n",
    "        # 确保即使没有结果也创建包含必要列的DataFrame\n",
    "        if results:\n",
    "            self.correlation_results = pd.DataFrame(results)\n",
    "        else:\n",
    "            # 创建空DataFrame但包含所需列\n",
    "            self.correlation_results = pd.DataFrame(columns=[\n",
    "                'filter', 'factor', 'correlation', 'abs_correlation', 'p_value'\n",
    "            ])\n",
    "        \n",
    "        print(f\"Calculated {len(self.correlation_results)} correlations.\")\n",
    "    \n",
    "    def analyze_correlations(self, threshold=0.7):\n",
    "        \"\"\"分析相关性结果并展示高相关性对\"\"\"\n",
    "        if self.correlation_results is None:\n",
    "            raise ValueError(\"Correlations not calculated. Call calculate_correlations() first.\")\n",
    "        \n",
    "        # 检查DataFrame是否为空或缺少必要列\n",
    "        if self.correlation_results.empty or 'abs_correlation' not in self.correlation_results.columns:\n",
    "            print(\"Warning: No correlation results available or required columns missing.\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # 筛选显著相关性\n",
    "        significant_corrs = self.correlation_results[\n",
    "            (self.correlation_results['abs_correlation'] > threshold) & \n",
    "            (self.correlation_results['p_value'] < 0.05)\n",
    "        ]\n",
    "        \n",
    "        # 按绝对值相关性排序\n",
    "        significant_corrs = significant_corrs.sort_values(\n",
    "            'abs_correlation', \n",
    "            ascending=False\n",
    "        )\n",
    "        \n",
    "        # 输出结果\n",
    "        print(f\"\\nFound {len(significant_corrs)} significant correlations (> {threshold}):\")\n",
    "        if not significant_corrs.empty:\n",
    "            print(significant_corrs[['filter', 'factor', 'correlation', 'p_value']])\n",
    "        else:\n",
    "            print(\"No significant correlations found.\")\n",
    "        \n",
    "        # 可视化高相关性对（仅当有结果时）\n",
    "        if not significant_corrs.empty:\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            sns.barplot(\n",
    "                x='abs_correlation',\n",
    "                y='filter',\n",
    "                hue='factor',\n",
    "                data=significant_corrs,\n",
    "                dodge=False\n",
    "            )\n",
    "            plt.title(f'Filter-Factor Correlations > {threshold}')\n",
    "            plt.xlabel('Absolute Correlation')\n",
    "            plt.ylabel('Filter')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        \n",
    "        # 返回分析结果\n",
    "        return significant_corrs\n",
    "    \n",
    "    def get_unique_filters(self, threshold=0.7):\n",
    "        \"\"\"识别独特filter（与所有因子相关性均低于阈值）\"\"\"\n",
    "        if self.correlation_results is None:\n",
    "            raise ValueError(\"Correlations not calculated. Call calculate_correlations() first.\")\n",
    "        \n",
    "        # 检查DataFrame是否为空或缺少必要列\n",
    "        if self.correlation_results.empty or 'abs_correlation' not in self.correlation_results.columns:\n",
    "            print(\"Warning: No correlation results available or required columns missing.\")\n",
    "            return []\n",
    "        \n",
    "        # 找出与任何因子的最大相关性低于阈值的filter\n",
    "        max_corrs = self.correlation_results.groupby('filter')['abs_correlation'].max()\n",
    "        unique_filters = max_corrs[max_corrs < threshold].index.tolist()\n",
    "        \n",
    "        print(f\"\\nUnique filters (max correlation < {threshold}):\")\n",
    "        for filter_name in unique_filters:\n",
    "            print(f\"- {filter_name}\")\n",
    "        \n",
    "        return unique_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99a2d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading factor data from /public/data/factor_data/ETH_15m_factor_data.txt...\n",
      "Loaded 143 factors with 172211 records\n",
      "Calculating filter values...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:00<00:00, 56.70it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter calculation completed.\n",
      "Calculating correlations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:01<00:00, 12.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated 0 correlations.\n",
      "Warning: No correlation results available or required columns missing.\n",
      "Warning: No correlation results available or required columns missing.\n",
      "\n",
      "Analysis completed. High correlation results saved to 'high_correlation_results.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 主程序\n",
    "if __name__ == \"__main__\":\n",
    "    # 配置路径和参数  \n",
    "    FACTOR_DATA_PATH = \"/public/data/factor_data/ETH_15m_factor_data.txt\"\n",
    "    START_DATE = \"2021-10-01\"\n",
    "    \n",
    "    # 初始化分析器\n",
    "    analyzer = FilterCorrelationAnalyzer(\n",
    "        factor_data_path=FACTOR_DATA_PATH,\n",
    "        start_date=START_DATE\n",
    "    )\n",
    "    \n",
    "    # 加载因子库数据\n",
    "    analyzer.load_factor_data()  \n",
    "    \n",
    "    \n",
    "    # 计算所有filter的值\n",
    "    analyzer.calculate_filters(df)\n",
    "    \n",
    "    # 计算相关性\n",
    "    analyzer.calculate_correlations()\n",
    "    \n",
    "    # 分析结果\n",
    "    high_corrs = analyzer.analyze_correlations(threshold=0.75)\n",
    "    unique_filters = analyzer.get_unique_filters(threshold=0.75)\n",
    "    \n",
    "    # 保存完整结果\n",
    "    # high_corrs.to_csv(\"high_correlation_results.csv\", index=False)\n",
    "    print(\"\\nAnalysis completed. High correlation results saved to 'high_correlation_results.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a7ef059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ret_stc_sig_price</th>\n",
       "      <th>ret_hv_ratio_signals</th>\n",
       "      <th>ret_td_signals</th>\n",
       "      <th>ret_ao_signals</th>\n",
       "      <th>ret_ena_signals</th>\n",
       "      <th>ret_williams_r_sig_price</th>\n",
       "      <th>ret_momentum_sig_price</th>\n",
       "      <th>ret_kc_strategy</th>\n",
       "      <th>ret_bollinger_rsi_signals</th>\n",
       "      <th>ret_macd_sig_price</th>\n",
       "      <th>...</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>close_time</th>\n",
       "      <th>turnover</th>\n",
       "      <th>trade_count</th>\n",
       "      <th>taker_buy_volume</th>\n",
       "      <th>taker_buy_turnover</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>129.6100</td>\n",
       "      <td>130.4300</td>\n",
       "      <td>129.0600</td>\n",
       "      <td>129.8100</td>\n",
       "      <td>18266.6000</td>\n",
       "      <td>1577808899999.0000</td>\n",
       "      <td>2374874.9534</td>\n",
       "      <td>1869.0000</td>\n",
       "      <td>8467.1470</td>\n",
       "      <td>1101015.1909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>129.7800</td>\n",
       "      <td>130.2700</td>\n",
       "      <td>129.5400</td>\n",
       "      <td>130.1200</td>\n",
       "      <td>9695.0020</td>\n",
       "      <td>1577809799999.0000</td>\n",
       "      <td>1260624.8251</td>\n",
       "      <td>803.0000</td>\n",
       "      <td>4873.9130</td>\n",
       "      <td>633747.8921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>130.1400</td>\n",
       "      <td>130.5100</td>\n",
       "      <td>130.0000</td>\n",
       "      <td>130.1600</td>\n",
       "      <td>9009.6350</td>\n",
       "      <td>1577810699999.0000</td>\n",
       "      <td>1172856.8646</td>\n",
       "      <td>631.0000</td>\n",
       "      <td>5035.0210</td>\n",
       "      <td>655487.1082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>130.1500</td>\n",
       "      <td>130.2100</td>\n",
       "      <td>130.0000</td>\n",
       "      <td>130.0100</td>\n",
       "      <td>4364.3280</td>\n",
       "      <td>1577811599999.0000</td>\n",
       "      <td>567846.1685</td>\n",
       "      <td>312.0000</td>\n",
       "      <td>2080.3990</td>\n",
       "      <td>270696.7570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>130.0100</td>\n",
       "      <td>130.0100</td>\n",
       "      <td>129.6900</td>\n",
       "      <td>129.8200</td>\n",
       "      <td>5641.9870</td>\n",
       "      <td>1577812499999.0000</td>\n",
       "      <td>732630.8254</td>\n",
       "      <td>392.0000</td>\n",
       "      <td>2276.5170</td>\n",
       "      <td>295624.2402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 143 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ret_stc_sig_price  ret_hv_ratio_signals  ret_td_signals  ret_ao_signals  \\\n",
       "0                  0                     0               0               0   \n",
       "1                  0                     0               0               0   \n",
       "2                  0                     0               0               0   \n",
       "3                  0                     0               0               0   \n",
       "4                  0                     0               0               0   \n",
       "\n",
       "   ret_ena_signals  ret_williams_r_sig_price  ret_momentum_sig_price  \\\n",
       "0                0                         0                       0   \n",
       "1                0                         0                       0   \n",
       "2                0                         0                       0   \n",
       "3                0                         0                       0   \n",
       "4                0                         0                       0   \n",
       "\n",
       "   ret_kc_strategy  ret_bollinger_rsi_signals  ret_macd_sig_price  ...  \\\n",
       "0                0                          0                   0  ...   \n",
       "1                0                          0                   0  ...   \n",
       "2                0                          0                   0  ...   \n",
       "3                0                          0                   0  ...   \n",
       "4                0                          0                   0  ...   \n",
       "\n",
       "      open     high      low    close     volume         close_time  \\\n",
       "0 129.6100 130.4300 129.0600 129.8100 18266.6000 1577808899999.0000   \n",
       "1 129.7800 130.2700 129.5400 130.1200  9695.0020 1577809799999.0000   \n",
       "2 130.1400 130.5100 130.0000 130.1600  9009.6350 1577810699999.0000   \n",
       "3 130.1500 130.2100 130.0000 130.0100  4364.3280 1577811599999.0000   \n",
       "4 130.0100 130.0100 129.6900 129.8200  5641.9870 1577812499999.0000   \n",
       "\n",
       "      turnover  trade_count  taker_buy_volume  taker_buy_turnover  \n",
       "0 2374874.9534    1869.0000         8467.1470        1101015.1909  \n",
       "1 1260624.8251     803.0000         4873.9130         633747.8921  \n",
       "2 1172856.8646     631.0000         5035.0210         655487.1082  \n",
       "3  567846.1685     312.0000         2080.3990         270696.7570  \n",
       "4  732630.8254     392.0000         2276.5170         295624.2402  \n",
       "\n",
       "[5 rows x 143 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path=\"/public/data/factor_data/ETH_15m_factor_data.txt\"\n",
    "factors=pd.read_csv(path, sep='|')\n",
    "factors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "16773df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ret_hv_ratio_signals\n",
      "ret_td_signals\n",
      "ret_ao_signals\n",
      "ret_ena_signals\n",
      "ret_williams_r_sig_price\n",
      "ret_momentum_sig_price\n",
      "ret_kc_strategy\n",
      "ret_bollinger_rsi_signals\n",
      "ret_macd_sig_price\n",
      "ret_ma_arrangement_sig\n",
      "ret_ma20_ma120_cross_sig_price\n",
      "ret_rsi_ma120_cross_sig_price\n",
      "ret_ma120_macd_1_cross_sig_price\n",
      "ret_ma120_bolling_cross_sig_price\n",
      "ret_ma120_cci_cross_sig_price\n",
      "ret_macd_02_cross_sig_price\n",
      "ret_ma120_macd_02_cross_sig_price\n",
      "ret_cci_fibonacci_signals\n",
      "ret_ma20_volume_cross_signals\n",
      "ret_ma20_rsi_macd_cross_sig_price\n",
      "ret_ma50_cross_sig_price\n",
      "ret_ma_bbi_rsi_sig_price\n",
      "ret_dc_bbi_cross_sig_price\n",
      "ret_ma_cci_sig\n",
      "ret_ma_vol_cci_sig\n",
      "ret_ma_short_long_cross_sig_price\n",
      "ret_ma_atr_cross_sig_price\n",
      "ret_dpo_ma_cross_sig_price\n",
      "ret_po_signals\n",
      "ret_rma_cross_sig_price\n",
      "ret_ma120_bbi_signals\n",
      "ret_skdj_sig_price\n",
      "ret_vao_signals\n",
      "ret_wma_signals\n",
      "ret_rsi_bb_ma_signal\n",
      "ret_macd_cross_signal\n",
      "ret_rsi_boll_sig\n",
      "ret_mfi_sig_price\n",
      "c_chu001\n",
      "c_chu002\n",
      "c_chu003\n",
      "c_chu004\n",
      "c_chu005\n",
      "c_chu006\n",
      "c_chu007\n",
      "c_chu008\n",
      "c_chu009\n",
      "c_chu010\n",
      "c_chu011\n",
      "c_chu012\n",
      "c_chu013\n",
      "c_chu014\n",
      "c_chu015\n",
      "c_chu016\n",
      "c_chu017\n",
      "c_chu018\n",
      "c_chu019\n",
      "c_chu020\n",
      "c_chu021\n",
      "c_chu022\n",
      "c_chu023\n",
      "c_chu024\n",
      "c_chu025\n",
      "c_chu026\n",
      "c_chu028\n",
      "c_chu029\n",
      "c_chu030\n",
      "c_chu031\n",
      "c_chu032\n",
      "c_chu033\n",
      "c_chu034\n",
      "c_chu037\n",
      "c_chu038\n",
      "c_chu039\n",
      "c_chu040\n",
      "c_chu041\n",
      "c_chu042\n",
      "c_chu043\n",
      "c_chu044\n",
      "c_chu045\n",
      "c_chu046\n",
      "c_chu047\n",
      "c_chu048\n",
      "c_chu049\n",
      "c_chu048.1\n",
      "c_chu049.1\n",
      "c_chu050\n",
      "c_chu051\n",
      "c_chu052\n",
      "c_chu053\n",
      "c_chu054\n",
      "c_chu055\n",
      "c_chu056\n",
      "c_chu057\n",
      "c_chu058\n",
      "c_chu059\n",
      "c_chu060\n",
      "c_chu061\n",
      "c_chu062\n",
      "c_hide_001\n",
      "c_hide_002\n",
      "c_hide_003\n",
      "c_hide_004\n",
      "c_hide_005\n",
      "c_hide_006\n",
      "c_hide_007\n",
      "c_hide_008\n",
      "c_hide_009\n",
      "c_hide_010\n",
      "c_hide_011\n",
      "c_hide_012\n",
      "c_hide_013\n",
      "c_hide_014\n",
      "c_hide_015\n",
      "c_hide_016\n",
      "c_hide_017\n",
      "c_hide_018\n",
      "c_hide_019\n",
      "c_hide_020\n",
      "c_hide_021\n",
      "c_hide_022\n",
      "c_hide_023\n",
      "c_hide_024\n",
      "c_hide_025\n",
      "c_hide_026\n",
      "c_hide_027\n",
      "c_hide_028\n",
      "c_hide_029\n",
      "c_hide_030\n",
      "c_hide_031\n",
      "c_hide_032\n",
      "open_time\n",
      "open\n",
      "high\n",
      "low\n",
      "close\n",
      "volume\n",
      "close_time\n",
      "turnover\n",
      "trade_count\n",
      "taker_buy_volume\n",
      "taker_buy_turnover\n"
     ]
    }
   ],
   "source": [
    "for i in list(factors.columns):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5aa77541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=192421, step=1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factors.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c5e6be77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_011(df, short_period=12, long_period=26):\n",
    "    '''\n",
    "    衡量MACD的过滤器，可用于识别趋势反转点\n",
    "    '''\n",
    "    short_ema = df['close'].ewm(span=short_period, adjust=False).mean()\n",
    "    long_ema = df['close'].ewm(span=long_period, adjust=False).mean()\n",
    "    macd = short_ema - long_ema\n",
    "    return macd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc3f1b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig=filter_011(df, 12, 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "13beb3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sig的index修改为arrange\n",
    "sig = sig.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ae3dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "factors['sig']=sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "acd7b39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix=factors.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "84859304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ret_stc_sig_price      -0.0012\n",
       "ret_hv_ratio_signals   -0.0018\n",
       "ret_td_signals          0.0021\n",
       "ret_ao_signals         -0.0029\n",
       "ret_ena_signals        -0.0026\n",
       "                         ...  \n",
       "turnover               -0.0001\n",
       "trade_count            -0.0043\n",
       "taker_buy_volume       -0.0138\n",
       "taker_buy_turnover     -0.0011\n",
       "sig                     1.0000\n",
       "Name: sig, Length: 144, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix.iloc[-1,:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cta_v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
