{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d233572",
   "metadata": {},
   "source": [
    "# 量化模型探索与执行指南\n",
    "\n",
    "本Notebook将指导你：\n",
    "1. 查看`model_example_v0.py`的内容\n",
    "2. 理解模型结构\n",
    "3. 安装所需依赖\n",
    "4. 运行量化模型\n",
    "\n",
    "首先确保你已通过VS Code连接到公司服务器！\n",
    "\n",
    "## 1. 查看模型文件内容\n",
    "我们可以直接在Notebook中查看Python文件内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19e16aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型文件路径: /public/data/factor_data/model_example_v0.py\n",
      "✅ 找到模型文件\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# 设置服务器上的文件路径\n",
    "SERVER_BASE_PATH = \"/public/data/factor_data/\"\n",
    "MODEL_FILE = \"model_example_v0.py\"\n",
    "MODEL_PATH = os.path.join(SERVER_BASE_PATH, MODEL_FILE)\n",
    "\n",
    "print(f\"模型文件路径: {MODEL_PATH}\")\n",
    "\n",
    "# 检查文件是否存在\n",
    "if os.path.exists(MODEL_PATH):\n",
    "    print(\"✅ 找到模型文件\")\n",
    "else:\n",
    "    print(\"❌ 未找到模型文件，请检查路径\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4759b1",
   "metadata": {},
   "source": [
    "### 显示模型文件内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8a41efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "显示模型文件内容: model_example_v0.py\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "import copy\n",
      "import numpy as np\n",
      "from sklearn.preprocessing import MinMaxScaler\n",
      "from sklearn.model_selection import TimeSeriesSplit\n",
      "from sklearn.linear_model import Ridge\n",
      "\n",
      "import os\n",
      "import pandas as pd\n",
      "import lightgbm as lgb\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "import torch.optim as optim\n",
      "from torch.utils.data import TensorDataset, DataLoader\n",
      "import logging\n",
      "\n",
      "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
      "\n",
      "class LSTMModel(nn.Module):\n",
      "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
      "        super(LSTMModel, self).__init__()\n",
      "        self.hidden_size = hidden_size\n",
      "        self.num_layers = num_layers\n",
      "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
      "        self.fc = nn.Linear(hidden_size, output_size)\n",
      "\n",
      "    def forward(self, x):\n",
      "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
      "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
      "        out, _ = self.lstm(x, (h0, c0))\n",
      "        out = self.fc(out[:, -1, :])\n",
      "        return out\n",
      "\n",
      "class TimeSeriesLSTM:\n",
      "    def __init__(self, input_size, hidden_size=64, num_layers=2, output_size=1,\n",
      "                 epochs=10, batch_size=32, lr=0.001, device='cpu'):\n",
      "        self.input_size = input_size\n",
      "        self.hidden_size = hidden_size\n",
      "        self.num_layers = num_layers\n",
      "        self.output_size = output_size\n",
      "        self.epochs = epochs\n",
      "        self.batch_size = batch_size\n",
      "        self.lr = lr\n",
      "        self.device = device\n",
      "        self.model = LSTMModel(input_size, hidden_size, num_layers, output_size).to(device)\n",
      "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n",
      "        self.criterion = nn.MSELoss()\n",
      "\n",
      "    def _prepare_data(self, X, y=None):\n",
      "        X_tensor = torch.tensor(X.values.reshape(-1, 1, self.input_size), dtype=torch.float32).to(self.device)\n",
      "        if y is not None:\n",
      "            y_tensor = torch.tensor(y.values.reshape(-1, self.output_size), dtype=torch.float32).to(self.device)\n",
      "            return TensorDataset(X_tensor, y_tensor)\n",
      "        return TensorDataset(X_tensor)\n",
      "\n",
      "    def fit(self, X_train, y_train):\n",
      "        train_dataset = self._prepare_data(X_train, y_train)\n",
      "        train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
      "\n",
      "        self.model.train()\n",
      "        for epoch in range(self.epochs):\n",
      "            for batch_X, batch_y in train_loader:\n",
      "                self.optimizer.zero_grad()\n",
      "                outputs = self.model(batch_X)\n",
      "                loss = self.criterion(outputs, batch_y)\n",
      "                loss.backward()\n",
      "                self.optimizer.step()\n",
      "\n",
      "\n",
      "    def predict(self, X_test):\n",
      "        test_dataset = self._prepare_data(X_test)\n",
      "        test_loader = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False)\n",
      "\n",
      "        self.model.eval()\n",
      "        predictions = []\n",
      "        with torch.no_grad():\n",
      "            for batch_X in test_loader:\n",
      "                outputs = self.model(batch_X[0])\n",
      "                predictions.append(outputs.cpu().numpy())\n",
      "        return np.vstack(predictions)\n",
      "\n",
      "    def score(self, X, y):\n",
      "        y_pred = self.predict(X)\n",
      "        y_true = y.values.reshape(-1, self.output_size)\n",
      "\n",
      "        mse = np.mean((y_true - y_pred)**2)\n",
      "        return -mse\n",
      "\n",
      "def train(X,y,model,n_split = 5,normalize=False):\n",
      "    scores = []\n",
      "    tscv = TimeSeriesSplit(n_splits=n_split)\n",
      "    for fold, (train_index, test_index) in enumerate(tscv.split(X)):\n",
      "        logging.info(f\"--- Fold {fold+1} ---\")\n",
      "\n",
      "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
      "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
      "\n",
      "        if normalize:\n",
      "            scaler = MinMaxScaler()\n",
      "            X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
      "            X_test = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
      "\n",
      "        logging.info(f\"训练集大小: {len(X_train)}, 测试集大小: {len(X_test)}\")\n",
      "        logging.info(f\"训练集索引范围: {X.index[train_index.min()]}-{X.index[train_index.max()]}\")\n",
      "        logging.info(f\"测试集索引范围: {X.index[test_index.min()]}-{X.index[test_index.max()]}\")\n",
      "\n",
      "        current_model = copy.deepcopy(model)\n",
      "\n",
      "        current_model.fit(X_train, y_train)\n",
      "        predictions = current_model.predict(X_test)\n",
      "        is_score = current_model.score(X_train, y_train)\n",
      "        os_score = current_model.score(X_test, y_test)\n",
      "        scores.append(os_score)\n",
      "\n",
      "        logging.info(f\"训练集评分: {is_score:.4f}, 测试集评分: {os_score:.4f}\")\n",
      "    return -sum(scores)\n",
      "\n",
      "if __name__=='__main__':\n",
      "    factor_data_path = '/public/data/factor_data'\n",
      "    file_name = 'BTCUSDT_15m_2020_2025_factor_data.pkl'\n",
      "\n",
      "    data = pd.read_pickle(os.path.join(factor_data_path,file_name))\n",
      "\n",
      "    data['target'] = data['close'].shift(-10)/data['close'] - 1\n",
      "\n",
      "    begin = '2021-10-01'\n",
      "    split = '2025-03-01'\n",
      "    selected_factors = [f'c_chu0{i}' for i in range(37,52)]\n",
      "    workding_data = data[selected_factors+['target']][begin:split].dropna()\n",
      "\n",
      "    X_data = workding_data[selected_factors]\n",
      "    y_data = workding_data['target']\n",
      "\n",
      "    ridge_model = Ridge(0.0008)\n",
      "    lgb_model = lgb.LGBMRegressor(random_state=42)\n",
      "\n",
      "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
      "    logging.info(f\"Using device: {device}\")\n",
      "\n",
      "\n",
      "    lstm_model = TimeSeriesLSTM(\n",
      "        input_size=len(selected_factors),\n",
      "        hidden_size=64,\n",
      "        num_layers=2,\n",
      "        epochs=5,\n",
      "        batch_size=32,\n",
      "        lr=0.001,\n",
      "        device=device\n",
      "    )\n",
      "\n",
      "    logging.info(\"\\n--- Training Ridge Model ---\")\n",
      "    ridge_score_sum = train(X_data, y_data, ridge_model, normalize=True)\n",
      "    logging.info(f\"Ridge Model Total  Score: {ridge_score_sum:.4f}\")\n",
      "\n",
      "    logging.info(\"\\n--- Training LightGBM Model ---\")\n",
      "    lgb_score_sum = train(X_data, y_data, lgb_model, normalize=False)\n",
      "    logging.info(f\"LightGBM Model Total  Score: {lgb_score_sum:.4f}\")\n",
      "\n",
      "    logging.info(\"\\n--- Training LSTM Model ---\")\n",
      "    lstm_score_sum = train(X_data, y_data, lstm_model, normalize=True)\n",
      "    logging.info(f\"LSTM Model Total  Score: {lstm_score_sum:.4f}\")\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 读取并显示模型文件内容\n",
    "print(f\"显示模型文件内容: {MODEL_FILE}\\n\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "with open(MODEL_PATH, 'r') as file:\n",
    "    content = file.read()\n",
    "    print(content)  # 显示前2000个字符\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ebc6f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import logging"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cta_v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
