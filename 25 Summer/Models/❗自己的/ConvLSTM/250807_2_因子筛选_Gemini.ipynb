{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "000141cc",
   "metadata": {},
   "source": [
    "# é‡åŒ–ç­–ç•¥å›æµ‹æ¡†æ¶ - ConvLSTMæ¨¡å‹é›†æˆ (V2 - å¢åŠ å› å­ç­›é€‰)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "733e7c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- å¿…è¦çš„åº“å¯¼å…¥ ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import logging\n",
    "from pandas.tseries.offsets import Week\n",
    "from tabulate import tabulate\n",
    "from colorama import Fore, Style, Back\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from collections import deque\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Conv1D, LSTM, Dense, Dropout, BatchNormalization, Flatten, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import classification_report\n",
    "import gc  # ç”¨äºå†…å­˜ç®¡ç†\n",
    "from scipy.stats import spearmanr # ä»…ç”¨äºéªŒè¯ï¼Œæ ¸å¿ƒè®¡ç®—ä¸å†ä¾èµ–\n",
    "from tqdm import tqdm # ç”¨äºæ˜¾ç¤ºç­›é€‰è¿›åº¦\n",
    "\n",
    "# å¿½ç•¥Pandasåœ¨ç‰¹å®šæ“ä½œä¸­å¯èƒ½äº§ç”Ÿçš„æ— å®³è­¦å‘Š\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning) # å¿½ç•¥åœ¨è®¡ç®—ä¸­å¯èƒ½é‡åˆ°çš„RuntimeWarning\n",
    "\n",
    "# é…ç½®æ—¥å¿—è¾“å‡ºæ ¼å¼\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# è®¾ç½®ç»˜å›¾é£æ ¼\n",
    "plt.style.use('seaborn-v0_8-darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c534338",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. æ–°å¢ï¼šä¸¤é˜¶æ®µå› å­ç­›é€‰æ¨¡å—\n",
    "\n",
    "è¯¥æ¨¡å—å®ç°äº†â€œè´¨é‡æŒ‡æ ‡åˆç­›â€å’Œâ€œå›æµ‹è¡¨ç°ç²¾ç­›â€çš„æ¼æ–—å¼ç­›é€‰æµç¨‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5606ed52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MODIFIED: ä¿®æ­£å¹¶ä¼˜åŒ–å› å­ç­›é€‰æ¨¡å— ---\n",
    "\n",
    "def calculate_factor_metrics(factor_series, forward_returns, rolling_window=252):\n",
    "    \"\"\"\n",
    "    è®¡ç®—å•ä¸ªå› å­çš„æ»šåŠ¨Rank ICå’ŒIR (ä½¿ç”¨é«˜æ•ˆçš„Pandasæƒ¯ç”¨æ³•)ã€‚\n",
    "    \n",
    "    å‚æ•°:\n",
    "    - factor_series (pd.Series): å•ä¸ªå› å­çš„æ—¶é—´åºåˆ—å€¼ã€‚\n",
    "    - forward_returns (pd.Series): å¯¹é½çš„æœªæ¥æ”¶ç›Šç‡åºåˆ—ã€‚\n",
    "    - rolling_window (int): è®¡ç®—æ»šåŠ¨æŒ‡æ ‡çš„çª—å£å¤§å°ã€‚\n",
    "    \n",
    "    è¿”å›:\n",
    "    - tuple: (å¹³å‡Rank IC, ä¿¡æ¯æ¯”ç‡ IR)\n",
    "    \"\"\"\n",
    "    # å¯¹é½æ•°æ®ï¼Œå»é™¤NaN\n",
    "    data = pd.concat([factor_series, forward_returns], axis=1).dropna()\n",
    "    data.columns = ['factor', 'return']\n",
    "\n",
    "    if len(data) < rolling_window:\n",
    "        return 0.0, 0.0\n",
    "\n",
    "    # --- FIX START: ä½¿ç”¨æœ€é«˜æ•ˆçš„Pandasæƒ¯ç”¨æ³•è®¡ç®—æ»šåŠ¨Rank IC ---\n",
    "    # æ­¥éª¤1: åˆ†åˆ«è®¡ç®—å› å­å’Œæ”¶ç›Šçš„æ»šåŠ¨ç§©æ¬¡\n",
    "    # .rank(pct=True) å°†å€¼è½¬æ¢ä¸º0åˆ°1çš„ç™¾åˆ†ä½ç§©æ¬¡\n",
    "    ranked_factor = data['factor'].rolling(window=rolling_window).rank(pct=True)\n",
    "    ranked_return = data['return'].rolling(window=rolling_window).rank(pct=True)\n",
    "    \n",
    "    # æ­¥éª¤2: è®¡ç®—æ»šåŠ¨ç§©æ¬¡çš„çš®å°”é€Šç›¸å…³ç³»æ•°ï¼Œè¿™ç­‰ä»·äºæ–¯çš®å°”æ›¼ç›¸å…³ç³»æ•°\n",
    "    # rolling().corr() æ˜¯é«˜åº¦ä¼˜åŒ–çš„å‡½æ•°\n",
    "    rolling_rank_ic = ranked_factor.rolling(window=rolling_window).corr(ranked_return)\n",
    "    # --- FIX END ---\n",
    "    \n",
    "    # è®¡ç®—å¹³å‡Rank IC\n",
    "    mean_rank_ic = rolling_rank_ic.mean()\n",
    "    \n",
    "    # è®¡ç®—IR (ä¿¡æ¯æ¯”ç‡)\n",
    "    std_rank_ic = rolling_rank_ic.std()\n",
    "    ir = mean_rank_ic / std_rank_ic if std_rank_ic > 0 and not np.isnan(std_rank_ic) else 0\n",
    "    \n",
    "    return mean_rank_ic, ir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4a52a4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def factor_to_signal(factor_series, upper_quantile=0.7, lower_quantile=0.3):\n",
    "    \"\"\"\n",
    "    å°†è¿ç»­çš„å› å­å€¼è½¬æ¢ä¸ºç¦»æ•£çš„äº¤æ˜“ä¿¡å· (1, -1, 0)ã€‚\n",
    "    \n",
    "    å‚æ•°:\n",
    "    - factor_series (pd.Series): å› å­å€¼åºåˆ—ã€‚\n",
    "    - upper_quantile (float): åšå¤šä¿¡å·çš„é˜ˆå€¼åˆ†ä½æ•°ã€‚\n",
    "    - lower_quantile (float): åšç©ºä¿¡å·çš„é˜ˆå€¼åˆ†ä½æ•°ã€‚\n",
    "    \n",
    "    è¿”å›:\n",
    "    - pd.Series: äº¤æ˜“ä¿¡å·åºåˆ—ã€‚\n",
    "    \"\"\"\n",
    "    upper_threshold = factor_series.quantile(upper_quantile)\n",
    "    lower_threshold = factor_series.quantile(lower_quantile)\n",
    "    \n",
    "    signal = pd.Series(0, index=factor_series.index, dtype=np.int8)\n",
    "    signal[factor_series > upper_threshold] = 1\n",
    "    signal[factor_series < lower_threshold] = -1\n",
    "    \n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8e75955b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_performance_metrics(backtest_results, trade_history, initial_capital, holding_period):\n",
    "    \"\"\"\n",
    "    ä¸€ä¸ªâ€œé™é»˜â€çš„æ€§èƒ½è®¡ç®—å‡½æ•°ï¼Œç”¨äºå› å­ç­›é€‰ï¼Œå®ƒè¿”å›æŒ‡æ ‡å€¼è€Œä¸æ˜¯æ‰“å°æŠ¥å‘Šã€‚\n",
    "    å…¶æ ¸å¿ƒè®¡ç®—é€»è¾‘ä¸¥æ ¼éµå¾ªæ‚¨æä¾›çš„ `evaluate_realized_pnl_performance` å‡½æ•°ã€‚\n",
    "    \"\"\"\n",
    "    df = backtest_results\n",
    "    trade_df = trade_history\n",
    "    \n",
    "    # æ ¸å¿ƒæ”¶ç›Šä¸é£é™©æŒ‡æ ‡\n",
    "    total_return = (df['equity_curve'].iloc[-1] - initial_capital) / initial_capital\n",
    "    equity_curve = df['equity_curve']\n",
    "    peak = equity_curve.expanding(min_periods=1).max()\n",
    "    drawdown = (peak - equity_curve) / peak\n",
    "    max_drawdown = drawdown.max()\n",
    "    \n",
    "    # å¹´åŒ–æŒ‡æ ‡\n",
    "    duration_years = max((df.index[-1] - df.index[0]).days / 365.25, 0.001)\n",
    "    annualized_return = total_return / duration_years\n",
    "    \n",
    "    # æ ‡å‡†åŒ–é£é™©è°ƒæ•´åæ”¶ç›Š\n",
    "    monthly_returns = df['equity_curve'].resample('M').last().pct_change().dropna()\n",
    "    sharpe_ratio = (monthly_returns.mean() / monthly_returns.std()) * np.sqrt(12) if len(monthly_returns) > 1 else 0\n",
    "    calmar_ratio = annualized_return / max_drawdown if max_drawdown > 0 else 0\n",
    "    \n",
    "    # äº¤æ˜“ç»Ÿè®¡\n",
    "    total_trades = len(trade_df)\n",
    "    expectancy = 0\n",
    "    if total_trades > 0:\n",
    "        winning_trades = trade_df[trade_df['net_pnl'] > 0]\n",
    "        losing_trades = trade_df[trade_df['net_pnl'] <= 0]\n",
    "        win_rate = len(winning_trades) / total_trades\n",
    "        avg_win = winning_trades['net_pnl'].mean() / initial_capital if len(winning_trades) > 0 else 0\n",
    "        avg_loss = losing_trades['net_pnl'].mean() / initial_capital if len(losing_trades) > 0 else 0\n",
    "        # æœŸæœ›æ”¶ç›Šå…¬å¼ä¸¥æ ¼æŒ‰ç…§æ‚¨æä¾›çš„ç‰ˆæœ¬\n",
    "        profit_factor = abs(winning_trades['net_pnl'].sum() / losing_trades['net_pnl'].abs().sum()) if len(losing_trades) > 0 and losing_trades['net_pnl'].abs().sum() > 0 else float('inf')\n",
    "        # ä¿®æ­£æœŸæœ›æ”¶ç›Šå…¬å¼ä»¥åŒ¹é…æ‚¨çš„å®šä¹‰\n",
    "        # æ‚¨çš„å®šä¹‰ï¼šæœŸæœ›æ”¶ç›Š = (èƒœç‡ * ç›ˆäºæ¯”) - (1 - èƒœç‡)\n",
    "        # æ³¨æ„ï¼šè¿™ä¸ªå…¬å¼åœ¨é‡‘èé¢†åŸŸä¸å¸¸è§ï¼Œä½†æˆ‘ä»¬ä¸¥æ ¼éµå¾ªæ‚¨çš„è¦æ±‚ã€‚\n",
    "        # å¸¸è§çš„å…¬å¼æ˜¯ï¼š(èƒœç‡ * å¹³å‡ç›ˆåˆ©) - (è´¥ç‡ * å¹³å‡äºæŸ)\n",
    "        # æˆ‘ä»¬å°†ä½¿ç”¨æ‚¨æä¾›çš„å…¬å¼ï¼š\n",
    "        expectancy_from_formula = (win_rate * profit_factor) - (1 - win_rate) if profit_factor != float('inf') else float('inf')\n",
    "    else:\n",
    "        expectancy_from_formula = 0\n",
    "\n",
    "    # æ•ˆç‡æŒ‡æ ‡\n",
    "    weekly_trades = trade_df.resample('W', on='entry_time').size().mean() if not trade_df.empty else 0\n",
    "    \n",
    "    return {\n",
    "        \"sharpe_ratio\": sharpe_ratio,\n",
    "        \"calmar_ratio\": calmar_ratio,\n",
    "        \"max_drawdown\": max_drawdown,\n",
    "        \"expectancy\": expectancy_from_formula,\n",
    "        \"weekly_trades\": weekly_trades\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4b5c0a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def screen_factors_sequentially(factor_data, config):\n",
    "    \"\"\"\n",
    "    æ‰§è¡Œå®Œæ•´çš„ä¸¤é˜¶æ®µæ¼æ–—å¼å› å­ç­›é€‰ã€‚\n",
    "    \n",
    "    å‚æ•°:\n",
    "    - factor_data (pd.DataFrame): åŒ…å«æ‰€æœ‰å¤‡é€‰å› å­å’Œ'close'ä»·æ ¼çš„æ•°æ®ã€‚\n",
    "    - config (dict): åŒ…å«æ‰€æœ‰ç­›é€‰é˜ˆå€¼çš„é…ç½®å­—å…¸ã€‚\n",
    "    \n",
    "    è¿”å›:\n",
    "    - list: æœ€ç»ˆé€šè¿‡æ‰€æœ‰ç­›é€‰çš„ç²¾è‹±å› å­çš„åç§°åˆ—è¡¨ã€‚\n",
    "    \"\"\"\n",
    "    logging.info(\"===== å¼€å§‹æ‰§è¡Œä¸¤é˜¶æ®µå› å­ç­›é€‰æµç¨‹ =====\")\n",
    "    \n",
    "    all_factor_cols = [col for col in factor_data.columns if col.startswith('ret') or col.startswith('c_chu') or col.startswith('c_hide')]\n",
    "    prices = factor_data['close']\n",
    "    \n",
    "    # --- é˜¶æ®µä¸€ï¼šåŸºäºè´¨é‡æŒ‡æ ‡çš„å¿«é€Ÿåˆç­› ---\n",
    "    logging.info(f\"--- é˜¶æ®µä¸€ï¼šåŸºäºRank ICå’ŒIRè¿›è¡Œåˆç­› (å…± {len(all_factor_cols)} ä¸ªå› å­) ---\")\n",
    "    \n",
    "    # é¢„è®¡ç®—æœªæ¥æ”¶ç›Šç‡ï¼Œç”¨äºICè®¡ç®—\n",
    "    forward_returns = prices.pct_change(config['holding_period']).shift(-config['holding_period'])\n",
    "    \n",
    "    passed_first_stage = []\n",
    "    \n",
    "    # ä½¿ç”¨tqdmæ˜¾ç¤ºè¿›åº¦æ¡\n",
    "    for factor_name in tqdm(all_factor_cols, desc=\"é˜¶æ®µä¸€ç­›é€‰è¿›åº¦\"):\n",
    "        factor_series = factor_data[factor_name]\n",
    "        rank_ic, ir = calculate_factor_metrics(factor_series, forward_returns)\n",
    "        \n",
    "        if abs(rank_ic) > config['rank_ic_threshold'] and abs(ir) > config['ir_threshold']:\n",
    "            passed_first_stage.append(factor_name)\n",
    "            \n",
    "    logging.info(f\"âœ… é˜¶æ®µä¸€å®Œæˆ: {len(passed_first_stage)} / {len(all_factor_cols)} ä¸ªå› å­é€šè¿‡åˆç­›ã€‚\")\n",
    "    \n",
    "    if not passed_first_stage:\n",
    "        logging.warning(\"âš ï¸ æ²¡æœ‰ä»»ä½•å› å­é€šè¿‡ç¬¬ä¸€é˜¶æ®µç­›é€‰ï¼Œæµç¨‹ç»ˆæ­¢ã€‚\")\n",
    "        return []\n",
    "\n",
    "    # --- é˜¶æ®µäºŒï¼šåŸºäºå›æµ‹è¡¨ç°çš„å®æˆ˜ç²¾ç­› ---\n",
    "    logging.info(f\"--- é˜¶æ®µäºŒï¼šåŸºäºå•å› å­å›æµ‹è¡¨ç°è¿›è¡Œç²¾ç­› (å…± {len(passed_first_stage)} ä¸ªå› å­) ---\")\n",
    "    \n",
    "    final_selected_factors = []\n",
    "    \n",
    "    for factor_name in tqdm(passed_first_stage, desc=\"é˜¶æ®µäºŒç­›é€‰è¿›åº¦\"):\n",
    "        # 1. å°†å› å­å€¼è½¬ä¸ºä¿¡å·\n",
    "        factor_signal = factor_to_signal(factor_data[factor_name])\n",
    "        \n",
    "        # 2. è°ƒç”¨æ‚¨æä¾›çš„ã€ä¸å¯ä¿®æ”¹çš„å›æµ‹å¼•æ“\n",
    "        backtest_results, trade_history = run_realized_pnl_backtest(\n",
    "            prices=prices,\n",
    "            signals=factor_signal,\n",
    "            initial_capital=config['initial_capital'],\n",
    "            commission_rate=config['commission_rate'],\n",
    "            holding_period=config['holding_period']\n",
    "        )\n",
    "        \n",
    "        # 3. å¦‚æœæ²¡æœ‰å‘ç”Ÿä»»ä½•äº¤æ˜“ï¼Œåˆ™ç›´æ¥æ·˜æ±°è¯¥å› å­\n",
    "        if trade_history.empty:\n",
    "            continue\n",
    "            \n",
    "        # 4. è®¡ç®—å›æµ‹æ€§èƒ½æŒ‡æ ‡\n",
    "        perf = _calculate_performance_metrics(\n",
    "            backtest_results, \n",
    "            trade_history, \n",
    "            config['initial_capital'],\n",
    "            config['holding_period']\n",
    "        )\n",
    "        \n",
    "        # 5. æ ¹æ®æ‚¨å¸¦æ•™çš„è¦æ±‚è¿›è¡Œè¯„ä¼°\n",
    "        # æ”¶ç›ŠæŒ‡æ ‡æ£€æŸ¥\n",
    "        returns_ok = (perf['sharpe_ratio'] > config['sharpe_threshold'] and perf['calmar_ratio'] > config['calmar_threshold']) or \\\n",
    "                     (perf['expectancy'] > config['expectancy_threshold'])\n",
    "        \n",
    "        # é£æ§æŒ‡æ ‡æ£€æŸ¥\n",
    "        risk_ok = perf['max_drawdown'] < config['mdd_threshold']\n",
    "        \n",
    "        # æ•ˆç‡æŒ‡æ ‡æ£€æŸ¥\n",
    "        efficiency_ok = perf['weekly_trades'] > config['weekly_trades_threshold']\n",
    "        \n",
    "        # å¿…é¡»åŒæ—¶æ»¡è¶³æ‰€æœ‰å¤§ç±»æŒ‡æ ‡\n",
    "        if returns_ok and risk_ok and efficiency_ok:\n",
    "            final_selected_factors.append(factor_name)\n",
    "            logging.info(f\"  -> âœ… å› å­ '{factor_name}' é€šè¿‡ç²¾ç­›. Sharpe: {perf['sharpe_ratio']:.2f}, MDD: {perf['max_drawdown']:.2%}\")\n",
    "        else:\n",
    "            logging.debug(f\"  -> âŒ å› å­ '{factor_name}' æœªé€šè¿‡ç²¾ç­›. Sharpe: {perf['sharpe_ratio']:.2f}, MDD: {perf['max_drawdown']:.2%}\")\n",
    "\n",
    "    logging.info(f\"âœ… é˜¶æ®µäºŒå®Œæˆ: {len(final_selected_factors)} / {len(passed_first_stage)} ä¸ªå› å­é€šè¿‡ç²¾ç­›ã€‚\")\n",
    "    logging.info(\"===== å› å­ç­›é€‰æµç¨‹ç»“æŸ =====\")\n",
    "    \n",
    "    return final_selected_factors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a587b5",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. ConvLSTMæ¨¡å‹æ„å»ºä¸è®­ç»ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "62cf9228",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_enhanced_conv_lstm_model(input_shape, num_features):\n",
    "    \"\"\"\n",
    "    æ„å»ºå¢å¼ºç‰ˆConvLSTMæ··åˆæ¨¡å‹æ¶æ„ï¼Œå¤„ç†æ›´å¤šå› å­\n",
    "    \n",
    "    æ¨¡å‹å¢å¼ºç‚¹:\n",
    "    1. å¢åŠ å·ç§¯å±‚é€šé“æ•°å’ŒLSTMå•å…ƒæ•°\n",
    "    2. æ·»åŠ åŒå‘LSTMæ•æ‰æ›´å¤æ‚çš„æ—¶åºä¾èµ–\n",
    "    3. å¼•å…¥æ³¨æ„åŠ›æœºåˆ¶èšç„¦é‡è¦ç‰¹å¾\n",
    "    4. å¢åŠ æ®‹å·®è¿æ¥æ·±åº¦\n",
    "    \n",
    "    å‚æ•°:\n",
    "    - input_shape: è¾“å…¥æ•°æ®å½¢çŠ¶ (æ—¶é—´æ­¥é•¿, ç‰¹å¾æ•°)\n",
    "    - num_features: ç‰¹å¾æ•°é‡\n",
    "    \n",
    "    è¿”å›:\n",
    "    - ç¼–è¯‘å¥½çš„Kerasæ¨¡å‹\n",
    "    \"\"\"\n",
    "    from tensorflow.keras.layers import Bidirectional, Attention, Reshape\n",
    "    \n",
    "    # è¾“å…¥å±‚\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # 1. ç‰¹å¾æå–åˆ†æ”¯\n",
    "    # 1Då·ç§¯åˆ†æ”¯ - æå–å±€éƒ¨ç‰¹å¾æ¨¡å¼\n",
    "    conv1 = Conv1D(filters=128, kernel_size=3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Dropout(0.3)(conv1)\n",
    "    \n",
    "    conv2 = Conv1D(filters=256, kernel_size=5, activation='relu', padding='same')(conv1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Dropout(0.3)(conv2)\n",
    "    \n",
    "    # 2. æ—¶åºä¾èµ–åˆ†æ”¯\n",
    "    # åŒå‘LSTMæ•æ‰å¤æ‚æ—¶åºæ¨¡å¼\n",
    "    lstm1 = Bidirectional(LSTM(128, return_sequences=True))(inputs)\n",
    "    lstm1 = BatchNormalization()(lstm1)\n",
    "    lstm1 = Dropout(0.3)(lstm1)\n",
    "    \n",
    "    # æ³¨æ„åŠ›æœºåˆ¶èšç„¦é‡è¦æ—¶é—´æ­¥\n",
    "    attention = Attention()([lstm1, lstm1])\n",
    "    lstm2 = Bidirectional(LSTM(256, return_sequences=False))(attention)\n",
    "    lstm2 = BatchNormalization()(lstm2)\n",
    "    lstm2 = Dropout(0.4)(lstm2)\n",
    "    \n",
    "    # 3. åˆå¹¶åˆ†æ”¯\n",
    "    conv_flat = Flatten()(conv2)\n",
    "    merged = concatenate([conv_flat, lstm2])\n",
    "    \n",
    "    # 4. å…¨è¿æ¥å±‚\n",
    "    dense1 = Dense(512, activation='relu')(merged)\n",
    "    dense1 = BatchNormalization()(dense1)\n",
    "    dense1 = Dropout(0.5)(dense1)\n",
    "    \n",
    "    dense2 = Dense(256, activation='relu')(dense1)\n",
    "    dense2 = BatchNormalization()(dense2)\n",
    "    dense2 = Dropout(0.4)(dense2)\n",
    "    \n",
    "    # 5. è¾“å‡ºå±‚ - ä¸‰åˆ†ç±»(åšå¤š/åšç©º/ä¸­æ€§)\n",
    "    outputs = Dense(3, activation='softmax')(dense2)\n",
    "    \n",
    "    # åˆ›å»ºæ¨¡å‹\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # ç¼–è¯‘æ¨¡å‹\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0005),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "084031ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MODIFIED: æ¥å—ç­›é€‰åçš„å› å­åˆ—è¡¨ ---\n",
    "def prepare_rolling_data(factor_data, selected_features, lookback=60, test_size=0.2):\n",
    "    \"\"\"\n",
    "    å‡†å¤‡æ»šåŠ¨è®­ç»ƒæ•°æ® - ä½¿ç”¨ç­›é€‰åçš„ç²¾è‹±å› å­\n",
    "    \n",
    "    å¢å¼ºç‚¹:\n",
    "    1. ä½¿ç”¨ç»è¿‡ä¸¤é˜¶æ®µç­›é€‰åçš„å› å­\n",
    "    2. å¢åŠ ç‰¹å¾é€‰æ‹©å’Œé™ç»´\n",
    "    3. æ”¹è¿›æœªæ¥æ”¶ç›Šç‡è®¡ç®—\n",
    "    \n",
    "    å‚æ•°:\n",
    "    - factor_data: å› å­æ•°æ®DataFrame\n",
    "    - selected_features: ç»è¿‡ç­›é€‰çš„å› å­åç§°åˆ—è¡¨\n",
    "    - lookback: å›çœ‹æ—¶é—´æ­¥é•¿\n",
    "    - test_size: æµ‹è¯•é›†æ¯”ä¾‹ï¼ˆç”¨äºéªŒè¯ï¼‰\n",
    "    \n",
    "    è¿”å›:\n",
    "    - ç‰¹å¾ã€æ ‡ç­¾å’Œæ ‡å‡†åŒ–å™¨\n",
    "    \"\"\"\n",
    "    logging.info(\"ğŸ“Š å‡†å¤‡æ»šåŠ¨è®­ç»ƒæ•°æ® (ä½¿ç”¨ç­›é€‰åçš„ç²¾è‹±å› å­)...\")\n",
    "    \n",
    "    # 1. ä½¿ç”¨ç­›é€‰åçš„ç‰¹å¾å› å­\n",
    "    feature_columns = selected_features\n",
    "    \n",
    "    if not feature_columns:\n",
    "        raise ValueError(\"é”™è¯¯ï¼šæ²¡æœ‰å¯ç”¨çš„ç‰¹å¾ã€‚å› å­ç­›é€‰ååˆ—è¡¨ä¸ºç©ºã€‚\")\n",
    "        \n",
    "    logging.info(f\"âœ… ä½¿ç”¨ {len(feature_columns)} ä¸ªç²¾è‹±å› å­ç‰¹å¾\")\n",
    "    \n",
    "    # 2. ç‰¹å¾é¢„å¤„ç† - å¡«å……ç¼ºå¤±å€¼\n",
    "    features = factor_data[feature_columns].fillna(method='ffill').fillna(0)\n",
    "    \n",
    "    # 3. åˆ›å»ºç›®æ ‡å˜é‡ - æœªæ¥10æœŸæ”¶ç›Šç‡æ–¹å‘ (æ”¹è¿›ç‰ˆ)\n",
    "    future_returns = np.log(factor_data['close']).diff(10).shift(-10)\n",
    "    volatility = future_returns.rolling(100).std().fillna(0.01)\n",
    "    upper_threshold = 0.75 * volatility\n",
    "    lower_threshold = -0.75 * volatility\n",
    "    y = np.zeros(len(future_returns))\n",
    "    y[future_returns > upper_threshold] = 1\n",
    "    y[future_returns < lower_threshold] = 2\n",
    "    y = tf.keras.utils.to_categorical(y, num_classes=3)\n",
    "    \n",
    "    # 4. ç‰¹å¾é€‰æ‹© - é€‰æ‹©æœ€ç›¸å…³çš„Kä¸ªç‰¹å¾ (å¦‚æœç­›é€‰åå› å­æ•°ä»è¾ƒå¤š)\n",
    "    k_best = min(100, len(feature_columns))\n",
    "    selector = SelectKBest(f_classif, k=k_best)\n",
    "    # ç¡®ä¿yå’Œfeatureså¯¹é½\n",
    "    aligned_features, aligned_y = features.align(pd.Series(y.argmax(axis=1), index=features.index), join='inner', axis=0)\n",
    "    features_selected = selector.fit_transform(aligned_features, aligned_y)\n",
    "    \n",
    "    # 5. é™ç»´ - ä½¿ç”¨PCAä¿ç•™95%çš„æ–¹å·®\n",
    "    pca = PCA(n_components=0.95)\n",
    "    features_reduced = pca.fit_transform(features_selected)\n",
    "    \n",
    "    logging.info(f\"âœ… é™ç»´åç‰¹å¾æ•°: {features_reduced.shape[1]}\")\n",
    "    \n",
    "    # 6. åˆ›å»ºæ—¶é—´åºåˆ—æ ·æœ¬\n",
    "    X = []\n",
    "    valid_indices = []\n",
    "    \n",
    "    # è·å–å¯¹é½åçš„ç´¢å¼•\n",
    "    aligned_indices = aligned_features.index\n",
    "    \n",
    "    for i in range(lookback, len(features_reduced) - 10):\n",
    "        X.append(features_reduced[i-lookback:i])\n",
    "        valid_indices.append(i)\n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = y[aligned_features.index[valid_indices]]\n",
    "    indices = aligned_indices[valid_indices]\n",
    "    \n",
    "    logging.info(f\"âœ… æ•°æ®å‡†å¤‡å®Œæˆ - æ ·æœ¬æ•°: {X.shape[0]}, æ—¶é—´æ­¥é•¿: {X.shape[1]}, ç‰¹å¾æ•°: {X.shape[2]}\")\n",
    "    return X, y, indices, pca, selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f69690be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_train_and_predict(X, y, indices, lookback=60, n_splits=5):\n",
    "    \"\"\"\n",
    "    æ‰§è¡Œæ»šåŠ¨è®­ç»ƒå’Œé¢„æµ‹ (å¢å¼ºç‰ˆ)\n",
    "    \n",
    "    å¢å¼ºç‚¹:\n",
    "    1. ä½¿ç”¨å¢å¼ºç‰ˆæ¨¡å‹\n",
    "    2. æ›´æ—©åœæ­¢å’ŒåŠ¨æ€å­¦ä¹ ç‡è°ƒæ•´\n",
    "    3. æ›´ç²¾ç»†çš„ä¿¡å·å¤„ç†\n",
    "    \n",
    "    å‚æ•°:\n",
    "    - X: ç‰¹å¾æ•°æ®\n",
    "    - y: æ ‡ç­¾æ•°æ®\n",
    "    - indices: æ—¶é—´ç´¢å¼•\n",
    "    - lookback: å›çœ‹æ—¶é—´æ­¥é•¿\n",
    "    - n_splits: æ—¶é—´åºåˆ—åˆ†å‰²æ•°\n",
    "    \n",
    "    è¿”å›:\n",
    "    - é¢„æµ‹ä¿¡å·Series\n",
    "    \"\"\"\n",
    "    logging.info(f\"ğŸš€ å¼€å§‹æ»šåŠ¨è®­ç»ƒ (n_splits={n_splits})...\")\n",
    "    \n",
    "    # åˆå§‹åŒ–é¢„æµ‹ç»“æœæ•°ç»„\n",
    "    all_predictions = np.zeros((len(y), 3))\n",
    "    \n",
    "    # åˆ›å»ºæ—¶é—´åºåˆ—äº¤å‰éªŒè¯å™¨\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    \n",
    "    # ç”¨äºå­˜å‚¨æ¯ä¸ªæŠ˜å çš„æ€§èƒ½\n",
    "    fold_accuracies = []\n",
    "    fold_losses = []\n",
    "    \n",
    "    for fold, (train_index, test_index) in enumerate(tscv.split(X)):\n",
    "        logging.info(f\"\\nğŸ” å¤„ç†æŠ˜å  {fold+1}/{n_splits}\")\n",
    "        logging.info(f\"  è®­ç»ƒé›†: {indices[train_index[0]]} åˆ° {indices[train_index[-1]]}\")\n",
    "        logging.info(f\"  æµ‹è¯•é›†: {indices[test_index[0]]} åˆ° {indices[test_index[-1]]}\")\n",
    "        \n",
    "        # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # æ ‡å‡†åŒ– - ä½¿ç”¨è®­ç»ƒé›†çš„ç»Ÿè®¡é‡\n",
    "        scaler = StandardScaler()\n",
    "        X_train_2d = X_train.reshape(-1, X_train.shape[-1])\n",
    "        X_test_2d = X_test.reshape(-1, X_test.shape[-1])\n",
    "        \n",
    "        scaler.fit(X_train_2d)\n",
    "        X_train_scaled = scaler.transform(X_train_2d).reshape(X_train.shape)\n",
    "        X_test_scaled = scaler.transform(X_test_2d).reshape(X_test.shape)\n",
    "        \n",
    "        # æ„å»ºå¢å¼ºç‰ˆæ¨¡å‹\n",
    "        model = build_enhanced_conv_lstm_model((lookback, X_train.shape[2]), X_train.shape[2])\n",
    "        \n",
    "        # å›è°ƒå‡½æ•° - æ›´æ—©åœæ­¢å’ŒåŠ¨æ€å­¦ä¹ ç‡\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True, verbose=1),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-6, verbose=1)\n",
    "        ]\n",
    "        \n",
    "        # è®­ç»ƒæ¨¡å‹ - å¢åŠ epochs\n",
    "        history = model.fit(\n",
    "            X_train_scaled, y_train,\n",
    "            epochs=50,\n",
    "            batch_size=1024,\n",
    "            validation_data=(X_test_scaled, y_test),\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # åœ¨æµ‹è¯•é›†ä¸Šé¢„æµ‹\n",
    "        test_pred = model.predict(X_test_scaled, batch_size=2048, verbose=0)\n",
    "        all_predictions[test_index] = test_pred\n",
    "        \n",
    "        # è¯„ä¼°æ€§èƒ½\n",
    "        test_loss, test_acc = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "        fold_accuracies.append(test_acc)\n",
    "        fold_losses.append(test_loss)\n",
    "        logging.info(f\"  æµ‹è¯•å‡†ç¡®ç‡: {test_acc:.4f}, æµ‹è¯•æŸå¤±: {test_loss:.4f}\")\n",
    "        \n",
    "        # æ¸…ç†å†…å­˜\n",
    "        del model, X_train, X_test, y_train, y_test\n",
    "        gc.collect()\n",
    "        tf.keras.backend.clear_session()\n",
    "    \n",
    "    # æ‰“å°æ•´ä½“æ€§èƒ½\n",
    "    logging.info(f\"\\nâœ… æ»šåŠ¨è®­ç»ƒå®Œæˆ - å¹³å‡å‡†ç¡®ç‡: {np.mean(fold_accuracies):.4f}, å¹³å‡æŸå¤±: {np.mean(fold_losses):.4f}\")\n",
    "    \n",
    "    # è½¬æ¢é¢„æµ‹ç»“æœä¸ºä¿¡å·\n",
    "    signal_probs = all_predictions[:, 1] - all_predictions[:, 2]  # åšå¤šæ¦‚ç‡ - åšç©ºæ¦‚ç‡\n",
    "    \n",
    "    # åˆ›å»ºä¿¡å·Series\n",
    "    signal_series = pd.Series(signal_probs, index=indices, name='signal_strength')\n",
    "    \n",
    "    # ä½¿ç”¨åŠ¨æ€é˜ˆå€¼ç”Ÿæˆäº¤æ˜“ä¿¡å·\n",
    "    rolling_mean = signal_series.rolling(window=100).mean()\n",
    "    rolling_std = signal_series.rolling(window=100).std()\n",
    "    \n",
    "    # åŠ¨æ€é˜ˆå€¼\n",
    "    long_threshold = rolling_mean + 0.5 * rolling_std\n",
    "    short_threshold = rolling_mean - 0.5 * rolling_std\n",
    "    \n",
    "    # ç”Ÿæˆæœ€ç»ˆä¿¡å·\n",
    "    signals = pd.Series(0, index=indices)\n",
    "    signals[signal_series > long_threshold] = 1\n",
    "    signals[signal_series < short_threshold] = -1\n",
    "    \n",
    "    # ä¿¡å·å¹³æ»‘ - é¿å…é¢‘ç¹å˜åŠ¨\n",
    "    signals = signals.rolling(window=5, min_periods=3).mean()\n",
    "    signals = np.where(signals > 0.3, 1, np.where(signals < -0.3, -1, 0))\n",
    "    \n",
    "    signal_series = pd.Series(signals, index=indices)\n",
    "    \n",
    "    logging.info(f\"ğŸ“¡ ä¿¡å·ç”Ÿæˆå®Œæˆ - åšå¤šæ¯”ä¾‹: {(signal_series == 1).mean():.2%}, \"\n",
    "                 f\"åšç©ºæ¯”ä¾‹: {(signal_series == -1).mean():.2%}\")\n",
    "    \n",
    "    return signal_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63784ec",
   "metadata": {},
   "source": [
    "## 3. æ ¸å¿ƒå›æµ‹ä¸è¯„ä¼°å‡½æ•° (ä¿æŒä¸å˜)\n",
    "(æ­¤å¤„ä¿ç•™åŸæœ‰çš„run_realized_pnl_backtestå’Œevaluate_realized_pnl_performanceå‡½æ•°)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0f3d8a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_realized_pnl_backtest(prices, signals, initial_capital=100000, commission_rate=0.0002, holding_period=10):\n",
    "    \"\"\"\n",
    "    æ‰§è¡ŒåŸºäºå·²å®ç°ç›ˆäºçš„é«˜æ€§èƒ½å›æµ‹ã€‚\n",
    "\n",
    "    æœ¬å‡½æ•°ä¸ºå›æµ‹æ¡†æ¶çš„æ ¸å¿ƒï¼Œå…¶è®¾è®¡ä¸¥æ ¼éµå¾ªä»¥ä¸‹äº¤æ˜“é€»è¾‘ï¼š\n",
    "    1. **èµ„é‡‘ç®¡ç†**: åˆå§‹èµ„é‡‘è¢«ç­‰åˆ†ä¸º10ä»½ï¼Œæ¯æ¬¡å¼€ä»“ä½¿ç”¨ä¸€ä»½ï¼Œç”¨äºæ¨¡æ‹Ÿåˆ†æ‰¹å»ºä»“ã€‚\n",
    "    2. **å•å‘æŒä»“**: åœ¨ä»»ä½•æ—¶é—´ç‚¹ï¼Œæ‰€æœ‰æŒä»“çš„æ–¹å‘å¿…é¡»ä¸€è‡´ï¼ˆå…¨ä¸ºå¤šå¤´æˆ–å…¨ä¸ºç©ºå¤´ï¼‰ï¼Œä¸å…è®¸é”ä»“æˆ–åŒæ—¶æŒæœ‰å¤šç©ºã€‚\n",
    "    3. **äº‹ä»¶é©±åŠ¨**: äº¤æ˜“ä¿¡å·åœ¨t-1æ—¶åˆ»äº§ç”Ÿï¼Œåœ¨tæ—¶åˆ»æ‰§è¡Œã€‚\n",
    "    4. **å›ºå®šæŒæœ‰æœŸ**: æ¯ä»½ç‹¬ç«‹çš„ä»“ä½æœ€å¤šæŒæœ‰`holding_period`ä¸ªå‘¨æœŸï¼Œåˆ°æœŸåè‡ªåŠ¨å¹³ä»“ã€‚\n",
    "    5. **æ¸è¿›å¼è°ƒä»“**: å½“æ”¶åˆ°ä¸å½“å‰æŒä»“æ–¹å‘ç›¸åçš„ä¿¡å·æ—¶ï¼Œä»…å¹³æ‰**æœ€æ—©å¼€ç«‹**çš„ä¸€ä»½ä»“ä½ï¼Œè€Œéå…¨éƒ¨å¹³ä»“ï¼Œä»¥å®ç°æ›´å¹³æ»‘çš„è°ƒä»“ï¼Œå‡å°‘äº¤æ˜“å†²å‡»ã€‚\n",
    "    6. **å·²å®ç°ç›ˆäº**: æƒç›Šæ›²çº¿çš„è®¡ç®—å®Œå…¨åŸºäºå·²å…³é—­ä»“ä½çš„çœŸå®ç›ˆäºï¼Œå¿½ç•¥æœªå¹³ä»“ä½çš„æµ®åŠ¨ç›ˆäºï¼Œä½¿ç»“æœæ›´ä¿å®ˆç¨³å¥ã€‚\n",
    "\n",
    "    æ€§èƒ½ä¼˜åŒ–å…³é”®ç‚¹:\n",
    "    - **é¢„åˆ†é…æ•°ç»„**: ä½¿ç”¨NumPyæ•°ç»„é¢„å…ˆåˆ†é…å†…å­˜æ¥å­˜å‚¨å›æµ‹ç»“æœï¼Œé¿å…åœ¨å¾ªç¯ä¸­åŠ¨æ€ä¿®æ”¹Pandas DataFrameï¼Œè¿™æ˜¯ä¸»è¦çš„æ€§èƒ½æå‡æ¥æºã€‚\n",
    "    - **é«˜æ•ˆé˜Ÿåˆ—æ“ä½œ**: åˆ©ç”¨`collections.deque`çš„O(1)æ—¶é—´å¤æ‚åº¦çš„`popleft()`å’Œ`append()`æ“ä½œç®¡ç†æ´»è·ƒä»“ä½ã€‚\n",
    "    - **ç®—æ³•ä¼˜åŒ–**: æ£€æŸ¥åˆ°æœŸä»“ä½æ—¶ï¼Œä»…éœ€æ£€æŸ¥é˜Ÿåˆ—å¤´éƒ¨çš„æœ€æ—©ä»“ä½ï¼Œæ— éœ€éå†æ•´ä¸ªé˜Ÿåˆ—ã€‚\n",
    "\n",
    "    å‚æ•°:\n",
    "    - prices (pd.Series): èµ„äº§çš„æ”¶ç›˜ä»·åºåˆ—ã€‚\n",
    "    - signals (pd.Series): äº¤æ˜“ä¿¡å·åºåˆ— (1: åšå¤š, -1: åšç©º, 0: ä¸­æ€§)ã€‚\n",
    "    - initial_capital (float): åˆå§‹æ€»èµ„æœ¬ã€‚\n",
    "    - commission_rate (float): å•è¾¹äº¤æ˜“æ‰‹ç»­è´¹ç‡ã€‚\n",
    "    - holding_period (int): æ¯ä»½ä»“ä½çš„æœ€å¤§æŒæœ‰å‘¨æœŸï¼ˆå•ä½ï¼šKçº¿æ•°é‡ï¼‰ã€‚\n",
    "\n",
    "    è¿”å›:\n",
    "    - pd.DataFrame: åŒ…å«å›æµ‹è¯¦ç»†è¿‡ç¨‹ï¼ˆå¦‚æŒä»“ã€æˆæœ¬ã€æƒç›Šç­‰ï¼‰çš„DataFrameã€‚\n",
    "    - pd.DataFrame: åŒ…å«æ¯ä¸€ç¬”å·²å®Œæˆäº¤æ˜“çš„è¯¦ç»†å†å²è®°å½•ã€‚\n",
    "    \"\"\"\n",
    "    logging.info(\"ğŸš€ å¼€å§‹æ‰§è¡Œä¼˜åŒ–ç‰ˆå›æµ‹ (åŸºäºå·²å®ç°ç›ˆäº)...\")\n",
    "\n",
    "    n = len(prices)\n",
    "    # --- æ€§èƒ½ä¼˜åŒ–: é¢„åˆ†é…ç»“æœå­˜å‚¨ ---\n",
    "    # å°†ç»“æœå­˜å‚¨åœ¨å­—å…¸åŒ…è£¹çš„NumPyæ•°ç»„ä¸­ï¼Œå¾ªç¯ç»“æŸåä¸€æ¬¡æ€§ç”ŸæˆDataFrameã€‚\n",
    "    # è¿™æ¯”åœ¨å¾ªç¯ä¸­é€è¡Œå¡«å……DataFrameï¼ˆå¦‚ä½¿ç”¨.atæˆ–.locï¼‰å¿«å‡ ä¸ªæ•°é‡çº§ã€‚\n",
    "    results = {\n",
    "        'position': np.zeros(n, dtype=np.int8),\n",
    "        'position_count': np.zeros(n, dtype=np.int8),\n",
    "        'cost_basis': np.zeros(n),\n",
    "        'transaction_costs': np.zeros(n),\n",
    "        'net_returns': np.zeros(n),\n",
    "        'equity_curve': np.full(n, initial_capital)\n",
    "    }\n",
    "\n",
    "    # --- æ€§èƒ½ä¼˜åŒ–: é¢„æå–æ•°æ®åˆ°NumPyæ•°ç»„ ---\n",
    "    # åœ¨å¾ªç¯å¼€å§‹å‰å°†Pandas Seriesè½¬æ¢ä¸ºNumPyæ•°ç»„ï¼Œåç»­åœ¨å¾ªç¯ä¸­è®¿é—®æ•°ç»„å…ƒç´ æ¯”è®¿é—®Serieså…ƒç´ æ›´å¿«ã€‚\n",
    "    close_arr = prices.values\n",
    "    signal_arr = signals.values\n",
    "    indices = prices.index # é¢„å­˜ç´¢å¼•ï¼Œç”¨äºè®°å½•äº¤æ˜“å†å²\n",
    "\n",
    "    # --- åˆå§‹åŒ–äº¤æ˜“çŠ¶æ€å˜é‡ ---\n",
    "    active_positions = deque()  # ä½¿ç”¨åŒç«¯é˜Ÿåˆ—(deque)é«˜æ•ˆç®¡ç†å…ˆè¿›å…ˆå‡ºçš„æŒä»“\n",
    "    realized_pnl = 0.0          # ç´¯è®¡å·²å®ç°ç›ˆäº\n",
    "    position_direction = 0      # å½“å‰æ•´ä½“æŒä»“æ–¹å‘ (1: å¤š, -1: ç©º, 0: æ— )\n",
    "    position_cost = 0.0         # å½“å‰æŒä»“çš„å¹³å‡æˆæœ¬ä»·\n",
    "    trade_history = []          # è®°å½•æ¯ä¸€ç¬”å®Œæ•´äº¤æ˜“çš„åˆ—è¡¨\n",
    "    capital_per_position = initial_capital / 10 # æ¯ä»½ä»“ä½åˆ†é…çš„èµ„é‡‘\n",
    "\n",
    "    # --- ä¸»å›æµ‹å¾ªç¯ ---\n",
    "    # ä»ç¬¬äºŒä¸ªæ—¶é—´ç‚¹å¼€å§‹éå†ï¼Œå› ä¸ºäº¤æ˜“å†³ç­–åŸºäºå‰ä¸€å¤©çš„ä¿¡å·\n",
    "    for i in range(1, n):\n",
    "        current_close = close_arr[i]\n",
    "        prev_signal = signal_arr[i-1]  # ä½¿ç”¨t-1çš„ä¿¡å·å†³å®štæ—¶åˆ»çš„æ“ä½œ\n",
    "        trades_occurred = False        # æ ‡è®°å½“æ—¥æ˜¯å¦æœ‰äº¤æ˜“ï¼ˆå¹³ä»“ï¼‰å‘ç”Ÿ\n",
    "\n",
    "        # 1. å¤„ç†åˆ°æœŸå¼ºåˆ¶å¹³ä»“\n",
    "        # --- æ€§èƒ½ä¼˜åŒ–: O(1)å¤æ‚åº¦çš„åˆ°æœŸæ£€æŸ¥ ---\n",
    "        # ç”±äºactive_positionsæ˜¯å…ˆè¿›å…ˆå‡ºé˜Ÿåˆ—ï¼Œæˆ‘ä»¬åªéœ€æ£€æŸ¥é˜Ÿå¤´ï¼ˆæœ€æ—©çš„ä»“ä½ï¼‰ã€‚\n",
    "        # å¦‚æœé˜Ÿå¤´æ²¡åˆ°æœŸï¼Œé‚£ä¹ˆé˜Ÿåˆ—ä¸­æ‰€æœ‰å…¶ä»–ä»“ä½ä¹Ÿä¸€å®šæ²¡åˆ°æœŸã€‚\n",
    "        while active_positions:\n",
    "            oldest_pos = active_positions[0] # åªçœ‹ä¸å–\n",
    "            if i - oldest_pos['entry_index'] >= holding_period:\n",
    "                # ä»“ä½å·²åˆ°æœŸï¼Œæ‰§è¡Œå¹³ä»“\n",
    "                pos_to_close = active_positions.popleft() # ä»é˜Ÿåˆ—ä¸­ç§»é™¤\n",
    "                exit_price = current_close\n",
    "                \n",
    "                # è®¡ç®—ç›ˆäº\n",
    "                pnl = (exit_price - pos_to_close['entry_price']) * pos_to_close['direction'] * pos_to_close['quantity']\n",
    "                exit_commission = commission_rate * exit_price * pos_to_close['quantity']\n",
    "                net_pnl = pnl - exit_commission\n",
    "                \n",
    "                # æ›´æ–°ç´¯è®¡å·²å®ç°ç›ˆäº\n",
    "                realized_pnl += net_pnl\n",
    "                trades_occurred = True\n",
    "                \n",
    "                # è®°å½•äº¤æ˜“æˆæœ¬\n",
    "                results['transaction_costs'][i] += exit_commission\n",
    "                \n",
    "                # è®°å½•äº¤æ˜“å†å²\n",
    "                trade_history.append({\n",
    "                    'entry_time': indices[pos_to_close['entry_index']], 'exit_time': indices[i],\n",
    "                    'direction': pos_to_close['direction'], 'entry_price': pos_to_close['entry_price'],\n",
    "                    'exit_price': exit_price, 'quantity': pos_to_close['quantity'],\n",
    "                    'pnl': pnl, 'commission': exit_commission, 'net_pnl': net_pnl,\n",
    "                    'duration': i - pos_to_close['entry_index'], 'type': 'expired'\n",
    "                })\n",
    "            else:\n",
    "                # æœ€æ—©çš„ä»“ä½éƒ½æœªåˆ°æœŸï¼Œåˆ™æ— éœ€ç»§ç»­æ£€æŸ¥\n",
    "                break\n",
    "\n",
    "        # 2. æ ¹æ®æ–°ä¿¡å·å¤„ç†äº¤æ˜“\n",
    "        if prev_signal != 0:  # åªå¯¹éä¸­æ€§ä¿¡å·åšå‡ºååº”\n",
    "            # æƒ…å†µA: å½“å‰æ— ä»»ä½•æŒä»“ï¼Œä¸”æœ‰æ–°ä¿¡å·\n",
    "            if position_direction == 0:\n",
    "                # å¼€ç«‹ç¬¬ä¸€ä»½ä»“ä½\n",
    "                quantity = capital_per_position / current_close\n",
    "                active_positions.append({\n",
    "                    'direction': prev_signal,\n",
    "                    'entry_price': current_close,\n",
    "                    'quantity': quantity,\n",
    "                    'entry_index': i\n",
    "                })\n",
    "                position_direction = prev_signal\n",
    "                position_cost = current_close\n",
    "                entry_commission = commission_rate * current_close * quantity\n",
    "                results['transaction_costs'][i] += entry_commission\n",
    "                results['position'][i] = prev_signal\n",
    "\n",
    "            # æƒ…å†µB: æ–°ä¿¡å·ä¸å½“å‰æŒä»“æ–¹å‘ç›¸åŒ (åŠ ä»“)\n",
    "            elif position_direction == prev_signal and len(active_positions) < 10:\n",
    "                # å¦‚æœä»“ä½æœªæ»¡10ä»½ï¼Œåˆ™åŠ å¼€ä¸€ä»½æ–°ä»“\n",
    "                quantity = capital_per_position / current_close\n",
    "                active_positions.append({\n",
    "                    'direction': prev_signal, 'entry_price': current_close,\n",
    "                    'quantity': quantity, 'entry_index': i\n",
    "                })\n",
    "                # æ›´æ–°å¹³å‡æŒä»“æˆæœ¬\n",
    "                total_quantity = sum(p['quantity'] for p in active_positions)\n",
    "                total_cost = sum(p['entry_price'] * p['quantity'] for p in active_positions)\n",
    "                position_cost = total_cost / total_quantity\n",
    "                entry_commission = commission_rate * current_close * quantity\n",
    "                results['transaction_costs'][i] += entry_commission\n",
    "                results['position'][i] = prev_signal\n",
    "\n",
    "            # æƒ…å†µC: æ–°ä¿¡å·ä¸å½“å‰æŒä»“æ–¹å‘ç›¸å (éƒ¨åˆ†å¹³ä»“)\n",
    "            elif position_direction != prev_signal and active_positions:\n",
    "                # æ ¸å¿ƒé€»è¾‘ï¼šåªå¹³æ‰æœ€æ—©çš„ä¸€ä»½ä»“ä½ï¼Œå®ç°æ¸è¿›å¼è°ƒä»“\n",
    "                pos_to_close = active_positions.popleft()\n",
    "                exit_price = current_close\n",
    "                pnl = (exit_price - pos_to_close['entry_price']) * pos_to_close['direction'] * pos_to_close['quantity']\n",
    "                exit_commission = commission_rate * exit_price * pos_to_close['quantity']\n",
    "                net_pnl = pnl - exit_commission\n",
    "\n",
    "                realized_pnl += net_pnl\n",
    "                trades_occurred = True\n",
    "                results['transaction_costs'][i] += exit_commission\n",
    "\n",
    "                trade_history.append({\n",
    "                    'entry_time': indices[pos_to_close['entry_index']], 'exit_time': indices[i],\n",
    "                    'direction': pos_to_close['direction'], 'entry_price': pos_to_close['entry_price'],\n",
    "                    'exit_price': exit_price, 'quantity': pos_to_close['quantity'],\n",
    "                    'pnl': pnl, 'commission': exit_commission, 'net_pnl': net_pnl,\n",
    "                    'duration': i - pos_to_close['entry_index'], 'type': 'signal'\n",
    "                })\n",
    "\n",
    "                # æ›´æ–°æŒä»“çŠ¶æ€\n",
    "                if active_positions:\n",
    "                    # å¦‚æœå¹³ä»“åä»æœ‰æŒä»“ï¼Œé‡æ–°è®¡ç®—å¹³å‡æˆæœ¬\n",
    "                    total_quantity = sum(p['quantity'] for p in active_positions)\n",
    "                    total_cost = sum(p['entry_price'] * p['quantity'] for p in active_positions)\n",
    "                    position_cost = total_cost / total_quantity\n",
    "                else:\n",
    "                    # å¦‚æœæ‰€æœ‰ä»“ä½éƒ½å·²å¹³æ‰ï¼Œé‡ç½®æŒä»“çŠ¶æ€\n",
    "                    position_direction = 0\n",
    "                    position_cost = 0.0\n",
    "                results['position'][i] = position_direction\n",
    "\n",
    "        # 3. æ›´æ–°æ¯æ—¥çŠ¶æ€\n",
    "        results['position_count'][i] = len(active_positions)\n",
    "        results['cost_basis'][i] = position_cost\n",
    "        results['equity_curve'][i] = initial_capital + realized_pnl # æƒç›Šæ›²çº¿ä»…éšå·²å®ç°ç›ˆäºå˜åŒ–\n",
    "\n",
    "        # 4. è®¡ç®—å½“æ—¥å‡€æ”¶ç›Šç‡ (ä»…åœ¨æœ‰å¹³ä»“äº¤æ˜“æ—¶å‘ç”Ÿå˜åŒ–)\n",
    "        if i > 0: # ä»ç¬¬äºŒå¤©å¼€å§‹è®¡ç®—\n",
    "            prev_equity = results['equity_curve'][i-1]\n",
    "            if trades_occurred:\n",
    "                results['net_returns'][i] = (results['equity_curve'][i] - prev_equity) / prev_equity\n",
    "            # å¦‚æœæ²¡æœ‰äº¤æ˜“ï¼Œå‡€æ”¶ç›Šä¸º0ï¼Œæ•°ç»„é»˜è®¤å°±æ˜¯0ï¼Œæ— éœ€æ“ä½œ\n",
    "\n",
    "    # --- å›æµ‹æœŸæœ«å¤„ç† ---\n",
    "    # å°†æ‰€æœ‰å‰©ä½™çš„æœªå¹³ä»“å¤´å¯¸åœ¨æœ€åä¸€ä¸ªäº¤æ˜“æ—¥å¼ºåˆ¶å¹³ä»“\n",
    "    if active_positions:\n",
    "        last_close = close_arr[-1]\n",
    "        for pos in active_positions:\n",
    "            exit_price = last_close\n",
    "            pnl = (exit_price - pos['entry_price']) * pos['direction'] * pos['quantity']\n",
    "            exit_commission = commission_rate * exit_price * pos['quantity']\n",
    "            net_pnl = pnl - exit_commission\n",
    "            realized_pnl += net_pnl\n",
    "            results['transaction_costs'][-1] += exit_commission\n",
    "\n",
    "            trade_history.append({\n",
    "                'entry_time': indices[pos['entry_index']],\n",
    "                'exit_time': indices[-1],\n",
    "                'direction': pos['direction'],\n",
    "                'entry_price': pos['entry_price'],\n",
    "                'exit_price': exit_price,\n",
    "                'quantity': pos['quantity'],\n",
    "                'pnl': pnl,\n",
    "                'commission': exit_commission,\n",
    "                'net_pnl': net_pnl,\n",
    "                'duration': n - 1 - pos['entry_index'],\n",
    "                'type': 'forced_close'\n",
    "            })\n",
    "            \n",
    "        # æ›´æ–°æœ€ç»ˆçš„æƒç›Šå’Œæ”¶ç›Šç‡\n",
    "        results['equity_curve'][-1] = initial_capital + realized_pnl\n",
    "        prev_equity = results['equity_curve'][-2] if n > 1 else initial_capital\n",
    "        results['net_returns'][-1] = (results['equity_curve'][-1] - prev_equity) / prev_equity\n",
    "\n",
    "    # --- æ•´åˆç»“æœ ---\n",
    "    # ä½¿ç”¨é¢„å…ˆè®¡ç®—å¥½çš„NumPyæ•°ç»„ï¼Œä¸€æ¬¡æ€§åˆ›å»ºæœ€ç»ˆçš„DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'close': prices,\n",
    "        'signal': signals,\n",
    "        'position': results['position'],\n",
    "        'position_count': results['position_count'],\n",
    "        'cost_basis': results['cost_basis'],\n",
    "        'transaction_costs': results['transaction_costs'],\n",
    "        'net_returns': results['net_returns'],\n",
    "        'equity_curve': results['equity_curve']\n",
    "    }, index=prices.index)\n",
    "\n",
    "    logging.info(\"âœ… ä¼˜åŒ–ç‰ˆå›æµ‹å®Œæˆã€‚\")\n",
    "    return df, pd.DataFrame(trade_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "94dc0e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_realized_pnl_performance(backtest_results, trade_history, initial_capital):\n",
    "    \"\"\"\n",
    "    å…¨é¢è¯„ä¼°åŸºäºå·²å®ç°ç›ˆäºçš„ç­–ç•¥è¡¨ç°ï¼Œå¹¶ç”Ÿæˆæ ‡å‡†åŒ–æŠ¥å‘Šã€‚\n",
    "\n",
    "    å…³é”®è¯„ä¼°é€»è¾‘:\n",
    "    - **æ ‡å‡†åŒ–æŒ‡æ ‡**: å¤æ™®æ¯”ç‡ç­‰å…³é”®é£é™©æŒ‡æ ‡åŸºäºæœˆåº¦æ”¶ç›Šç‡è®¡ç®—ï¼Œä»¥æä¾›æ›´ç¨³å¥ã€æ›´å…·å¯æ¯”æ€§çš„è¯„ä¼°ã€‚\n",
    "    - **å‘é‡åŒ–è®¡ç®—**: å°½å¯èƒ½ä½¿ç”¨Pandaså’ŒNumPyçš„å‘é‡åŒ–åŠŸèƒ½ï¼Œä»¥æé«˜è®¡ç®—æ•ˆç‡ã€‚\n",
    "    - **ç²¾ç¡®äº¤æ˜“ç»Ÿè®¡**: æ‰€æœ‰äº¤æ˜“ç›¸å…³æŒ‡æ ‡ï¼ˆèƒœç‡ã€ç›ˆäºæ¯”ç­‰ï¼‰å‡åŸºäº`trade_history` DataFrameè¿›è¡Œç²¾ç¡®è®¡ç®—ã€‚\n",
    "    - **å¯è§†åŒ–æŠ¥å‘Š**: ç”Ÿæˆæ¸…æ™°çš„æƒç›Šæ›²çº¿å›¾å’Œå¤šç»´åº¦ã€æ ¼å¼åŒ–çš„æ€§èƒ½æŒ‡æ ‡è¡¨æ ¼ã€‚\n",
    "    \"\"\"\n",
    "    logging.info(\"ğŸ“Š å¼€å§‹è¿›è¡Œå…¨é¢çš„ç­–ç•¥æ€§èƒ½è¯„ä¼°...\")\n",
    "\n",
    "    df = backtest_results.copy()\n",
    "    trade_df = trade_history.copy()\n",
    "\n",
    "    # --- 1. æ ¸å¿ƒæ”¶ç›Šä¸é£é™©æŒ‡æ ‡ ---\n",
    "    final_equity = df['equity_curve'].iloc[-1]\n",
    "    total_return = (final_equity - initial_capital) / initial_capital\n",
    "\n",
    "    # å‘é‡åŒ–è®¡ç®—å›æ’¤ (Drawdown)\n",
    "    equity_curve = df['equity_curve']\n",
    "    peak = equity_curve.expanding(min_periods=1).max() # è®¡ç®—æ»šåŠ¨æœ€é«˜ç‚¹\n",
    "    drawdown = (peak - equity_curve) / peak            # è®¡ç®—å›æ’¤ç™¾åˆ†æ¯”\n",
    "    max_drawdown = drawdown.max()                      # è·å–æœ€å¤§å›æ’¤\n",
    "    \n",
    "    # æ‰¾åˆ°æœ€å¤§å›æ’¤\n",
    "    mdd_end = drawdown.idxmax() if not drawdown.empty else None # æœ€å¤§å›æ’¤ç»“æŸç‚¹\n",
    "    mdd_start = peak[:mdd_end].idxmax() if mdd_end is not None else None # æœ€å¤§å›æ’¤å¼€å§‹ç‚¹\n",
    "\n",
    "    # è®¡ç®—å¹´åŒ–æŒ‡æ ‡\n",
    "    total_days = (df.index[-1] - df.index[0]).days\n",
    "    duration_years = max(total_days / 365.25, 0.001)  # é¿å…é™¤ä»¥é›¶ï¼Œæœ€çŸ­ä¸º0.001å¹´\n",
    "    annualized_return = total_return / duration_years\n",
    "\n",
    "    # --- 2. æ ‡å‡†åŒ–é£é™©è°ƒæ•´åæ”¶ç›Š (Standardized Risk-Adjusted Metrics) ---\n",
    "    # å…³é”®ä¿®æ­£ï¼šä¸ºéµå¾ªè¡Œä¸šç¨³å¥æ ‡å‡†ï¼Œé¿å…é«˜é¢‘æ•°æ®å¯¹æŒ‡æ ‡çš„æ‰­æ›²ï¼Œ\n",
    "    # å¤æ™®æ¯”ç‡ç­‰æŒ‡æ ‡åº”åŸºäºé¢‘ç‡è¾ƒä½ï¼ˆå¦‚æœˆåº¦ï¼‰çš„æ”¶ç›Šç‡è®¡ç®—ã€‚\n",
    "    monthly_returns = df['equity_curve'].resample('M').last().pct_change().dropna()\n",
    "\n",
    "    # å¤æ™®æ¯”ç‡ (Sharpe Ratio)\n",
    "    # å…¬å¼: å¹´åŒ–(æœˆåº¦å¹³å‡æ”¶ç›Š / æœˆåº¦æ”¶ç›Šæ ‡å‡†å·®)\n",
    "    sharpe_ratio = (monthly_returns.mean() / monthly_returns.std()) * np.sqrt(12) if len(monthly_returns) > 1 else 0\n",
    "\n",
    "    # å¡ç›æ¯”ç‡ (Calmar Ratio)\n",
    "    # å…¬å¼: å¹´åŒ–æ”¶ç›Šç‡ / æœ€å¤§å›æ’¤\n",
    "    calmar_ratio = annualized_return / max_drawdown if max_drawdown > 0 else 0\n",
    "    \n",
    "    # å¹´åŒ–æ³¢åŠ¨ç‡ (åŸºäºæ—¥å‡€æ”¶ç›Šç‡è®¡ç®—)\n",
    "    annualized_volatility = df['net_returns'].std() * np.sqrt(365.25) # å‡è®¾ä¸€å¹´æœ‰365.25ä¸ªäº¤æ˜“æ—¥\n",
    "\n",
    "    # --- 3. äº¤æ˜“ç»Ÿè®¡ (åŸºäºç²¾ç¡®çš„äº¤æ˜“å†å²) ---\n",
    "    total_trades = len(trade_df)\n",
    "    if total_trades > 0:\n",
    "        winning_trades = trade_df[trade_df['net_pnl'] > 0]\n",
    "        losing_trades = trade_df[trade_df['net_pnl'] <= 0]\n",
    "\n",
    "        win_rate = len(winning_trades) / total_trades\n",
    "        # å¹³å‡ç›ˆ/äºè®¡ç®—çš„æ˜¯å åˆå§‹èµ„æœ¬çš„ç™¾åˆ†æ¯”\n",
    "        avg_win = winning_trades['net_pnl'].mean() / initial_capital if len(winning_trades) > 0 else 0\n",
    "        avg_loss = losing_trades['net_pnl'].mean() / initial_capital if len(losing_trades) > 0 else 0\n",
    "        # ç›ˆäºæ¯”\n",
    "        profit_factor = abs(winning_trades['net_pnl'].sum() / losing_trades['net_pnl'].abs().sum()) if len(losing_trades) > 0 and losing_trades['net_pnl'].abs().sum() > 0 else float('inf')\n",
    "        # æœŸæœ›æ”¶ç›Š\n",
    "        expectancy = (win_rate * avg_win) + ((1 - win_rate) * avg_loss)\n",
    "    else:\n",
    "        # å¦‚æœæ²¡æœ‰äº¤æ˜“ï¼Œæ‰€æœ‰æŒ‡æ ‡è®¾ä¸º0\n",
    "        win_rate = avg_win = avg_loss = profit_factor = expectancy = 0\n",
    "\n",
    "    # --- 4. å…¶ä»–è¾…åŠ©æŒ‡æ ‡ ---\n",
    "    # æŒä»“æ¯”ä¾‹ (å‘é‡åŒ–è®¡ç®—)\n",
    "    long_ratio = (df['position'] > 0).mean()\n",
    "    short_ratio = (df['position'] < 0).mean()\n",
    "\n",
    "    # æ¯å‘¨å¼€ä»“é¢‘ç‡\n",
    "    weekly_trades = trade_df.resample('W', on='entry_time').size().mean() if not trade_df.empty else 0\n",
    "\n",
    "    # å¹´åŒ–æ¢æ‰‹ç‡ (Annualized Turnover)\n",
    "    if total_trades > 0:\n",
    "        # åä¹‰æœ¬é‡‘ = ä»·æ ¼ * æ•°é‡\n",
    "        trade_df['entry_notional'] = trade_df['entry_price'] * trade_df['quantity']\n",
    "        trade_df['exit_notional'] = trade_df['exit_price'] * trade_df['quantity']\n",
    "        # æ€»äº¤æ˜“é¢ = (ä¹°å…¥æ€»é¢ + å–å‡ºæ€»é¢) / 2\n",
    "        total_turnover = (trade_df['entry_notional'].sum() + trade_df['exit_notional'].sum()) / 2\n",
    "        avg_net_assets = df['equity_curve'].mean()\n",
    "        # å¹´åŒ–æ¢æ‰‹ç‡ = (æ€»äº¤æ˜“é¢ / å¹³å‡å‡€èµ„äº§) / å¹´æ•°\n",
    "        annualized_turnover = (total_turnover / avg_net_assets) / duration_years\n",
    "    else:\n",
    "        annualized_turnover = 0\n",
    "\n",
    "    # ä¿¡æ¯ç³»æ•° (Information Coefficient, IC)\n",
    "    # è¡¡é‡ä¿¡å·å¯¹ä¸‹ä¸€æœŸæ”¶ç›Šçš„é¢„æµ‹èƒ½åŠ›\n",
    "    forward_returns = df['close'].pct_change().shift(-1)\n",
    "    # ç¡®ä¿ä¿¡å·å’Œæœªæ¥æ”¶ç›Šå¯¹é½ï¼Œä¸”æ— ç©ºå€¼\n",
    "    valid_idx = df['signal'].shift(1).notna() & forward_returns.notna()\n",
    "    ic = np.corrcoef(df['signal'].shift(1)[valid_idx], forward_returns[valid_idx])[0, 1]\n",
    "\n",
    "    # é€å¹´æ”¶ç›Šç‡\n",
    "    yearly_returns = []\n",
    "    for year, group in df.groupby(df.index.year):\n",
    "        if len(group) > 1:\n",
    "            start_equity = group['equity_curve'].iloc[0]\n",
    "            end_equity = group['equity_curve'].iloc[-1]\n",
    "            yearly_return = (end_equity - start_equity) / start_equity\n",
    "            yearly_returns.append((year, yearly_return))\n",
    "\n",
    "    # --- 5. åŸºå‡†è®¡ç®— ---\n",
    "    # ç†è®ºåŸºå‡†: å®Œç¾é¢„æµ‹ä¸‹çš„ç†è®ºæ”¶ç›Š (ä¿¡å· * æœªæ¥10æœŸæ”¶ç›Š)ï¼Œç”¨äºè¡¡é‡ä¿¡å·è´¨é‡\n",
    "    future_return = (df['close'].shift(-10) - df['close']) / df['close']\n",
    "    # ä¹˜ä»¥0.1æ˜¯å› ä¸ºç­–ç•¥æ¯æ¬¡åªæŠ•å…¥1/10çš„èµ„é‡‘\n",
    "    theoretical_benchmark = (df['signal'].shift(1) * future_return * 0.1).fillna(0).cumsum()\n",
    "    strategy_cumulative = (df['equity_curve'] - initial_capital) / initial_capital\n",
    "    correlation = strategy_cumulative.corr(theoretical_benchmark)\n",
    "\n",
    "    # ä¹°å…¥å¹¶æŒæœ‰åŸºå‡† (Buy & Hold)\n",
    "    buy_hold_curve = initial_capital * (df['close'] / df['close'].iloc[0])\n",
    "\n",
    "    # --- 6. ç”Ÿæˆæ ¼å¼åŒ–æŠ¥å‘Š ---\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(Fore.CYAN + Style.BRIGHT + \" \" * 30 + \"ç­–ç•¥æ€§èƒ½è¯„ä¼°æŠ¥å‘Š\" + \" \" * 30 + Style.RESET_ALL)\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(\"\\n\" + Fore.BLUE + Style.BRIGHT + \"=\"*30 + \" æ”¶ç›ŠæŒ‡æ ‡ \" + \"=\"*30 + Style.RESET_ALL)\n",
    "    detail_headers = [\"æŒ‡æ ‡åç§°\", \"è®¡ç®—ç»“æœ\", \"è¦æ±‚\", \"çŠ¶æ€\"]\n",
    "    \n",
    "    sharpe_status = \"âœ… è¾¾æ ‡\" if sharpe_ratio >= 2.0 else Fore.RED + \"âŒ æœªè¾¾æ ‡\" + Style.RESET_ALL\n",
    "    calmar_status = \"âœ… è¾¾æ ‡\" if calmar_ratio >= 5.0 else Fore.RED + \"âŒ æœªè¾¾æ ‡\" + Style.RESET_ALL\n",
    "    expectancy_status = \"âœ… è¾¾æ ‡\" if expectancy >= 0.25 else Fore.RED + \"âŒ æœªè¾¾æ ‡\" + Style.RESET_ALL\n",
    "    \n",
    "    detail_table = [\n",
    "        [\"å¤æ™®æ¯”ç‡ (Sharpe)\", f\"{sharpe_ratio:.4f}\", \"> 2.0\", sharpe_status],\n",
    "        [\"å¡ç›æ¯”ç‡ (Calmar)\", f\"{calmar_ratio:.4f}\", \"> 5.0\", calmar_status],\n",
    "        [\"æœŸæœ›æ”¶ç›Š (Expectancy)\", f\"{expectancy:.4f}\", \"> 0.25\", expectancy_status]\n",
    "    ]\n",
    "    print(tabulate(detail_table, headers=detail_headers, tablefmt=\"grid\", stralign=\"center\", numalign=\"center\"))\n",
    "    \n",
    "    print(\"\\n\" + Fore.BLUE + Style.BRIGHT + \"ç­–ç•¥æ–¹æ¡ˆè¯„ä¼°\" + Style.RESET_ALL)\n",
    "    scheme_table = [\n",
    "        [\"æ–¹æ¡ˆä¸€ (å¤æ™® & å¡ç›)\", \"âœ… è¾¾æ ‡\" if sharpe_ratio >= 2.0 and calmar_ratio >= 5.0 else Fore.RED + \"âŒ æœªè¾¾æ ‡\" + Style.RESET_ALL],\n",
    "        [\"æ–¹æ¡ˆäºŒ (æœŸæœ›æ”¶ç›Š)\", \"âœ… è¾¾æ ‡\" if expectancy >= 0.25 else Fore.RED + \"âŒ æœªè¾¾æ ‡\" + Style.RESET_ALL],\n",
    "        [\"ç»¼åˆæ”¶ç›ŠæŒ‡æ ‡\", \"âœ… è¾¾æ ‡\" if sharpe_ratio >= 2.0 and calmar_ratio >= 5.0 and expectancy >= 0.25 else Fore.RED + \"âŒ æœªè¾¾æ ‡\" + Style.RESET_ALL]\n",
    "    ]\n",
    "    print(tabulate(scheme_table, headers=[\"ç­–ç•¥æ–¹æ¡ˆ\", \"çŠ¶æ€\"], tablefmt=\"grid\", stralign=\"center\", numalign=\"center\"))\n",
    "    \n",
    "    print(\"\\n\" + Fore.BLUE + Style.BRIGHT + \"æŒä»“ç»Ÿè®¡\" + Style.RESET_ALL)\n",
    "    position_table = [\n",
    "        [\"å¤šå¤´æŒä»“å æ¯”\", f\"{long_ratio:.2%}\"],\n",
    "        [\"ç©ºå¤´æŒä»“å æ¯”\", f\"{short_ratio:.2%}\"]\n",
    "    ]\n",
    "    print(tabulate(position_table, headers=[\"æŒ‡æ ‡\", \"å€¼\"], tablefmt=\"grid\", stralign=\"center\", numalign=\"center\"))\n",
    "    \n",
    "    print(\"\\n\" + Fore.YELLOW + Style.BRIGHT + \"=\"*30 + \" é£æ§ä¸æ•ˆç‡æŒ‡æ ‡ \" + \"=\"*30 + Style.RESET_ALL)\n",
    "    risk_headers = [\"æŒ‡æ ‡åç§°\", \"è®¡ç®—ç»“æœ\", \"è¦æ±‚\", \"çŠ¶æ€\"]\n",
    "    mdd_status = \"âœ… è¾¾æ ‡\" if max_drawdown < 0.2 else Fore.RED + \"âŒ æœªè¾¾æ ‡\" + Style.RESET_ALL\n",
    "    trade_freq_status = \"âœ… è¾¾æ ‡\" if weekly_trades > 5 else Fore.RED + \"âŒ æœªè¾¾æ ‡\" + Style.RESET_ALL\n",
    "    \n",
    "    risk_table = [\n",
    "        [\"æœ€å¤§å›æ’¤ (MDD)\", f\"{max_drawdown:.3%}\", \"< 0.2\", mdd_status],\n",
    "        [\"æ¯å‘¨å¼€ä»“é¢‘ç‡\", f\"{weekly_trades:.4f}\", \"> 5\", trade_freq_status]\n",
    "    ]\n",
    "    print(tabulate(risk_table, headers=risk_headers, tablefmt=\"grid\", stralign=\"center\", numalign=\"center\"))\n",
    "    \n",
    "    print(\"\\n\" + Fore.YELLOW + Style.BRIGHT + \"ç»¼åˆæŒ‡æ ‡è¯„ä¼°\" + Style.RESET_ALL)\n",
    "    risk_summary_table = [\n",
    "        [\"ç»¼åˆé£æ§æŒ‡æ ‡\", \"âœ… è¾¾æ ‡\" if max_drawdown < 0.2 else Fore.RED + \"âŒ æœªè¾¾æ ‡\" + Style.RESET_ALL],\n",
    "        [\"ç»¼åˆæ•ˆç‡æŒ‡æ ‡\", \"âœ… è¾¾æ ‡\" if weekly_trades > 5 else Fore.RED + \"âŒ æœªè¾¾æ ‡\" + Style.RESET_ALL]\n",
    "    ]\n",
    "    print(tabulate(risk_summary_table, headers=[\"æŒ‡æ ‡\", \"çŠ¶æ€\"], tablefmt=\"grid\", stralign=\"center\", numalign=\"center\"))\n",
    "    \n",
    "    print(\"\\n\" + Fore.GREEN + Style.BRIGHT + \"=\"*30 + \" è¯¦ç»†æŒ‡æ ‡ \" + \"=\"*30 + Style.RESET_ALL)\n",
    "    detailed_headers = [\"æŒ‡æ ‡åç§°\", \"å€¼\"]\n",
    "    detailed_table = [\n",
    "        [Fore.YELLOW + \"ä¸'signal Ã— return'åŸºå‡†çš„ç›¸å…³æ€§\" + Style.RESET_ALL, f\"{correlation:.3%}\"],\n",
    "        [\"æ€»æ”¶ç›Šç‡ (Total Return)\", f\"{total_return:.3%}\"],\n",
    "        [\"å¹´åŒ–æ”¶ç›Šç‡ (Annualized Return)\", f\"{annualized_return:.3%}\"],\n",
    "        [\"å¹´åŒ–æ³¢åŠ¨ç‡ (Annualized Vol)\", f\"{annualized_volatility:.3%}\"],\n",
    "        [\"æ€»ç›ˆäº (Total PnL)\", f\"${final_equity - initial_capital:,.2f}\"],\n",
    "        [\"æ€»äº¤æ˜“ç¬”æ•° (Total Trades)\", f\"{total_trades}\"],\n",
    "        [\"ç›ˆåˆ©äº¤æ˜“ç¬”æ•° (Winning Trades)\", f\"{len(winning_trades)}\"],\n",
    "        [\"äºæŸäº¤æ˜“ç¬”æ•° (Losing Trades)\", f\"{len(losing_trades)}\"],\n",
    "        [\"èƒœç‡ (Win Rate)\", f\"{win_rate:.3%}\"],\n",
    "        [\"ç›ˆäºæ¯” (Profit Factor)\", f\"{profit_factor:.3f}\"],\n",
    "        [\"å¹³å‡ç›ˆåˆ© (Average Win)\", f\"{avg_win:.3%}\"],\n",
    "        [\"å¹³å‡äºæŸ (Average Loss)\", f\"{avg_loss:.3%}\"],\n",
    "        [\"å¹´åŒ–æ¢æ‰‹ç‡ (Annualized Turnover)\", f\"{annualized_turnover:.3%}\"],\n",
    "        [\"æœ€å¤§å›æ’¤èµ·å§‹æ—¥æœŸ\", f\"{mdd_start}\"],\n",
    "        [\"æœ€å¤§å›æ’¤ç»“æŸæ—¥æœŸ\", f\"{mdd_end}\"],\n",
    "        [\"ä¿¡æ¯ç³»æ•° (IC)\", f\"{ic:.3f}\"]\n",
    "    ]\n",
    "    print(tabulate(detailed_table, headers=detailed_headers, tablefmt=\"grid\", stralign=\"center\", numalign=\"center\"))\n",
    "    \n",
    "    print(\"\\n\" + Fore.MAGENTA + Style.BRIGHT + \"=\"*30 + \" é€å¹´æ”¶ç›Šç‡ \" + \"=\"*30 + Style.RESET_ALL)\n",
    "    yearly_table = []\n",
    "    for year, return_val in yearly_returns:\n",
    "        yearly_table.append([year, f\"{return_val:.3%}\"])\n",
    "    print(tabulate(yearly_table, headers=[\"å¹´ä»½\", \"æ”¶ç›Šç‡\"], tablefmt=\"grid\", stralign=\"center\", numalign=\"center\"))\n",
    "\n",
    "    # --- 7. ç»˜åˆ¶æƒç›Šæ›²çº¿å›¾ ---\n",
    "    fig, ax = plt.subplots(figsize=(15, 10))\n",
    "    \n",
    "    # ä»…åœ¨æœ‰äº¤æ˜“å‘ç”Ÿæ—¶ç»˜åˆ¶å‚ç›´çº¿æ¡\n",
    "    trade_dates = trade_df['exit_time'].unique()\n",
    "    trade_dates = sorted(trade_dates)\n",
    "    \n",
    "    # ç»˜åˆ¶é˜¶æ¢¯çŠ¶çš„ç­–ç•¥æƒç›Šæ›²çº¿\n",
    "    prev_equity = initial_capital\n",
    "    for date in trade_dates:\n",
    "        equity = df.loc[date, 'equity_curve']\n",
    "        # ç»˜åˆ¶æ°´å¹³çº¿ï¼ˆå‰ä¸€ç‚¹åˆ°å½“å‰ç‚¹ï¼‰\n",
    "        prev_date = df.index[df.index.get_loc(date) - 1] if date != df.index[0] else date\n",
    "        ax.hlines(y=prev_equity, xmin=prev_date, xmax=date, color='royalblue', linewidth=2)\n",
    "        # ç»˜åˆ¶å‚ç›´çº¿ï¼ˆå½“å‰ç‚¹ï¼‰\n",
    "        ax.vlines(x=date, ymin=prev_equity, ymax=equity, color='royalblue', linewidth=2)\n",
    "        prev_equity = equity\n",
    "    \n",
    "    # ç»˜åˆ¶æœ€åä¸€æ®µ\n",
    "    last_trade_date = trade_dates[-1] if trade_dates else df.index[0]\n",
    "    ax.hlines(y=prev_equity, xmin=last_trade_date, xmax=df.index[-1], color='royalblue', linewidth=2)\n",
    "    \n",
    "    # ç»˜åˆ¶ç­–ç•¥æƒç›Šæ›²çº¿ (ä½¿ç”¨é˜¶æ¢¯å›¾)\n",
    "    # é˜¶æ¢¯å›¾(step plot)èƒ½å®Œç¾å±•ç¤ºå·²å®ç°ç›ˆäºæ›²çº¿çš„ç‰¹æ€§ï¼šæƒç›Šåªåœ¨äº¤æ˜“å¹³ä»“æ—¶å‘ç”Ÿé˜¶è·ƒå¼å˜åŒ–ã€‚\n",
    "    ax.step(df.index, df['equity_curve'], where='post', label='Strategy Equity', color='royalblue', linewidth=2)\n",
    "\n",
    "    # ç»˜åˆ¶ç†è®ºåŸºå‡†æ›²çº¿\n",
    "    theoretical_curve = initial_capital * (1 + theoretical_benchmark)\n",
    "    ax.plot(df.index, theoretical_curve, label='Theoretical Benchmark (signalÃ—return)', color='purple', linestyle='--', alpha=0.7)\n",
    "\n",
    "    # ç»˜åˆ¶ä¹°å…¥å¹¶æŒæœ‰åŸºå‡†æ›²çº¿\n",
    "    ax.plot(df.index, buy_hold_curve, label='Buy & Hold BTC', color='darkorange', linestyle=':', alpha=0.7)\n",
    "\n",
    "    # è®¾ç½®å›¾è¡¨æ ‡é¢˜å’Œæ ‡ç­¾\n",
    "    ax.set_title('Strategy Equity Curve vs. Benchmarks (Realized PnL Only)', fontsize=16)\n",
    "    ax.set_xlabel('Date', fontsize=12)\n",
    "    ax.set_ylabel('Net Asset Value', fontsize=12)\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    logging.info(\"âœ… ç­–ç•¥è¯„ä¼°æŠ¥å‘Šç”Ÿæˆå®Œæ¯•ã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa116caf",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. ä¸»ç¨‹åºæ‰§è¡Œ (æ›´æ–°)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "44e9a745",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-07 22:46:27,365 - INFO - ğŸ”§ TensorFlowå·²é…ç½®ä¸ºä½¿ç”¨æœ€å¤š 16 ä¸ª intra-op æ ¸å¿ƒå’Œ 4 ä¸ª inter-op æ ¸å¿ƒã€‚\n",
      "2025-08-07 22:46:27,365 - INFO - ğŸ“‚ ä» /public/data/factor_data/BTCUSDT_15m_2020_2025_factor_data.pkl åŠ è½½å› å­æ•°æ®...\n",
      "/tmp/ipykernel_1524356/2410634353.py:44: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  factor_data = pickle.load(f)\n",
      "2025-08-07 22:46:27,449 - INFO - âœ… æ•°æ®åŠ è½½æˆåŠŸ - å½¢çŠ¶: (128448, 141)\n",
      "2025-08-07 22:46:27,450 - INFO - ğŸ“… æ—¶é—´èŒƒå›´: 2021-10-01 00:00:00 è‡³ 2025-05-30 23:45:00\n",
      "2025-08-07 22:46:27,450 - INFO - ===== å¼€å§‹æ‰§è¡Œä¸¤é˜¶æ®µå› å­ç­›é€‰æµç¨‹ =====\n",
      "2025-08-07 22:46:27,451 - INFO - --- é˜¶æ®µä¸€ï¼šåŸºäºRank ICå’ŒIRè¿›è¡Œåˆç­› (å…± 130 ä¸ªå› å­) ---\n",
      "é˜¶æ®µä¸€ç­›é€‰è¿›åº¦: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 130/130 [00:17<00:00,  7.46it/s]\n",
      "2025-08-07 22:46:44,892 - INFO - âœ… é˜¶æ®µä¸€å®Œæˆ: 35 / 130 ä¸ªå› å­é€šè¿‡åˆç­›ã€‚\n",
      "2025-08-07 22:46:44,892 - INFO - --- é˜¶æ®µäºŒï¼šåŸºäºå•å› å­å›æµ‹è¡¨ç°è¿›è¡Œç²¾ç­› (å…± 35 ä¸ªå› å­) ---\n",
      "é˜¶æ®µäºŒç­›é€‰è¿›åº¦:   0%|          | 0/35 [00:00<?, ?it/s]2025-08-07 22:46:44,899 - INFO - ğŸš€ å¼€å§‹æ‰§è¡Œä¼˜åŒ–ç‰ˆå›æµ‹ (åŸºäºå·²å®ç°ç›ˆäº)...\n",
      "2025-08-07 22:46:45,431 - INFO - âœ… ä¼˜åŒ–ç‰ˆå›æµ‹å®Œæˆã€‚\n",
      "/tmp/ipykernel_1524356/2151007373.py:21: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_returns = df['equity_curve'].resample('M').last().pct_change().dropna()\n",
      "é˜¶æ®µäºŒç­›é€‰è¿›åº¦:   3%|â–         | 1/35 [00:00<00:21,  1.59it/s]2025-08-07 22:46:45,528 - INFO - ğŸš€ å¼€å§‹æ‰§è¡Œä¼˜åŒ–ç‰ˆå›æµ‹ (åŸºäºå·²å®ç°ç›ˆäº)...\n",
      "2025-08-07 22:46:46,280 - INFO - âœ… ä¼˜åŒ–ç‰ˆå›æµ‹å®Œæˆã€‚\n",
      "/tmp/ipykernel_1524356/2151007373.py:21: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_returns = df['equity_curve'].resample('M').last().pct_change().dropna()\n",
      "é˜¶æ®µäºŒç­›é€‰è¿›åº¦:   6%|â–Œ         | 2/35 [00:01<00:26,  1.26it/s]2025-08-07 22:46:46,433 - INFO - ğŸš€ å¼€å§‹æ‰§è¡Œä¼˜åŒ–ç‰ˆå›æµ‹ (åŸºäºå·²å®ç°ç›ˆäº)...\n",
      "2025-08-07 22:46:46,599 - INFO - âœ… ä¼˜åŒ–ç‰ˆå›æµ‹å®Œæˆã€‚\n",
      "/tmp/ipykernel_1524356/2151007373.py:21: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_returns = df['equity_curve'].resample('M').last().pct_change().dropna()\n",
      "é˜¶æ®µäºŒç­›é€‰è¿›åº¦:   9%|â–Š         | 3/35 [00:01<00:16,  1.90it/s]2025-08-07 22:46:46,641 - INFO - ğŸš€ å¼€å§‹æ‰§è¡Œä¼˜åŒ–ç‰ˆå›æµ‹ (åŸºäºå·²å®ç°ç›ˆäº)...\n",
      "2025-08-07 22:46:46,746 - INFO - âœ… ä¼˜åŒ–ç‰ˆå›æµ‹å®Œæˆã€‚\n",
      "/tmp/ipykernel_1524356/2151007373.py:21: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_returns = df['equity_curve'].resample('M').last().pct_change().dropna()\n",
      "é˜¶æ®µäºŒç­›é€‰è¿›åº¦:  11%|â–ˆâ–        | 4/35 [00:01<00:11,  2.69it/s]2025-08-07 22:46:46,784 - INFO - ğŸš€ å¼€å§‹æ‰§è¡Œä¼˜åŒ–ç‰ˆå›æµ‹ (åŸºäºå·²å®ç°ç›ˆäº)...\n",
      "2025-08-07 22:46:47,070 - INFO - âœ… ä¼˜åŒ–ç‰ˆå›æµ‹å®Œæˆã€‚\n",
      "/tmp/ipykernel_1524356/2151007373.py:21: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_returns = df['equity_curve'].resample('M').last().pct_change().dropna()\n",
      "é˜¶æ®µäºŒç­›é€‰è¿›åº¦:  14%|â–ˆâ–        | 5/35 [00:02<00:10,  2.74it/s]2025-08-07 22:46:47,131 - INFO - ğŸš€ å¼€å§‹æ‰§è¡Œä¼˜åŒ–ç‰ˆå›æµ‹ (åŸºäºå·²å®ç°ç›ˆäº)...\n",
      "2025-08-07 22:46:47,350 - INFO - âœ… ä¼˜åŒ–ç‰ˆå›æµ‹å®Œæˆã€‚\n",
      "/tmp/ipykernel_1524356/2151007373.py:21: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_returns = df['equity_curve'].resample('M').last().pct_change().dropna()\n",
      "é˜¶æ®µäºŒç­›é€‰è¿›åº¦:  17%|â–ˆâ–‹        | 6/35 [00:02<00:09,  3.04it/s]2025-08-07 22:46:47,392 - INFO - ğŸš€ å¼€å§‹æ‰§è¡Œä¼˜åŒ–ç‰ˆå›æµ‹ (åŸºäºå·²å®ç°ç›ˆäº)...\n",
      "2025-08-07 22:46:47,599 - INFO - âœ… ä¼˜åŒ–ç‰ˆå›æµ‹å®Œæˆã€‚\n",
      "/tmp/ipykernel_1524356/2151007373.py:21: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_returns = df['equity_curve'].resample('M').last().pct_change().dropna()\n",
      "é˜¶æ®µäºŒç­›é€‰è¿›åº¦:  20%|â–ˆâ–ˆ        | 7/35 [00:02<00:08,  3.30it/s]2025-08-07 22:46:47,641 - INFO - ğŸš€ å¼€å§‹æ‰§è¡Œä¼˜åŒ–ç‰ˆå›æµ‹ (åŸºäºå·²å®ç°ç›ˆäº)...\n",
      "2025-08-07 22:46:48,370 - INFO - âœ… ä¼˜åŒ–ç‰ˆå›æµ‹å®Œæˆã€‚\n",
      "/tmp/ipykernel_1524356/2151007373.py:21: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_returns = df['equity_curve'].resample('M').last().pct_change().dropna()\n",
      "é˜¶æ®µäºŒç­›é€‰è¿›åº¦:  23%|â–ˆâ–ˆâ–       | 8/35 [00:03<00:13,  2.07it/s]2025-08-07 22:46:48,507 - INFO - ğŸš€ å¼€å§‹æ‰§è¡Œä¼˜åŒ–ç‰ˆå›æµ‹ (åŸºäºå·²å®ç°ç›ˆäº)...\n",
      "2025-08-07 22:46:48,595 - INFO - âœ… ä¼˜åŒ–ç‰ˆå›æµ‹å®Œæˆã€‚\n",
      "/tmp/ipykernel_1524356/2151007373.py:21: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_returns = df['equity_curve'].resample('M').last().pct_change().dropna()\n",
      "é˜¶æ®µäºŒç­›é€‰è¿›åº¦:  26%|â–ˆâ–ˆâ–Œ       | 9/35 [00:03<00:09,  2.74it/s]2025-08-07 22:46:48,614 - INFO - ğŸš€ å¼€å§‹æ‰§è¡Œä¼˜åŒ–ç‰ˆå›æµ‹ (åŸºäºå·²å®ç°ç›ˆäº)...\n",
      "2025-08-07 22:46:48,683 - INFO - âœ… ä¼˜åŒ–ç‰ˆå›æµ‹å®Œæˆã€‚\n",
      "2025-08-07 22:46:48,687 - INFO - ğŸš€ å¼€å§‹æ‰§è¡Œä¼˜åŒ–ç‰ˆå›æµ‹ (åŸºäºå·²å®ç°ç›ˆäº)...\n",
      "2025-08-07 22:46:48,919 - INFO - âœ… ä¼˜åŒ–ç‰ˆå›æµ‹å®Œæˆã€‚\n",
      "/tmp/ipykernel_1524356/2151007373.py:21: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_returns = df['equity_curve'].resample('M').last().pct_change().dropna()\n",
      "é˜¶æ®µäºŒç­›é€‰è¿›åº¦:  31%|â–ˆâ–ˆâ–ˆâ–      | 11/35 [00:04<00:06,  3.60it/s]2025-08-07 22:46:48,975 - INFO - ğŸš€ å¼€å§‹æ‰§è¡Œä¼˜åŒ–ç‰ˆå›æµ‹ (åŸºäºå·²å®ç°ç›ˆäº)...\n",
      "2025-08-07 22:46:49,045 - INFO - âœ… ä¼˜åŒ–ç‰ˆå›æµ‹å®Œæˆã€‚\n",
      "2025-08-07 22:46:49,050 - INFO - ğŸš€ å¼€å§‹æ‰§è¡Œä¼˜åŒ–ç‰ˆå›æµ‹ (åŸºäºå·²å®ç°ç›ˆäº)...\n",
      "2025-08-07 22:46:49,385 - INFO - âœ… ä¼˜åŒ–ç‰ˆå›æµ‹å®Œæˆã€‚\n",
      "/tmp/ipykernel_1524356/2151007373.py:21: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_returns = df['equity_curve'].resample('M').last().pct_change().dropna()\n",
      "é˜¶æ®µäºŒç­›é€‰è¿›åº¦:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 13/35 [00:04<00:05,  3.89it/s]2025-08-07 22:46:49,427 - INFO - ğŸš€ å¼€å§‹æ‰§è¡Œä¼˜åŒ–ç‰ˆå›æµ‹ (åŸºäºå·²å®ç°ç›ˆäº)...\n",
      "2025-08-07 22:46:49,726 - INFO - âœ… ä¼˜åŒ–ç‰ˆå›æµ‹å®Œæˆã€‚\n",
      "/tmp/ipykernel_1524356/2151007373.py:21: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_returns = df['equity_curve'].resample('M').last().pct_change().dropna()\n",
      "é˜¶æ®µäºŒç­›é€‰è¿›åº¦:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 14/35 [00:04<00:05,  3.54it/s]2025-08-07 22:46:49,799 - INFO - ğŸš€ å¼€å§‹æ‰§è¡Œä¼˜åŒ–ç‰ˆå›æµ‹ (åŸºäºå·²å®ç°ç›ˆäº)...\n",
      "2025-08-07 22:46:50,581 - INFO - âœ… ä¼˜åŒ–ç‰ˆå›æµ‹å®Œæˆã€‚\n",
      "/tmp/ipykernel_1524356/2151007373.py:21: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_returns = df['equity_curve'].resample('M').last().pct_change().dropna()\n",
      "é˜¶æ®µäºŒç­›é€‰è¿›åº¦:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 15/35 [00:05<00:08,  2.27it/s]2025-08-07 22:46:50,732 - INFO - ğŸš€ å¼€å§‹æ‰§è¡Œä¼˜åŒ–ç‰ˆå›æµ‹ (åŸºäºå·²å®ç°ç›ˆäº)...\n",
      "2025-08-07 22:46:51,537 - INFO - âœ… ä¼˜åŒ–ç‰ˆå›æµ‹å®Œæˆã€‚\n",
      "/tmp/ipykernel_1524356/2151007373.py:21: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_returns = df['equity_curve'].resample('M').last().pct_change().dropna()\n",
      "é˜¶æ®µäºŒç­›é€‰è¿›åº¦:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 16/35 [00:06<00:10,  1.74it/s]2025-08-07 22:46:51,697 - INFO - ğŸš€ å¼€å§‹æ‰§è¡Œä¼˜åŒ–ç‰ˆå›æµ‹ (åŸºäºå·²å®ç°ç›ˆäº)...\n",
      "2025-08-07 22:46:52,325 - INFO - âœ… ä¼˜åŒ–ç‰ˆå›æµ‹å®Œæˆã€‚\n",
      "/tmp/ipykernel_1524356/2151007373.py:21: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_returns = df['equity_curve'].resample('M').last().pct_change().dropna()\n",
      "é˜¶æ®µäºŒç­›é€‰è¿›åº¦:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 17/35 [00:07<00:11,  1.62it/s]2025-08-07 22:46:52,434 - INFO - ğŸš€ å¼€å§‹æ‰§è¡Œä¼˜åŒ–ç‰ˆå›æµ‹ (åŸºäºå·²å®ç°ç›ˆäº)...\n",
      "2025-08-07 22:46:53,110 - INFO - âœ… ä¼˜åŒ–ç‰ˆå›æµ‹å®Œæˆã€‚\n",
      "/tmp/ipykernel_1524356/2151007373.py:21: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_returns = df['equity_curve'].resample('M').last().pct_change().dropna()\n",
      "é˜¶æ®µäºŒç­›é€‰è¿›åº¦:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 18/35 [00:08<00:11,  1.49it/s]2025-08-07 22:46:53,249 - INFO - ğŸš€ å¼€å§‹æ‰§è¡Œä¼˜åŒ–ç‰ˆå›æµ‹ (åŸºäºå·²å®ç°ç›ˆäº)...\n",
      "2025-08-07 22:46:54,108 - INFO - âœ… ä¼˜åŒ–ç‰ˆå›æµ‹å®Œæˆã€‚\n",
      "/tmp/ipykernel_1524356/2151007373.py:21: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_returns = df['equity_curve'].resample('M').last().pct_change().dropna()\n",
      "é˜¶æ®µäºŒç­›é€‰è¿›åº¦:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 19/35 [00:09<00:12,  1.29it/s]2025-08-07 22:46:54,272 - INFO - ğŸš€ å¼€å§‹æ‰§è¡Œä¼˜åŒ–ç‰ˆå›æµ‹ (åŸºäºå·²å®ç°ç›ˆäº)...\n",
      "2025-08-07 22:46:54,918 - INFO - âœ… ä¼˜åŒ–ç‰ˆå›æµ‹å®Œæˆã€‚\n",
      "/tmp/ipykernel_1524356/2151007373.py:21: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_returns = df['equity_curve'].resample('M').last().pct_change().dropna()\n",
      "é˜¶æ®µäºŒç­›é€‰è¿›åº¦:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 20/35 [00:10<00:11,  1.30it/s]2025-08-07 22:46:55,030 - INFO - ğŸš€ å¼€å§‹æ‰§è¡Œä¼˜åŒ–ç‰ˆå›æµ‹ (åŸºäºå·²å®ç°ç›ˆäº)...\n",
      "2025-08-07 22:46:55,515 - INFO - âœ… ä¼˜åŒ–ç‰ˆå›æµ‹å®Œæˆã€‚\n",
      "/tmp/ipykernel_1524356/2151007373.py:21: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_returns = df['equity_curve'].resample('M').last().pct_change().dropna()\n",
      "é˜¶æ®µäºŒç­›é€‰è¿›åº¦:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 21/35 [00:10<00:10,  1.39it/s]2025-08-07 22:46:55,638 - INFO - ğŸš€ å¼€å§‹æ‰§è¡Œä¼˜åŒ–ç‰ˆå›æµ‹ (åŸºäºå·²å®ç°ç›ˆäº)...\n",
      "2025-08-07 22:46:56,352 - INFO - âœ… ä¼˜åŒ–ç‰ˆå›æµ‹å®Œæˆã€‚\n",
      "/tmp/ipykernel_1524356/2151007373.py:21: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_returns = df['equity_curve'].resample('M').last().pct_change().dropna()\n",
      "é˜¶æ®µäºŒç­›é€‰è¿›åº¦:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 22/35 [00:11<00:09,  1.32it/s]2025-08-07 22:46:56,491 - INFO - ğŸš€ å¼€å§‹æ‰§è¡Œä¼˜åŒ–ç‰ˆå›æµ‹ (åŸºäºå·²å®ç°ç›ˆäº)...\n",
      "2025-08-07 22:46:57,258 - INFO - âœ… ä¼˜åŒ–ç‰ˆå›æµ‹å®Œæˆã€‚\n",
      "/tmp/ipykernel_1524356/2151007373.py:21: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_returns = df['equity_curve'].resample('M').last().pct_change().dropna()\n",
      "é˜¶æ®µäºŒç­›é€‰è¿›åº¦:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 23/35 [00:12<00:09,  1.24it/s]2025-08-07 22:46:57,414 - INFO - ğŸš€ å¼€å§‹æ‰§è¡Œä¼˜åŒ–ç‰ˆå›æµ‹ (åŸºäºå·²å®ç°ç›ˆäº)...\n",
      "2025-08-07 22:46:58,379 - INFO - âœ… ä¼˜åŒ–ç‰ˆå›æµ‹å®Œæˆã€‚\n",
      "/tmp/ipykernel_1524356/2151007373.py:21: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_returns = df['equity_curve'].resample('M').last().pct_change().dropna()\n",
      "é˜¶æ®µäºŒç­›é€‰è¿›åº¦:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 24/35 [00:13<00:09,  1.11it/s]2025-08-07 22:46:58,528 - INFO - ğŸš€ å¼€å§‹æ‰§è¡Œä¼˜åŒ–ç‰ˆå›æµ‹ (åŸºäºå·²å®ç°ç›ˆäº)...\n",
      "2025-08-07 22:46:59,080 - INFO - âœ… ä¼˜åŒ–ç‰ˆå›æµ‹å®Œæˆã€‚\n",
      "/tmp/ipykernel_1524356/2151007373.py:21: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_returns = df['equity_curve'].resample('M').last().pct_change().dropna()\n",
      "é˜¶æ®µäºŒç­›é€‰è¿›åº¦:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 25/35 [00:14<00:08,  1.19it/s]2025-08-07 22:46:59,223 - INFO - ğŸš€ å¼€å§‹æ‰§è¡Œä¼˜åŒ–ç‰ˆå›æµ‹ (åŸºäºå·²å®ç°ç›ˆäº)...\n",
      "2025-08-07 22:46:59,865 - INFO - âœ… ä¼˜åŒ–ç‰ˆå›æµ‹å®Œæˆã€‚\n",
      "/tmp/ipykernel_1524356/2151007373.py:21: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_returns = df['equity_curve'].resample('M').last().pct_change().dropna()\n",
      "é˜¶æ®µäºŒç­›é€‰è¿›åº¦:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 26/35 [00:15<00:07,  1.22it/s]2025-08-07 22:46:59,987 - INFO - ğŸš€ å¼€å§‹æ‰§è¡Œä¼˜åŒ–ç‰ˆå›æµ‹ (åŸºäºå·²å®ç°ç›ˆäº)...\n",
      "2025-08-07 22:47:00,790 - INFO - âœ… ä¼˜åŒ–ç‰ˆå›æµ‹å®Œæˆã€‚\n",
      "/tmp/ipykernel_1524356/2151007373.py:21: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_returns = df['equity_curve'].resample('M').last().pct_change().dropna()\n",
      "é˜¶æ®µäºŒç­›é€‰è¿›åº¦:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 27/35 [00:16<00:06,  1.17it/s]2025-08-07 22:47:00,942 - INFO - ğŸš€ å¼€å§‹æ‰§è¡Œä¼˜åŒ–ç‰ˆå›æµ‹ (åŸºäºå·²å®ç°ç›ˆäº)...\n",
      "2025-08-07 22:47:01,568 - INFO - âœ… ä¼˜åŒ–ç‰ˆå›æµ‹å®Œæˆã€‚\n",
      "/tmp/ipykernel_1524356/2151007373.py:21: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_returns = df['equity_curve'].resample('M').last().pct_change().dropna()\n",
      "é˜¶æ®µäºŒç­›é€‰è¿›åº¦:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 28/35 [00:16<00:05,  1.22it/s]2025-08-07 22:47:01,679 - INFO - ğŸš€ å¼€å§‹æ‰§è¡Œä¼˜åŒ–ç‰ˆå›æµ‹ (åŸºäºå·²å®ç°ç›ˆäº)...\n",
      "2025-08-07 22:47:02,336 - INFO - âœ… ä¼˜åŒ–ç‰ˆå›æµ‹å®Œæˆã€‚\n",
      "/tmp/ipykernel_1524356/2151007373.py:21: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_returns = df['equity_curve'].resample('M').last().pct_change().dropna()\n",
      "é˜¶æ®µäºŒç­›é€‰è¿›åº¦:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 29/35 [00:17<00:04,  1.24it/s]2025-08-07 22:47:02,454 - INFO - ğŸš€ å¼€å§‹æ‰§è¡Œä¼˜åŒ–ç‰ˆå›æµ‹ (åŸºäºå·²å®ç°ç›ˆäº)...\n",
      "2025-08-07 22:47:03,102 - INFO - âœ… ä¼˜åŒ–ç‰ˆå›æµ‹å®Œæˆã€‚\n",
      "/tmp/ipykernel_1524356/2151007373.py:21: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_returns = df['equity_curve'].resample('M').last().pct_change().dropna()\n",
      "é˜¶æ®µäºŒç­›é€‰è¿›åº¦:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 30/35 [00:18<00:03,  1.26it/s]2025-08-07 22:47:03,222 - INFO - ğŸš€ å¼€å§‹æ‰§è¡Œä¼˜åŒ–ç‰ˆå›æµ‹ (åŸºäºå·²å®ç°ç›ˆäº)...\n",
      "2025-08-07 22:47:04,045 - INFO - âœ… ä¼˜åŒ–ç‰ˆå›æµ‹å®Œæˆã€‚\n",
      "/tmp/ipykernel_1524356/2151007373.py:21: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_returns = df['equity_curve'].resample('M').last().pct_change().dropna()\n",
      "é˜¶æ®µäºŒç­›é€‰è¿›åº¦:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 31/35 [00:19<00:03,  1.17it/s]2025-08-07 22:47:04,205 - INFO - ğŸš€ å¼€å§‹æ‰§è¡Œä¼˜åŒ–ç‰ˆå›æµ‹ (åŸºäºå·²å®ç°ç›ˆäº)...\n",
      "2025-08-07 22:47:05,153 - INFO - âœ… ä¼˜åŒ–ç‰ˆå›æµ‹å®Œæˆã€‚\n",
      "/tmp/ipykernel_1524356/2151007373.py:21: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_returns = df['equity_curve'].resample('M').last().pct_change().dropna()\n",
      "é˜¶æ®µäºŒç­›é€‰è¿›åº¦:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 32/35 [00:20<00:02,  1.07it/s]2025-08-07 22:47:05,346 - INFO - ğŸš€ å¼€å§‹æ‰§è¡Œä¼˜åŒ–ç‰ˆå›æµ‹ (åŸºäºå·²å®ç°ç›ˆäº)...\n",
      "2025-08-07 22:47:06,201 - INFO - âœ… ä¼˜åŒ–ç‰ˆå›æµ‹å®Œæˆã€‚\n",
      "/tmp/ipykernel_1524356/2151007373.py:21: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_returns = df['equity_curve'].resample('M').last().pct_change().dropna()\n",
      "é˜¶æ®µäºŒç­›é€‰è¿›åº¦:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 33/35 [00:21<00:01,  1.04it/s]2025-08-07 22:47:06,370 - INFO - ğŸš€ å¼€å§‹æ‰§è¡Œä¼˜åŒ–ç‰ˆå›æµ‹ (åŸºäºå·²å®ç°ç›ˆäº)...\n",
      "2025-08-07 22:47:07,195 - INFO - âœ… ä¼˜åŒ–ç‰ˆå›æµ‹å®Œæˆã€‚\n",
      "/tmp/ipykernel_1524356/2151007373.py:21: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_returns = df['equity_curve'].resample('M').last().pct_change().dropna()\n",
      "é˜¶æ®µäºŒç­›é€‰è¿›åº¦:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 34/35 [00:22<00:00,  1.03it/s]2025-08-07 22:47:07,353 - INFO - ğŸš€ å¼€å§‹æ‰§è¡Œä¼˜åŒ–ç‰ˆå›æµ‹ (åŸºäºå·²å®ç°ç›ˆäº)...\n",
      "2025-08-07 22:47:08,175 - INFO - âœ… ä¼˜åŒ–ç‰ˆå›æµ‹å®Œæˆã€‚\n",
      "/tmp/ipykernel_1524356/2151007373.py:21: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_returns = df['equity_curve'].resample('M').last().pct_change().dropna()\n",
      "é˜¶æ®µäºŒç­›é€‰è¿›åº¦: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:23<00:00,  1.49it/s]\n",
      "2025-08-07 22:47:08,337 - INFO - âœ… é˜¶æ®µäºŒå®Œæˆ: 0 / 35 ä¸ªå› å­é€šè¿‡ç²¾ç­›ã€‚\n",
      "2025-08-07 22:47:08,338 - INFO - ===== å› å­ç­›é€‰æµç¨‹ç»“æŸ =====\n",
      "2025-08-07 22:47:08,339 - ERROR - âŒ æ²¡æœ‰ä»»ä½•å› å­é€šè¿‡ç­›é€‰ï¼Œæ— æ³•ç»§ç»­è®­ç»ƒæ¨¡å‹ã€‚è¯·æ£€æŸ¥å› å­è´¨é‡æˆ–æ”¾å®½ç­›é€‰æ ‡å‡†ã€‚\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # --- 0. CPUæ ¸å¿ƒæ•°é…ç½® ---\n",
    "    NUM_THREADS = 16\n",
    "    tf.config.threading.set_intra_op_parallelism_threads(NUM_THREADS)\n",
    "    tf.config.threading.set_inter_op_parallelism_threads(4)\n",
    "    logging.info(f\"ğŸ”§ TensorFlowå·²é…ç½®ä¸ºä½¿ç”¨æœ€å¤š {NUM_THREADS} ä¸ª intra-op æ ¸å¿ƒå’Œ 4 ä¸ª inter-op æ ¸å¿ƒã€‚\")\n",
    "\n",
    "    # --- 1. å‚æ•°é…ç½® ---\n",
    "    FACTOR_FILE = '/public/data/factor_data/BTCUSDT_15m_2020_2025_factor_data.pkl'\n",
    "    \n",
    "    # å›æµ‹æ ¸å¿ƒå‚æ•°\n",
    "    COMMISSION_RATE = 0.0002\n",
    "    INITIAL_CAPITAL = 100000\n",
    "    HOLDING_PERIOD = 10\n",
    "    \n",
    "    # ConvLSTMæ¨¡å‹å‚æ•°\n",
    "    LOOKBACK_PERIOD = 60\n",
    "    N_SPLITS = 5\n",
    "\n",
    "    # --- NEW: å› å­ç­›é€‰æµç¨‹é…ç½® ---\n",
    "    # å°†æ‰€æœ‰ç­›é€‰é˜ˆå€¼é›†ä¸­åœ¨æ­¤å¤„ï¼Œæ–¹ä¾¿ç»Ÿä¸€ç®¡ç†å’Œè°ƒæ•´\n",
    "    SCREENING_CONFIG = {\n",
    "        # å›æµ‹å‚æ•° (ä¸ä¸»æµç¨‹ä¸€è‡´)\n",
    "        'initial_capital': INITIAL_CAPITAL,\n",
    "        'commission_rate': COMMISSION_RATE,\n",
    "        'holding_period': HOLDING_PERIOD,\n",
    "        \n",
    "        # é˜¶æ®µä¸€: è´¨é‡æŒ‡æ ‡é˜ˆå€¼\n",
    "        'rank_ic_threshold': 0.01, # Rank IC ç»å¯¹å€¼\n",
    "        'ir_threshold': 0.3,       # IR ç»å¯¹å€¼\n",
    "        \n",
    "        # é˜¶æ®µäºŒ: å›æµ‹è¡¨ç°é˜ˆå€¼\n",
    "        'sharpe_threshold': 2.0,\n",
    "        'calmar_threshold': 5.0,\n",
    "        'expectancy_threshold': 0.25,\n",
    "        'mdd_threshold': 0.20, # æœ€å¤§å›æ’¤ < 20%\n",
    "        'weekly_trades_threshold': 5\n",
    "    }\n",
    "\n",
    "    # --- 2. åŠ è½½å› å­æ•°æ® ---\n",
    "    logging.info(f\"ğŸ“‚ ä» {FACTOR_FILE} åŠ è½½å› å­æ•°æ®...\")\n",
    "    try:\n",
    "        with open(FACTOR_FILE, 'rb') as f:\n",
    "            factor_data = pickle.load(f)\n",
    "        factor_data.index = pd.to_datetime(factor_data.index)\n",
    "        close_prices = factor_data['close'].copy()\n",
    "        logging.info(f\"âœ… æ•°æ®åŠ è½½æˆåŠŸ - å½¢çŠ¶: {factor_data.shape}\")\n",
    "        logging.info(f\"ğŸ“… æ—¶é—´èŒƒå›´: {factor_data.index[0]} è‡³ {factor_data.index[-1]}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"âŒ åŠ è½½æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}\")\n",
    "        factor_data = None\n",
    "\n",
    "    # --- 3. æ•´åˆäº†å› å­ç­›é€‰çš„å®Œæ•´é€»è¾‘æµ ---\n",
    "    if factor_data is not None:\n",
    "        # 3.1 --- NEW: æ‰§è¡Œä¸¤é˜¶æ®µå› å­ç­›é€‰ ---\n",
    "        selected_factors = screen_factors_sequentially(factor_data, SCREENING_CONFIG)\n",
    "        \n",
    "        if not selected_factors:\n",
    "            logging.error(\"âŒ æ²¡æœ‰ä»»ä½•å› å­é€šè¿‡ç­›é€‰ï¼Œæ— æ³•ç»§ç»­è®­ç»ƒæ¨¡å‹ã€‚è¯·æ£€æŸ¥å› å­è´¨é‡æˆ–æ”¾å®½ç­›é€‰æ ‡å‡†ã€‚\")\n",
    "        else:\n",
    "            logging.info(f\"ğŸ‰ æœ€ç»ˆé€‰å®šçš„ç²¾è‹±å› å­åˆ—è¡¨ ({len(selected_factors)}ä¸ª): {selected_factors}\")\n",
    "            \n",
    "            try:\n",
    "                # 3.2 --- MODIFIED: ä½¿ç”¨ç­›é€‰åçš„å› å­å‡†å¤‡æ•°æ® ---\n",
    "                X, y, indices, pca, selector = prepare_rolling_data(\n",
    "                    factor_data, \n",
    "                    selected_features=selected_factors, \n",
    "                    lookback=LOOKBACK_PERIOD\n",
    "                )\n",
    "                \n",
    "                # 3.3 æ‰§è¡Œæ»šåŠ¨è®­ç»ƒå¹¶ç”Ÿæˆæœ€ç»ˆæ¨¡å‹ä¿¡å·\n",
    "                signals = rolling_train_and_predict(X, y, indices, lookback=LOOKBACK_PERIOD, n_splits=N_SPLITS)\n",
    "                \n",
    "                # 3.4 åˆ›å»ºä¸åŸå§‹æ•°æ®å¯¹é½çš„å®Œæ•´ä¿¡å·åºåˆ—\n",
    "                full_signals = pd.Series(0, index=factor_data.index)\n",
    "                full_signals.loc[signals.index] = signals\n",
    "                \n",
    "                # 3.5 å¯¹æœ€ç»ˆæ¨¡å‹è¿›è¡Œå›æµ‹ä¸è¯„ä¼°\n",
    "                logging.info(\"âœ… æœ€ç»ˆæ¨¡å‹ä¿¡å·ç”Ÿæˆå®Œæ¯•ï¼Œå¼€å§‹è¿›è¡Œæœ€ç»ˆå›æµ‹ä¸è¯„ä¼°...\")\n",
    "                \n",
    "                backtest_results, trade_history = run_realized_pnl_backtest(\n",
    "                    prices=close_prices,\n",
    "                    signals=full_signals,\n",
    "                    initial_capital=INITIAL_CAPITAL,\n",
    "                    commission_rate=COMMISSION_RATE,\n",
    "                    holding_period=HOLDING_PERIOD\n",
    "                )\n",
    "\n",
    "                evaluate_realized_pnl_performance(\n",
    "                    backtest_results,\n",
    "                    trade_history,\n",
    "                    INITIAL_CAPITAL\n",
    "                )\n",
    "            except Exception as e:\n",
    "                logging.error(f\"âŒ åœ¨æ¨¡å‹è®­ç»ƒæˆ–æœ€ç»ˆå›æµ‹è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}\", exc_info=True)\n",
    "\n",
    "    else:\n",
    "        logging.warning(\"âš ï¸ ç”±äºæ•°æ®åŠ è½½å¤±è´¥ï¼Œè·³è¿‡æ‰€æœ‰åç»­æ­¥éª¤ã€‚\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor_flow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
