{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "000141cc",
   "metadata": {},
   "source": [
    "# é‡åŒ–ç­–ç•¥å›æµ‹æ¡†æ¶ - ConvLSTMæ¨¡å‹é›†æˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "733e7c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- å¿…è¦çš„åº“å¯¼å…¥ ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import logging\n",
    "from pandas.tseries.offsets import Week\n",
    "from tabulate import tabulate\n",
    "from colorama import Fore, Style, Back\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from collections import deque\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Conv1D, LSTM, Dense, Dropout, BatchNormalization, Flatten, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import classification_report\n",
    "import gc  # ç”¨äºå†…å­˜ç®¡ç†\n",
    "\n",
    "# å¿½ç•¥Pandasåœ¨ç‰¹å®šæ“ä½œä¸­å¯èƒ½äº§ç”Ÿçš„æ— å®³è­¦å‘Š\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# é…ç½®æ—¥å¿—è¾“å‡ºæ ¼å¼\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# è®¾ç½®ç»˜å›¾é£æ ¼\n",
    "plt.style.use('seaborn-v0_8-darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a587b5",
   "metadata": {},
   "source": [
    "---\n",
    "## ConvLSTMæ¨¡å‹æ„å»ºä¸è®­ç»ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62cf9228",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_conv_lstm_model(input_shape, num_features):\n",
    "    \"\"\"\n",
    "    æ„å»ºConvLSTMæ··åˆæ¨¡å‹æ¶æ„\n",
    "    \n",
    "    æ¨¡å‹è®¾è®¡ç†å¿µ:\n",
    "    1. ä½¿ç”¨1Då·ç§¯å±‚æå–å±€éƒ¨ç‰¹å¾æ¨¡å¼\n",
    "    2. LSTMå±‚æ•æ‰æ—¶é—´åºåˆ—ä¾èµ–å…³ç³»\n",
    "    3. æ·±åº¦æ®‹å·®è¿æ¥å¢å¼ºä¿¡æ¯æµåŠ¨\n",
    "    4. æ‰¹å½’ä¸€åŒ–å’ŒDropoutæé«˜æ³›åŒ–èƒ½åŠ›\n",
    "    \n",
    "    å‚æ•°:\n",
    "    - input_shape: è¾“å…¥æ•°æ®å½¢çŠ¶ (æ—¶é—´æ­¥é•¿, ç‰¹å¾æ•°)\n",
    "    - num_features: ç‰¹å¾æ•°é‡\n",
    "    \n",
    "    è¿”å›:\n",
    "    - ç¼–è¯‘å¥½çš„Kerasæ¨¡å‹\n",
    "    \"\"\"\n",
    "    # è¾“å…¥å±‚\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # 1Då·ç§¯åˆ†æ”¯ - æå–å±€éƒ¨ç‰¹å¾\n",
    "    conv1 = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Dropout(0.2)(conv1)\n",
    "    \n",
    "    conv2 = Conv1D(filters=128, kernel_size=5, activation='relu', padding='same')(conv1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Dropout(0.2)(conv2)\n",
    "    \n",
    "    # LSTMåˆ†æ”¯ - æ•æ‰æ—¶åºä¾èµ–\n",
    "    lstm1 = LSTM(64, return_sequences=True)(inputs)\n",
    "    lstm1 = BatchNormalization()(lstm1)\n",
    "    lstm1 = Dropout(0.2)(lstm1)\n",
    "    \n",
    "    lstm2 = LSTM(128, return_sequences=False)(lstm1)\n",
    "    lstm2 = BatchNormalization()(lstm2)\n",
    "    lstm2 = Dropout(0.3)(lstm2)\n",
    "    \n",
    "    # åˆå¹¶åˆ†æ”¯\n",
    "    merged = concatenate([Flatten()(conv2), lstm2])\n",
    "    \n",
    "    # å…¨è¿æ¥å±‚\n",
    "    dense1 = Dense(256, activation='relu')(merged)\n",
    "    dense1 = BatchNormalization()(dense1)\n",
    "    dense1 = Dropout(0.4)(dense1)\n",
    "    \n",
    "    dense2 = Dense(128, activation='relu')(dense1)\n",
    "    dense2 = BatchNormalization()(dense2)\n",
    "    dense2 = Dropout(0.3)(dense2)\n",
    "    \n",
    "    # è¾“å‡ºå±‚ - ä¸‰åˆ†ç±»(åšå¤š/åšç©º/ä¸­æ€§)\n",
    "    outputs = Dense(3, activation='softmax')(dense2)\n",
    "    \n",
    "    # åˆ›å»ºæ¨¡å‹\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # ç¼–è¯‘æ¨¡å‹\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "084031ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_rolling_data(factor_data, lookback=60, test_size=0.2):\n",
    "    \"\"\"\n",
    "    å‡†å¤‡æ»šåŠ¨è®­ç»ƒæ•°æ®\n",
    "    \n",
    "    å‚æ•°:\n",
    "    - factor_data: å› å­æ•°æ®DataFrame\n",
    "    - lookback: å›çœ‹æ—¶é—´æ­¥é•¿\n",
    "    - test_size: æµ‹è¯•é›†æ¯”ä¾‹ï¼ˆç”¨äºéªŒè¯ï¼‰\n",
    "    \n",
    "    è¿”å›:\n",
    "    - ç‰¹å¾ã€æ ‡ç­¾å’Œæ ‡å‡†åŒ–å™¨\n",
    "    \"\"\"\n",
    "    logging.info(\"ğŸ“Š å‡†å¤‡æ»šåŠ¨è®­ç»ƒæ•°æ®...\")\n",
    "    \n",
    "    # æå–ç‰¹å¾å’Œç›®æ ‡\n",
    "    feature_columns = [col for col in factor_data.columns \n",
    "                      if col.startswith('c_chu') or col.startswith('c_hide')]\n",
    "    \n",
    "    logging.info(f\"âœ… ä½¿ç”¨ {len(feature_columns)} ä¸ªå› å­ç‰¹å¾\")\n",
    "    \n",
    "    # ç‰¹å¾é¢„å¤„ç† - å¡«å……ç¼ºå¤±å€¼\n",
    "    features = factor_data[feature_columns].values\n",
    "    \n",
    "    # åˆ›å»ºç›®æ ‡å˜é‡ - æœªæ¥10æœŸæ”¶ç›Šç‡æ–¹å‘\n",
    "    future_returns = factor_data['close'].pct_change(10).shift(-10)\n",
    "    y = np.zeros(len(future_returns))\n",
    "    \n",
    "    # åˆ†ç±»æ ‡ç­¾: 1(åšå¤š), -1(åšç©º), 0(ä¸­æ€§)\n",
    "    y[future_returns > 0.005] = 1    # æ˜¾è‘—ä¸Šæ¶¨\n",
    "    y[future_returns < -0.005] = 2   # æ˜¾è‘—ä¸‹è·Œ\n",
    "    y = tf.keras.utils.to_categorical(y, num_classes=3)\n",
    "    \n",
    "    # åˆ›å»ºæ—¶é—´åºåˆ—æ ·æœ¬\n",
    "    X = []\n",
    "    valid_indices = []\n",
    "    \n",
    "    for i in range(lookback, len(features)):\n",
    "        X.append(features[i-lookback:i])\n",
    "        valid_indices.append(i)\n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = y[valid_indices]\n",
    "    indices = factor_data.index[valid_indices]\n",
    "    \n",
    "    logging.info(f\"âœ… æ•°æ®å‡†å¤‡å®Œæˆ - æ ·æœ¬æ•°: {X.shape[0]}, æ—¶é—´æ­¥é•¿: {X.shape[1]}, ç‰¹å¾æ•°: {X.shape[2]}\")\n",
    "    return X, y, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f69690be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_train_and_predict(X, y, indices, lookback=60, n_splits=5):\n",
    "    \"\"\"\n",
    "    æ‰§è¡Œæ»šåŠ¨è®­ç»ƒå’Œé¢„æµ‹\n",
    "    \n",
    "    å‚æ•°:\n",
    "    - X: ç‰¹å¾æ•°æ®\n",
    "    - y: æ ‡ç­¾æ•°æ®\n",
    "    - indices: æ—¶é—´ç´¢å¼•\n",
    "    - lookback: å›çœ‹æ—¶é—´æ­¥é•¿\n",
    "    - n_splits: æ—¶é—´åºåˆ—åˆ†å‰²æ•°\n",
    "    \n",
    "    è¿”å›:\n",
    "    - é¢„æµ‹ä¿¡å·Series\n",
    "    \"\"\"\n",
    "    logging.info(f\"ğŸš€ å¼€å§‹æ»šåŠ¨è®­ç»ƒ (n_splits={n_splits})...\")\n",
    "    \n",
    "    # åˆå§‹åŒ–é¢„æµ‹ç»“æœæ•°ç»„\n",
    "    all_predictions = np.zeros((len(y), 3))\n",
    "    \n",
    "    # åˆ›å»ºæ—¶é—´åºåˆ—äº¤å‰éªŒè¯å™¨\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    \n",
    "    # ç”¨äºå­˜å‚¨æ¯ä¸ªæŠ˜å çš„æ€§èƒ½\n",
    "    fold_accuracies = []\n",
    "    fold_losses = []\n",
    "    \n",
    "    for fold, (train_index, test_index) in enumerate(tscv.split(X)):\n",
    "        logging.info(f\"\\nğŸ” å¤„ç†æŠ˜å  {fold+1}/{n_splits}\")\n",
    "        logging.info(f\"  è®­ç»ƒé›†: {indices[train_index[0]]} åˆ° {indices[train_index[-1]]}\")\n",
    "        logging.info(f\"  æµ‹è¯•é›†: {indices[test_index[0]]} åˆ° {indices[test_index[-1]]}\")\n",
    "        \n",
    "        # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # æ ‡å‡†åŒ– - ä½¿ç”¨è®­ç»ƒé›†çš„ç»Ÿè®¡é‡\n",
    "        scaler = StandardScaler()\n",
    "        X_train_2d = X_train.reshape(-1, X_train.shape[-1])\n",
    "        X_test_2d = X_test.reshape(-1, X_test.shape[-1])\n",
    "        \n",
    "        scaler.fit(X_train_2d)\n",
    "        X_train_scaled = scaler.transform(X_train_2d).reshape(X_train.shape)\n",
    "        X_test_scaled = scaler.transform(X_test_2d).reshape(X_test.shape)\n",
    "        \n",
    "        # æ„å»ºæ¨¡å‹\n",
    "        model = build_conv_lstm_model((lookback, X_train.shape[2]), X_train.shape[2])\n",
    "        \n",
    "        # å›è°ƒå‡½æ•°\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
    "        ]\n",
    "        \n",
    "        # è®­ç»ƒæ¨¡å‹\n",
    "        history = model.fit(\n",
    "            X_train_scaled, y_train,\n",
    "            epochs=30,\n",
    "            batch_size=512,\n",
    "            validation_data=(X_test_scaled, y_test),\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # åœ¨æµ‹è¯•é›†ä¸Šé¢„æµ‹\n",
    "        test_pred = model.predict(X_test_scaled, batch_size=1024, verbose=0)\n",
    "        all_predictions[test_index] = test_pred\n",
    "        \n",
    "        # è¯„ä¼°æ€§èƒ½\n",
    "        test_loss, test_acc = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "        fold_accuracies.append(test_acc)\n",
    "        fold_losses.append(test_loss)\n",
    "        logging.info(f\"  æµ‹è¯•å‡†ç¡®ç‡: {test_acc:.4f}, æµ‹è¯•æŸå¤±: {test_loss:.4f}\")\n",
    "        \n",
    "        # æ¸…ç†å†…å­˜\n",
    "        del model, X_train, X_test, y_train, y_test\n",
    "        gc.collect()\n",
    "        tf.keras.backend.clear_session()\n",
    "    \n",
    "    # æ‰“å°æ•´ä½“æ€§èƒ½\n",
    "    logging.info(f\"\\nâœ… æ»šåŠ¨è®­ç»ƒå®Œæˆ - å¹³å‡å‡†ç¡®ç‡: {np.mean(fold_accuracies):.4f}, å¹³å‡æŸå¤±: {np.mean(fold_losses):.4f}\")\n",
    "    \n",
    "    # è½¬æ¢é¢„æµ‹ç»“æœä¸ºä¿¡å·\n",
    "    signal_labels = np.argmax(all_predictions, axis=1)\n",
    "    signals = np.zeros(len(indices))\n",
    "    signals = np.where(signal_labels == 1, 1, np.where(signal_labels == 2, -1, 0))\n",
    "    \n",
    "    # åˆ›å»ºä¿¡å·Serieså¹¶è®¾ç½®ç´¢å¼•\n",
    "    signal_series = pd.Series(signals, index=indices)\n",
    "    \n",
    "    # å¹³æ»‘ä¿¡å· - é¿å…é¢‘ç¹å˜åŠ¨\n",
    "    signal_series = signal_series.rolling(window=4, min_periods=1).mean()\n",
    "    signal_series = pd.Series(\n",
    "        np.where(signal_series > 0.33, 1, np.where(signal_series < -0.33, -1, 0)),\n",
    "        index=indices\n",
    "    )\n",
    "    \n",
    "    logging.info(f\"ğŸ“¡ ä¿¡å·ç”Ÿæˆå®Œæˆ - åšå¤šæ¯”ä¾‹: {(signal_series == 1).mean():.2%}, \"\n",
    "                 f\"åšç©ºæ¯”ä¾‹: {(signal_series == -1).mean():.2%}\")\n",
    "    \n",
    "    return signal_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63784ec",
   "metadata": {},
   "source": [
    "## 2. æ ¸å¿ƒå›æµ‹ä¸è¯„ä¼°å‡½æ•° (ä¿æŒä¸å˜)\n",
    "(æ­¤å¤„ä¿ç•™åŸæœ‰çš„run_realized_pnl_backtestå’Œevaluate_realized_pnl_performanceå‡½æ•°)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f3d8a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_realized_pnl_backtest(prices, signals, initial_capital=100000, commission_rate=0.0002, holding_period=10):\n",
    "    \"\"\"\n",
    "    æ‰§è¡ŒåŸºäºå·²å®ç°ç›ˆäºçš„é«˜æ€§èƒ½å›æµ‹ã€‚\n",
    "\n",
    "    æœ¬å‡½æ•°ä¸ºå›æµ‹æ¡†æ¶çš„æ ¸å¿ƒï¼Œå…¶è®¾è®¡ä¸¥æ ¼éµå¾ªä»¥ä¸‹äº¤æ˜“é€»è¾‘ï¼š\n",
    "    1. **èµ„é‡‘ç®¡ç†**: åˆå§‹èµ„é‡‘è¢«ç­‰åˆ†ä¸º10ä»½ï¼Œæ¯æ¬¡å¼€ä»“ä½¿ç”¨ä¸€ä»½ï¼Œç”¨äºæ¨¡æ‹Ÿåˆ†æ‰¹å»ºä»“ã€‚\n",
    "    2. **å•å‘æŒä»“**: åœ¨ä»»ä½•æ—¶é—´ç‚¹ï¼Œæ‰€æœ‰æŒä»“çš„æ–¹å‘å¿…é¡»ä¸€è‡´ï¼ˆå…¨ä¸ºå¤šå¤´æˆ–å…¨ä¸ºç©ºå¤´ï¼‰ï¼Œä¸å…è®¸é”ä»“æˆ–åŒæ—¶æŒæœ‰å¤šç©ºã€‚\n",
    "    3. **äº‹ä»¶é©±åŠ¨**: äº¤æ˜“ä¿¡å·åœ¨t-1æ—¶åˆ»äº§ç”Ÿï¼Œåœ¨tæ—¶åˆ»æ‰§è¡Œã€‚\n",
    "    4. **å›ºå®šæŒæœ‰æœŸ**: æ¯ä»½ç‹¬ç«‹çš„ä»“ä½æœ€å¤šæŒæœ‰`holding_period`ä¸ªå‘¨æœŸï¼Œåˆ°æœŸåè‡ªåŠ¨å¹³ä»“ã€‚\n",
    "    5. **æ¸è¿›å¼è°ƒä»“**: å½“æ”¶åˆ°ä¸å½“å‰æŒä»“æ–¹å‘ç›¸åçš„ä¿¡å·æ—¶ï¼Œä»…å¹³æ‰**æœ€æ—©å¼€ç«‹**çš„ä¸€ä»½ä»“ä½ï¼Œè€Œéå…¨éƒ¨å¹³ä»“ï¼Œä»¥å®ç°æ›´å¹³æ»‘çš„è°ƒä»“ï¼Œå‡å°‘äº¤æ˜“å†²å‡»ã€‚\n",
    "    6. **å·²å®ç°ç›ˆäº**: æƒç›Šæ›²çº¿çš„è®¡ç®—å®Œå…¨åŸºäºå·²å…³é—­ä»“ä½çš„çœŸå®ç›ˆäºï¼Œå¿½ç•¥æœªå¹³ä»“ä½çš„æµ®åŠ¨ç›ˆäºï¼Œä½¿ç»“æœæ›´ä¿å®ˆç¨³å¥ã€‚\n",
    "\n",
    "    æ€§èƒ½ä¼˜åŒ–å…³é”®ç‚¹:\n",
    "    - **é¢„åˆ†é…æ•°ç»„**: ä½¿ç”¨NumPyæ•°ç»„é¢„å…ˆåˆ†é…å†…å­˜æ¥å­˜å‚¨å›æµ‹ç»“æœï¼Œé¿å…åœ¨å¾ªç¯ä¸­åŠ¨æ€ä¿®æ”¹Pandas DataFrameï¼Œè¿™æ˜¯ä¸»è¦çš„æ€§èƒ½æå‡æ¥æºã€‚\n",
    "    - **é«˜æ•ˆé˜Ÿåˆ—æ“ä½œ**: åˆ©ç”¨`collections.deque`çš„O(1)æ—¶é—´å¤æ‚åº¦çš„`popleft()`å’Œ`append()`æ“ä½œç®¡ç†æ´»è·ƒä»“ä½ã€‚\n",
    "    - **ç®—æ³•ä¼˜åŒ–**: æ£€æŸ¥åˆ°æœŸä»“ä½æ—¶ï¼Œä»…éœ€æ£€æŸ¥é˜Ÿåˆ—å¤´éƒ¨çš„æœ€æ—©ä»“ä½ï¼Œæ— éœ€éå†æ•´ä¸ªé˜Ÿåˆ—ã€‚\n",
    "\n",
    "    å‚æ•°:\n",
    "    - prices (pd.Series): èµ„äº§çš„æ”¶ç›˜ä»·åºåˆ—ã€‚\n",
    "    - signals (pd.Series): äº¤æ˜“ä¿¡å·åºåˆ— (1: åšå¤š, -1: åšç©º, 0: ä¸­æ€§)ã€‚\n",
    "    - initial_capital (float): åˆå§‹æ€»èµ„æœ¬ã€‚\n",
    "    - commission_rate (float): å•è¾¹äº¤æ˜“æ‰‹ç»­è´¹ç‡ã€‚\n",
    "    - holding_period (int): æ¯ä»½ä»“ä½çš„æœ€å¤§æŒæœ‰å‘¨æœŸï¼ˆå•ä½ï¼šKçº¿æ•°é‡ï¼‰ã€‚\n",
    "\n",
    "    è¿”å›:\n",
    "    - pd.DataFrame: åŒ…å«å›æµ‹è¯¦ç»†è¿‡ç¨‹ï¼ˆå¦‚æŒä»“ã€æˆæœ¬ã€æƒç›Šç­‰ï¼‰çš„DataFrameã€‚\n",
    "    - pd.DataFrame: åŒ…å«æ¯ä¸€ç¬”å·²å®Œæˆäº¤æ˜“çš„è¯¦ç»†å†å²è®°å½•ã€‚\n",
    "    \"\"\"\n",
    "    logging.info(\"ğŸš€ å¼€å§‹æ‰§è¡Œä¼˜åŒ–ç‰ˆå›æµ‹ (åŸºäºå·²å®ç°ç›ˆäº)...\")\n",
    "\n",
    "    n = len(prices)\n",
    "    # --- æ€§èƒ½ä¼˜åŒ–: é¢„åˆ†é…ç»“æœå­˜å‚¨ ---\n",
    "    # å°†ç»“æœå­˜å‚¨åœ¨å­—å…¸åŒ…è£¹çš„NumPyæ•°ç»„ä¸­ï¼Œå¾ªç¯ç»“æŸåä¸€æ¬¡æ€§ç”ŸæˆDataFrameã€‚\n",
    "    # è¿™æ¯”åœ¨å¾ªç¯ä¸­é€è¡Œå¡«å……DataFrameï¼ˆå¦‚ä½¿ç”¨.atæˆ–.locï¼‰å¿«å‡ ä¸ªæ•°é‡çº§ã€‚\n",
    "    results = {\n",
    "        'position': np.zeros(n, dtype=np.int8),\n",
    "        'position_count': np.zeros(n, dtype=np.int8),\n",
    "        'cost_basis': np.zeros(n),\n",
    "        'transaction_costs': np.zeros(n),\n",
    "        'net_returns': np.zeros(n),\n",
    "        'equity_curve': np.full(n, initial_capital)\n",
    "    }\n",
    "\n",
    "    # --- æ€§èƒ½ä¼˜åŒ–: é¢„æå–æ•°æ®åˆ°NumPyæ•°ç»„ ---\n",
    "    # åœ¨å¾ªç¯å¼€å§‹å‰å°†Pandas Seriesè½¬æ¢ä¸ºNumPyæ•°ç»„ï¼Œåç»­åœ¨å¾ªç¯ä¸­è®¿é—®æ•°ç»„å…ƒç´ æ¯”è®¿é—®Serieså…ƒç´ æ›´å¿«ã€‚\n",
    "    close_arr = prices.values\n",
    "    signal_arr = signals.values\n",
    "    indices = prices.index # é¢„å­˜ç´¢å¼•ï¼Œç”¨äºè®°å½•äº¤æ˜“å†å²\n",
    "\n",
    "    # --- åˆå§‹åŒ–äº¤æ˜“çŠ¶æ€å˜é‡ ---\n",
    "    active_positions = deque()  # ä½¿ç”¨åŒç«¯é˜Ÿåˆ—(deque)é«˜æ•ˆç®¡ç†å…ˆè¿›å…ˆå‡ºçš„æŒä»“\n",
    "    realized_pnl = 0.0          # ç´¯è®¡å·²å®ç°ç›ˆäº\n",
    "    position_direction = 0      # å½“å‰æ•´ä½“æŒä»“æ–¹å‘ (1: å¤š, -1: ç©º, 0: æ— )\n",
    "    position_cost = 0.0         # å½“å‰æŒä»“çš„å¹³å‡æˆæœ¬ä»·\n",
    "    trade_history = []          # è®°å½•æ¯ä¸€ç¬”å®Œæ•´äº¤æ˜“çš„åˆ—è¡¨\n",
    "    capital_per_position = initial_capital / 10 # æ¯ä»½ä»“ä½åˆ†é…çš„èµ„é‡‘\n",
    "\n",
    "    # --- ä¸»å›æµ‹å¾ªç¯ ---\n",
    "    # ä»ç¬¬äºŒä¸ªæ—¶é—´ç‚¹å¼€å§‹éå†ï¼Œå› ä¸ºäº¤æ˜“å†³ç­–åŸºäºå‰ä¸€å¤©çš„ä¿¡å·\n",
    "    for i in range(1, n):\n",
    "        current_close = close_arr[i]\n",
    "        prev_signal = signal_arr[i-1]  # ä½¿ç”¨t-1çš„ä¿¡å·å†³å®štæ—¶åˆ»çš„æ“ä½œ\n",
    "        trades_occurred = False        # æ ‡è®°å½“æ—¥æ˜¯å¦æœ‰äº¤æ˜“ï¼ˆå¹³ä»“ï¼‰å‘ç”Ÿ\n",
    "\n",
    "        # 1. å¤„ç†åˆ°æœŸå¼ºåˆ¶å¹³ä»“\n",
    "        # --- æ€§èƒ½ä¼˜åŒ–: O(1)å¤æ‚åº¦çš„åˆ°æœŸæ£€æŸ¥ ---\n",
    "        # ç”±äºactive_positionsæ˜¯å…ˆè¿›å…ˆå‡ºé˜Ÿåˆ—ï¼Œæˆ‘ä»¬åªéœ€æ£€æŸ¥é˜Ÿå¤´ï¼ˆæœ€æ—©çš„ä»“ä½ï¼‰ã€‚\n",
    "        # å¦‚æœé˜Ÿå¤´æ²¡åˆ°æœŸï¼Œé‚£ä¹ˆé˜Ÿåˆ—ä¸­æ‰€æœ‰å…¶ä»–ä»“ä½ä¹Ÿä¸€å®šæ²¡åˆ°æœŸã€‚\n",
    "        while active_positions:\n",
    "            oldest_pos = active_positions[0] # åªçœ‹ä¸å–\n",
    "            if i - oldest_pos['entry_index'] >= holding_period:\n",
    "                # ä»“ä½å·²åˆ°æœŸï¼Œæ‰§è¡Œå¹³ä»“\n",
    "                pos_to_close = active_positions.popleft() # ä»é˜Ÿåˆ—ä¸­ç§»é™¤\n",
    "                exit_price = current_close\n",
    "                \n",
    "                # è®¡ç®—ç›ˆäº\n",
    "                pnl = (exit_price - pos_to_close['entry_price']) * pos_to_close['direction'] * pos_to_close['quantity']\n",
    "                exit_commission = commission_rate * exit_price * pos_to_close['quantity']\n",
    "                net_pnl = pnl - exit_commission\n",
    "                \n",
    "                # æ›´æ–°ç´¯è®¡å·²å®ç°ç›ˆäº\n",
    "                realized_pnl += net_pnl\n",
    "                trades_occurred = True\n",
    "                \n",
    "                # è®°å½•äº¤æ˜“æˆæœ¬\n",
    "                results['transaction_costs'][i] += exit_commission\n",
    "                \n",
    "                # è®°å½•äº¤æ˜“å†å²\n",
    "                trade_history.append({\n",
    "                    'entry_time': indices[pos_to_close['entry_index']], 'exit_time': indices[i],\n",
    "                    'direction': pos_to_close['direction'], 'entry_price': pos_to_close['entry_price'],\n",
    "                    'exit_price': exit_price, 'quantity': pos_to_close['quantity'],\n",
    "                    'pnl': pnl, 'commission': exit_commission, 'net_pnl': net_pnl,\n",
    "                    'duration': i - pos_to_close['entry_index'], 'type': 'expired'\n",
    "                })\n",
    "            else:\n",
    "                # æœ€æ—©çš„ä»“ä½éƒ½æœªåˆ°æœŸï¼Œåˆ™æ— éœ€ç»§ç»­æ£€æŸ¥\n",
    "                break\n",
    "\n",
    "        # 2. æ ¹æ®æ–°ä¿¡å·å¤„ç†äº¤æ˜“\n",
    "        if prev_signal != 0:  # åªå¯¹éä¸­æ€§ä¿¡å·åšå‡ºååº”\n",
    "            # æƒ…å†µA: å½“å‰æ— ä»»ä½•æŒä»“ï¼Œä¸”æœ‰æ–°ä¿¡å·\n",
    "            if position_direction == 0:\n",
    "                # å¼€ç«‹ç¬¬ä¸€ä»½ä»“ä½\n",
    "                quantity = capital_per_position / current_close\n",
    "                active_positions.append({\n",
    "                    'direction': prev_signal,\n",
    "                    'entry_price': current_close,\n",
    "                    'quantity': quantity,\n",
    "                    'entry_index': i\n",
    "                })\n",
    "                position_direction = prev_signal\n",
    "                position_cost = current_close\n",
    "                entry_commission = commission_rate * current_close * quantity\n",
    "                results['transaction_costs'][i] += entry_commission\n",
    "                results['position'][i] = prev_signal\n",
    "\n",
    "            # æƒ…å†µB: æ–°ä¿¡å·ä¸å½“å‰æŒä»“æ–¹å‘ç›¸åŒ (åŠ ä»“)\n",
    "            elif position_direction == prev_signal and len(active_positions) < 10:\n",
    "                # å¦‚æœä»“ä½æœªæ»¡10ä»½ï¼Œåˆ™åŠ å¼€ä¸€ä»½æ–°ä»“\n",
    "                quantity = capital_per_position / current_close\n",
    "                active_positions.append({\n",
    "                    'direction': prev_signal, 'entry_price': current_close,\n",
    "                    'quantity': quantity, 'entry_index': i\n",
    "                })\n",
    "                # æ›´æ–°å¹³å‡æŒä»“æˆæœ¬\n",
    "                total_quantity = sum(p['quantity'] for p in active_positions)\n",
    "                total_cost = sum(p['entry_price'] * p['quantity'] for p in active_positions)\n",
    "                position_cost = total_cost / total_quantity\n",
    "                entry_commission = commission_rate * current_close * quantity\n",
    "                results['transaction_costs'][i] += entry_commission\n",
    "                results['position'][i] = prev_signal\n",
    "\n",
    "            # æƒ…å†µC: æ–°ä¿¡å·ä¸å½“å‰æŒä»“æ–¹å‘ç›¸å (éƒ¨åˆ†å¹³ä»“)\n",
    "            elif position_direction != prev_signal and active_positions:\n",
    "                # æ ¸å¿ƒé€»è¾‘ï¼šåªå¹³æ‰æœ€æ—©çš„ä¸€ä»½ä»“ä½ï¼Œå®ç°æ¸è¿›å¼è°ƒä»“\n",
    "                pos_to_close = active_positions.popleft()\n",
    "                exit_price = current_close\n",
    "                pnl = (exit_price - pos_to_close['entry_price']) * pos_to_close['direction'] * pos_to_close['quantity']\n",
    "                exit_commission = commission_rate * exit_price * pos_to_close['quantity']\n",
    "                net_pnl = pnl - exit_commission\n",
    "\n",
    "                realized_pnl += net_pnl\n",
    "                trades_occurred = True\n",
    "                results['transaction_costs'][i] += exit_commission\n",
    "\n",
    "                trade_history.append({\n",
    "                    'entry_time': indices[pos_to_close['entry_index']], 'exit_time': indices[i],\n",
    "                    'direction': pos_to_close['direction'], 'entry_price': pos_to_close['entry_price'],\n",
    "                    'exit_price': exit_price, 'quantity': pos_to_close['quantity'],\n",
    "                    'pnl': pnl, 'commission': exit_commission, 'net_pnl': net_pnl,\n",
    "                    'duration': i - pos_to_close['entry_index'], 'type': 'signal'\n",
    "                })\n",
    "\n",
    "                # æ›´æ–°æŒä»“çŠ¶æ€\n",
    "                if active_positions:\n",
    "                    # å¦‚æœå¹³ä»“åä»æœ‰æŒä»“ï¼Œé‡æ–°è®¡ç®—å¹³å‡æˆæœ¬\n",
    "                    total_quantity = sum(p['quantity'] for p in active_positions)\n",
    "                    total_cost = sum(p['entry_price'] * p['quantity'] for p in active_positions)\n",
    "                    position_cost = total_cost / total_quantity\n",
    "                else:\n",
    "                    # å¦‚æœæ‰€æœ‰ä»“ä½éƒ½å·²å¹³æ‰ï¼Œé‡ç½®æŒä»“çŠ¶æ€\n",
    "                    position_direction = 0\n",
    "                    position_cost = 0.0\n",
    "                results['position'][i] = position_direction\n",
    "\n",
    "        # 3. æ›´æ–°æ¯æ—¥çŠ¶æ€\n",
    "        results['position_count'][i] = len(active_positions)\n",
    "        results['cost_basis'][i] = position_cost\n",
    "        results['equity_curve'][i] = initial_capital + realized_pnl # æƒç›Šæ›²çº¿ä»…éšå·²å®ç°ç›ˆäºå˜åŒ–\n",
    "\n",
    "        # 4. è®¡ç®—å½“æ—¥å‡€æ”¶ç›Šç‡ (ä»…åœ¨æœ‰å¹³ä»“äº¤æ˜“æ—¶å‘ç”Ÿå˜åŒ–)\n",
    "        if i > 0: # ä»ç¬¬äºŒå¤©å¼€å§‹è®¡ç®—\n",
    "            prev_equity = results['equity_curve'][i-1]\n",
    "            if trades_occurred:\n",
    "                results['net_returns'][i] = (results['equity_curve'][i] - prev_equity) / prev_equity\n",
    "            # å¦‚æœæ²¡æœ‰äº¤æ˜“ï¼Œå‡€æ”¶ç›Šä¸º0ï¼Œæ•°ç»„é»˜è®¤å°±æ˜¯0ï¼Œæ— éœ€æ“ä½œ\n",
    "\n",
    "    # --- å›æµ‹æœŸæœ«å¤„ç† ---\n",
    "    # å°†æ‰€æœ‰å‰©ä½™çš„æœªå¹³ä»“å¤´å¯¸åœ¨æœ€åä¸€ä¸ªäº¤æ˜“æ—¥å¼ºåˆ¶å¹³ä»“\n",
    "    if active_positions:\n",
    "        last_close = close_arr[-1]\n",
    "        for pos in active_positions:\n",
    "            exit_price = last_close\n",
    "            pnl = (exit_price - pos['entry_price']) * pos['direction'] * pos['quantity']\n",
    "            exit_commission = commission_rate * exit_price * pos['quantity']\n",
    "            net_pnl = pnl - exit_commission\n",
    "            realized_pnl += net_pnl\n",
    "            results['transaction_costs'][-1] += exit_commission\n",
    "\n",
    "            trade_history.append({\n",
    "                'entry_time': indices[pos['entry_index']],\n",
    "                'exit_time': indices[-1],\n",
    "                'direction': pos['direction'],\n",
    "                'entry_price': pos['entry_price'],\n",
    "                'exit_price': exit_price,\n",
    "                'quantity': pos['quantity'],\n",
    "                'pnl': pnl,\n",
    "                'commission': exit_commission,\n",
    "                'net_pnl': net_pnl,\n",
    "                'duration': n - 1 - pos['entry_index'],\n",
    "                'type': 'forced_close'\n",
    "            })\n",
    "            \n",
    "        # æ›´æ–°æœ€ç»ˆçš„æƒç›Šå’Œæ”¶ç›Šç‡\n",
    "        results['equity_curve'][-1] = initial_capital + realized_pnl\n",
    "        prev_equity = results['equity_curve'][-2] if n > 1 else initial_capital\n",
    "        results['net_returns'][-1] = (results['equity_curve'][-1] - prev_equity) / prev_equity\n",
    "\n",
    "    # --- æ•´åˆç»“æœ ---\n",
    "    # ä½¿ç”¨é¢„å…ˆè®¡ç®—å¥½çš„NumPyæ•°ç»„ï¼Œä¸€æ¬¡æ€§åˆ›å»ºæœ€ç»ˆçš„DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'close': prices,\n",
    "        'signal': signals,\n",
    "        'position': results['position'],\n",
    "        'position_count': results['position_count'],\n",
    "        'cost_basis': results['cost_basis'],\n",
    "        'transaction_costs': results['transaction_costs'],\n",
    "        'net_returns': results['net_returns'],\n",
    "        'equity_curve': results['equity_curve']\n",
    "    }, index=prices.index)\n",
    "\n",
    "    logging.info(\"âœ… ä¼˜åŒ–ç‰ˆå›æµ‹å®Œæˆã€‚\")\n",
    "    return df, pd.DataFrame(trade_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94dc0e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_realized_pnl_performance(backtest_results, trade_history, initial_capital):\n",
    "    \"\"\"\n",
    "    å…¨é¢è¯„ä¼°åŸºäºå·²å®ç°ç›ˆäºçš„ç­–ç•¥è¡¨ç°ï¼Œå¹¶ç”Ÿæˆæ ‡å‡†åŒ–æŠ¥å‘Šã€‚\n",
    "\n",
    "    å…³é”®è¯„ä¼°é€»è¾‘:\n",
    "    - **æ ‡å‡†åŒ–æŒ‡æ ‡**: å¤æ™®æ¯”ç‡ç­‰å…³é”®é£é™©æŒ‡æ ‡åŸºäºæœˆåº¦æ”¶ç›Šç‡è®¡ç®—ï¼Œä»¥æä¾›æ›´ç¨³å¥ã€æ›´å…·å¯æ¯”æ€§çš„è¯„ä¼°ã€‚\n",
    "    - **å‘é‡åŒ–è®¡ç®—**: å°½å¯èƒ½ä½¿ç”¨Pandaså’ŒNumPyçš„å‘é‡åŒ–åŠŸèƒ½ï¼Œä»¥æé«˜è®¡ç®—æ•ˆç‡ã€‚\n",
    "    - **ç²¾ç¡®äº¤æ˜“ç»Ÿè®¡**: æ‰€æœ‰äº¤æ˜“ç›¸å…³æŒ‡æ ‡ï¼ˆèƒœç‡ã€ç›ˆäºæ¯”ç­‰ï¼‰å‡åŸºäº`trade_history` DataFrameè¿›è¡Œç²¾ç¡®è®¡ç®—ã€‚\n",
    "    - **å¯è§†åŒ–æŠ¥å‘Š**: ç”Ÿæˆæ¸…æ™°çš„æƒç›Šæ›²çº¿å›¾å’Œå¤šç»´åº¦ã€æ ¼å¼åŒ–çš„æ€§èƒ½æŒ‡æ ‡è¡¨æ ¼ã€‚\n",
    "    \"\"\"\n",
    "    logging.info(\"ğŸ“Š å¼€å§‹è¿›è¡Œå…¨é¢çš„ç­–ç•¥æ€§èƒ½è¯„ä¼°...\")\n",
    "\n",
    "    df = backtest_results.copy()\n",
    "    trade_df = trade_history.copy()\n",
    "\n",
    "    # --- 1. æ ¸å¿ƒæ”¶ç›Šä¸é£é™©æŒ‡æ ‡ ---\n",
    "    final_equity = df['equity_curve'].iloc[-1]\n",
    "    total_return = (final_equity - initial_capital) / initial_capital\n",
    "\n",
    "    # å‘é‡åŒ–è®¡ç®—å›æ’¤ (Drawdown)\n",
    "    equity_curve = df['equity_curve']\n",
    "    peak = equity_curve.expanding(min_periods=1).max() # è®¡ç®—æ»šåŠ¨æœ€é«˜ç‚¹\n",
    "    drawdown = (peak - equity_curve) / peak            # è®¡ç®—å›æ’¤ç™¾åˆ†æ¯”\n",
    "    max_drawdown = drawdown.max()                      # è·å–æœ€å¤§å›æ’¤\n",
    "    \n",
    "    # æ‰¾åˆ°æœ€å¤§å›æ’¤\n",
    "    mdd_end = drawdown.idxmax() if not drawdown.empty else None # æœ€å¤§å›æ’¤ç»“æŸç‚¹\n",
    "    mdd_start = peak[:mdd_end].idxmax() if mdd_end is not None else None # æœ€å¤§å›æ’¤å¼€å§‹ç‚¹\n",
    "\n",
    "    # è®¡ç®—å¹´åŒ–æŒ‡æ ‡\n",
    "    total_days = (df.index[-1] - df.index[0]).days\n",
    "    duration_years = max(total_days / 365.25, 0.001)  # é¿å…é™¤ä»¥é›¶ï¼Œæœ€çŸ­ä¸º0.001å¹´\n",
    "    annualized_return = total_return / duration_years\n",
    "\n",
    "    # --- 2. æ ‡å‡†åŒ–é£é™©è°ƒæ•´åæ”¶ç›Š (Standardized Risk-Adjusted Metrics) ---\n",
    "    # å…³é”®ä¿®æ­£ï¼šä¸ºéµå¾ªè¡Œä¸šç¨³å¥æ ‡å‡†ï¼Œé¿å…é«˜é¢‘æ•°æ®å¯¹æŒ‡æ ‡çš„æ‰­æ›²ï¼Œ\n",
    "    # å¤æ™®æ¯”ç‡ç­‰æŒ‡æ ‡åº”åŸºäºé¢‘ç‡è¾ƒä½ï¼ˆå¦‚æœˆåº¦ï¼‰çš„æ”¶ç›Šç‡è®¡ç®—ã€‚\n",
    "    monthly_returns = df['equity_curve'].resample('M').last().pct_change().dropna()\n",
    "\n",
    "    # å¤æ™®æ¯”ç‡ (Sharpe Ratio)\n",
    "    # å…¬å¼: å¹´åŒ–(æœˆåº¦å¹³å‡æ”¶ç›Š / æœˆåº¦æ”¶ç›Šæ ‡å‡†å·®)\n",
    "    sharpe_ratio = (monthly_returns.mean() / monthly_returns.std()) * np.sqrt(12) if len(monthly_returns) > 1 else 0\n",
    "\n",
    "    # å¡ç›æ¯”ç‡ (Calmar Ratio)\n",
    "    # å…¬å¼: å¹´åŒ–æ”¶ç›Šç‡ / æœ€å¤§å›æ’¤\n",
    "    calmar_ratio = annualized_return / max_drawdown if max_drawdown > 0 else 0\n",
    "    \n",
    "    # å¹´åŒ–æ³¢åŠ¨ç‡ (åŸºäºæ—¥å‡€æ”¶ç›Šç‡è®¡ç®—)\n",
    "    annualized_volatility = df['net_returns'].std() * np.sqrt(365.25) # å‡è®¾ä¸€å¹´æœ‰365.25ä¸ªäº¤æ˜“æ—¥\n",
    "\n",
    "    # --- 3. äº¤æ˜“ç»Ÿè®¡ (åŸºäºç²¾ç¡®çš„äº¤æ˜“å†å²) ---\n",
    "    total_trades = len(trade_df)\n",
    "    if total_trades > 0:\n",
    "        winning_trades = trade_df[trade_df['net_pnl'] > 0]\n",
    "        losing_trades = trade_df[trade_df['net_pnl'] <= 0]\n",
    "\n",
    "        win_rate = len(winning_trades) / total_trades\n",
    "        # å¹³å‡ç›ˆ/äºè®¡ç®—çš„æ˜¯å åˆå§‹èµ„æœ¬çš„ç™¾åˆ†æ¯”\n",
    "        avg_win = winning_trades['net_pnl'].mean() / initial_capital if len(winning_trades) > 0 else 0\n",
    "        avg_loss = losing_trades['net_pnl'].mean() / initial_capital if len(losing_trades) > 0 else 0\n",
    "        # ç›ˆäºæ¯”\n",
    "        profit_factor = abs(winning_trades['net_pnl'].sum() / losing_trades['net_pnl'].abs().sum()) if len(losing_trades) > 0 and losing_trades['net_pnl'].abs().sum() > 0 else float('inf')\n",
    "        # æœŸæœ›æ”¶ç›Š\n",
    "        expectancy = (win_rate * avg_win) + ((1 - win_rate) * avg_loss)\n",
    "    else:\n",
    "        # å¦‚æœæ²¡æœ‰äº¤æ˜“ï¼Œæ‰€æœ‰æŒ‡æ ‡è®¾ä¸º0\n",
    "        win_rate = avg_win = avg_loss = profit_factor = expectancy = 0\n",
    "\n",
    "    # --- 4. å…¶ä»–è¾…åŠ©æŒ‡æ ‡ ---\n",
    "    # æŒä»“æ¯”ä¾‹ (å‘é‡åŒ–è®¡ç®—)\n",
    "    long_ratio = (df['position'] > 0).mean()\n",
    "    short_ratio = (df['position'] < 0).mean()\n",
    "\n",
    "    # æ¯å‘¨å¼€ä»“é¢‘ç‡\n",
    "    weekly_trades = trade_df.resample('W', on='entry_time').size().mean() if not trade_df.empty else 0\n",
    "\n",
    "    # å¹´åŒ–æ¢æ‰‹ç‡ (Annualized Turnover)\n",
    "    if total_trades > 0:\n",
    "        # åä¹‰æœ¬é‡‘ = ä»·æ ¼ * æ•°é‡\n",
    "        trade_df['entry_notional'] = trade_df['entry_price'] * trade_df['quantity']\n",
    "        trade_df['exit_notional'] = trade_df['exit_price'] * trade_df['quantity']\n",
    "        # æ€»äº¤æ˜“é¢ = (ä¹°å…¥æ€»é¢ + å–å‡ºæ€»é¢) / 2\n",
    "        total_turnover = (trade_df['entry_notional'].sum() + trade_df['exit_notional'].sum()) / 2\n",
    "        avg_net_assets = df['equity_curve'].mean()\n",
    "        # å¹´åŒ–æ¢æ‰‹ç‡ = (æ€»äº¤æ˜“é¢ / å¹³å‡å‡€èµ„äº§) / å¹´æ•°\n",
    "        annualized_turnover = (total_turnover / avg_net_assets) / duration_years\n",
    "    else:\n",
    "        annualized_turnover = 0\n",
    "\n",
    "    # ä¿¡æ¯ç³»æ•° (Information Coefficient, IC)\n",
    "    # è¡¡é‡ä¿¡å·å¯¹ä¸‹ä¸€æœŸæ”¶ç›Šçš„é¢„æµ‹èƒ½åŠ›\n",
    "    forward_returns = df['close'].pct_change().shift(-1)\n",
    "    # ç¡®ä¿ä¿¡å·å’Œæœªæ¥æ”¶ç›Šå¯¹é½ï¼Œä¸”æ— ç©ºå€¼\n",
    "    valid_idx = df['signal'].shift(1).notna() & forward_returns.notna()\n",
    "    ic = np.corrcoef(df['signal'].shift(1)[valid_idx], forward_returns[valid_idx])[0, 1]\n",
    "\n",
    "    # é€å¹´æ”¶ç›Šç‡\n",
    "    yearly_returns = []\n",
    "    for year, group in df.groupby(df.index.year):\n",
    "        if len(group) > 1:\n",
    "            start_equity = group['equity_curve'].iloc[0]\n",
    "            end_equity = group['equity_curve'].iloc[-1]\n",
    "            yearly_return = (end_equity - start_equity) / start_equity\n",
    "            yearly_returns.append((year, yearly_return))\n",
    "\n",
    "    # --- 5. åŸºå‡†è®¡ç®— ---\n",
    "    # ç†è®ºåŸºå‡†: å®Œç¾é¢„æµ‹ä¸‹çš„ç†è®ºæ”¶ç›Š (ä¿¡å· * æœªæ¥10æœŸæ”¶ç›Š)ï¼Œç”¨äºè¡¡é‡ä¿¡å·è´¨é‡\n",
    "    future_return = (df['close'].shift(-10) - df['close']) / df['close']\n",
    "    # ä¹˜ä»¥0.1æ˜¯å› ä¸ºç­–ç•¥æ¯æ¬¡åªæŠ•å…¥1/10çš„èµ„é‡‘\n",
    "    theoretical_benchmark = (df['signal'].shift(1) * future_return * 0.1).fillna(0).cumsum()\n",
    "    strategy_cumulative = (df['equity_curve'] - initial_capital) / initial_capital\n",
    "    correlation = strategy_cumulative.corr(theoretical_benchmark)\n",
    "\n",
    "    # ä¹°å…¥å¹¶æŒæœ‰åŸºå‡† (Buy & Hold)\n",
    "    buy_hold_curve = initial_capital * (df['close'] / df['close'].iloc[0])\n",
    "\n",
    "    # --- 6. ç”Ÿæˆæ ¼å¼åŒ–æŠ¥å‘Š ---\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(Fore.CYAN + Style.BRIGHT + \" \" * 30 + \"ç­–ç•¥æ€§èƒ½è¯„ä¼°æŠ¥å‘Š\" + \" \" * 30 + Style.RESET_ALL)\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(\"\\n\" + Fore.BLUE + Style.BRIGHT + \"=\"*30 + \" æ”¶ç›ŠæŒ‡æ ‡ \" + \"=\"*30 + Style.RESET_ALL)\n",
    "    detail_headers = [\"æŒ‡æ ‡åç§°\", \"è®¡ç®—ç»“æœ\", \"è¦æ±‚\", \"çŠ¶æ€\"]\n",
    "    \n",
    "    sharpe_status = \"âœ… è¾¾æ ‡\" if sharpe_ratio >= 2.0 else Fore.RED + \"âŒ æœªè¾¾æ ‡\" + Style.RESET_ALL\n",
    "    calmar_status = \"âœ… è¾¾æ ‡\" if calmar_ratio >= 5.0 else Fore.RED + \"âŒ æœªè¾¾æ ‡\" + Style.RESET_ALL\n",
    "    expectancy_status = \"âœ… è¾¾æ ‡\" if expectancy >= 0.25 else Fore.RED + \"âŒ æœªè¾¾æ ‡\" + Style.RESET_ALL\n",
    "    \n",
    "    detail_table = [\n",
    "        [\"å¤æ™®æ¯”ç‡ (Sharpe)\", f\"{sharpe_ratio:.4f}\", \"> 2.0\", sharpe_status],\n",
    "        [\"å¡ç›æ¯”ç‡ (Calmar)\", f\"{calmar_ratio:.4f}\", \"> 5.0\", calmar_status],\n",
    "        [\"æœŸæœ›æ”¶ç›Š (Expectancy)\", f\"{expectancy:.4f}\", \"> 0.25\", expectancy_status]\n",
    "    ]\n",
    "    print(tabulate(detail_table, headers=detail_headers, tablefmt=\"grid\", stralign=\"center\", numalign=\"center\"))\n",
    "    \n",
    "    print(\"\\n\" + Fore.BLUE + Style.BRIGHT + \"ç­–ç•¥æ–¹æ¡ˆè¯„ä¼°\" + Style.RESET_ALL)\n",
    "    scheme_table = [\n",
    "        [\"æ–¹æ¡ˆä¸€ (å¤æ™® & å¡ç›)\", \"âœ… è¾¾æ ‡\" if sharpe_ratio >= 2.0 and calmar_ratio >= 5.0 else Fore.RED + \"âŒ æœªè¾¾æ ‡\" + Style.RESET_ALL],\n",
    "        [\"æ–¹æ¡ˆäºŒ (æœŸæœ›æ”¶ç›Š)\", \"âœ… è¾¾æ ‡\" if expectancy >= 0.25 else Fore.RED + \"âŒ æœªè¾¾æ ‡\" + Style.RESET_ALL],\n",
    "        [\"ç»¼åˆæ”¶ç›ŠæŒ‡æ ‡\", \"âœ… è¾¾æ ‡\" if sharpe_ratio >= 2.0 and calmar_ratio >= 5.0 and expectancy >= 0.25 else Fore.RED + \"âŒ æœªè¾¾æ ‡\" + Style.RESET_ALL]\n",
    "    ]\n",
    "    print(tabulate(scheme_table, headers=[\"ç­–ç•¥æ–¹æ¡ˆ\", \"çŠ¶æ€\"], tablefmt=\"grid\", stralign=\"center\", numalign=\"center\"))\n",
    "    \n",
    "    print(\"\\n\" + Fore.BLUE + Style.BRIGHT + \"æŒä»“ç»Ÿè®¡\" + Style.RESET_ALL)\n",
    "    position_table = [\n",
    "        [\"å¤šå¤´æŒä»“å æ¯”\", f\"{long_ratio:.2%}\"],\n",
    "        [\"ç©ºå¤´æŒä»“å æ¯”\", f\"{short_ratio:.2%}\"]\n",
    "    ]\n",
    "    print(tabulate(position_table, headers=[\"æŒ‡æ ‡\", \"å€¼\"], tablefmt=\"grid\", stralign=\"center\", numalign=\"center\"))\n",
    "    \n",
    "    print(\"\\n\" + Fore.YELLOW + Style.BRIGHT + \"=\"*30 + \" é£æ§ä¸æ•ˆç‡æŒ‡æ ‡ \" + \"=\"*30 + Style.RESET_ALL)\n",
    "    risk_headers = [\"æŒ‡æ ‡åç§°\", \"è®¡ç®—ç»“æœ\", \"è¦æ±‚\", \"çŠ¶æ€\"]\n",
    "    mdd_status = \"âœ… è¾¾æ ‡\" if max_drawdown < 0.2 else Fore.RED + \"âŒ æœªè¾¾æ ‡\" + Style.RESET_ALL\n",
    "    trade_freq_status = \"âœ… è¾¾æ ‡\" if weekly_trades > 5 else Fore.RED + \"âŒ æœªè¾¾æ ‡\" + Style.RESET_ALL\n",
    "    \n",
    "    risk_table = [\n",
    "        [\"æœ€å¤§å›æ’¤ (MDD)\", f\"{max_drawdown:.3%}\", \"< 0.2\", mdd_status],\n",
    "        [\"æ¯å‘¨å¼€ä»“é¢‘ç‡\", f\"{weekly_trades:.4f}\", \"> 5\", trade_freq_status]\n",
    "    ]\n",
    "    print(tabulate(risk_table, headers=risk_headers, tablefmt=\"grid\", stralign=\"center\", numalign=\"center\"))\n",
    "    \n",
    "    print(\"\\n\" + Fore.YELLOW + Style.BRIGHT + \"ç»¼åˆæŒ‡æ ‡è¯„ä¼°\" + Style.RESET_ALL)\n",
    "    risk_summary_table = [\n",
    "        [\"ç»¼åˆé£æ§æŒ‡æ ‡\", \"âœ… è¾¾æ ‡\" if max_drawdown < 0.2 else Fore.RED + \"âŒ æœªè¾¾æ ‡\" + Style.RESET_ALL],\n",
    "        [\"ç»¼åˆæ•ˆç‡æŒ‡æ ‡\", \"âœ… è¾¾æ ‡\" if weekly_trades > 5 else Fore.RED + \"âŒ æœªè¾¾æ ‡\" + Style.RESET_ALL]\n",
    "    ]\n",
    "    print(tabulate(risk_summary_table, headers=[\"æŒ‡æ ‡\", \"çŠ¶æ€\"], tablefmt=\"grid\", stralign=\"center\", numalign=\"center\"))\n",
    "    \n",
    "    print(\"\\n\" + Fore.GREEN + Style.BRIGHT + \"=\"*30 + \" è¯¦ç»†æŒ‡æ ‡ \" + \"=\"*30 + Style.RESET_ALL)\n",
    "    detailed_headers = [\"æŒ‡æ ‡åç§°\", \"å€¼\"]\n",
    "    detailed_table = [\n",
    "        [Fore.YELLOW + \"ä¸'signal Ã— return'åŸºå‡†çš„ç›¸å…³æ€§\" + Style.RESET_ALL, f\"{correlation:.3%}\"],\n",
    "        [\"æ€»æ”¶ç›Šç‡ (Total Return)\", f\"{total_return:.3%}\"],\n",
    "        [\"å¹´åŒ–æ”¶ç›Šç‡ (Annualized Return)\", f\"{annualized_return:.3%}\"],\n",
    "        [\"å¹´åŒ–æ³¢åŠ¨ç‡ (Annualized Vol)\", f\"{annualized_volatility:.3%}\"],\n",
    "        [\"æ€»ç›ˆäº (Total PnL)\", f\"${final_equity - initial_capital:,.2f}\"],\n",
    "        [\"æ€»äº¤æ˜“ç¬”æ•° (Total Trades)\", f\"{total_trades}\"],\n",
    "        [\"ç›ˆåˆ©äº¤æ˜“ç¬”æ•° (Winning Trades)\", f\"{len(winning_trades)}\"],\n",
    "        [\"äºæŸäº¤æ˜“ç¬”æ•° (Losing Trades)\", f\"{len(losing_trades)}\"],\n",
    "        [\"èƒœç‡ (Win Rate)\", f\"{win_rate:.3%}\"],\n",
    "        [\"ç›ˆäºæ¯” (Profit Factor)\", f\"{profit_factor:.3f}\"],\n",
    "        [\"å¹³å‡ç›ˆåˆ© (Average Win)\", f\"{avg_win:.3%}\"],\n",
    "        [\"å¹³å‡äºæŸ (Average Loss)\", f\"{avg_loss:.3%}\"],\n",
    "        [\"å¹´åŒ–æ¢æ‰‹ç‡ (Annualized Turnover)\", f\"{annualized_turnover:.3%}\"],\n",
    "        [\"æœ€å¤§å›æ’¤èµ·å§‹æ—¥æœŸ\", f\"{mdd_start}\"],\n",
    "        [\"æœ€å¤§å›æ’¤ç»“æŸæ—¥æœŸ\", f\"{mdd_end}\"],\n",
    "        [\"ä¿¡æ¯ç³»æ•° (IC)\", f\"{ic:.3f}\"]\n",
    "    ]\n",
    "    print(tabulate(detailed_table, headers=detailed_headers, tablefmt=\"grid\", stralign=\"center\", numalign=\"center\"))\n",
    "    \n",
    "    print(\"\\n\" + Fore.MAGENTA + Style.BRIGHT + \"=\"*30 + \" é€å¹´æ”¶ç›Šç‡ \" + \"=\"*30 + Style.RESET_ALL)\n",
    "    yearly_table = []\n",
    "    for year, return_val in yearly_returns:\n",
    "        yearly_table.append([year, f\"{return_val:.3%}\"])\n",
    "    print(tabulate(yearly_table, headers=[\"å¹´ä»½\", \"æ”¶ç›Šç‡\"], tablefmt=\"grid\", stralign=\"center\", numalign=\"center\"))\n",
    "\n",
    "    # --- 7. ç»˜åˆ¶æƒç›Šæ›²çº¿å›¾ ---\n",
    "    fig, ax = plt.subplots(figsize=(15, 10))\n",
    "    \n",
    "    # ä»…åœ¨æœ‰äº¤æ˜“å‘ç”Ÿæ—¶ç»˜åˆ¶å‚ç›´çº¿æ¡\n",
    "    trade_dates = trade_df['exit_time'].unique()\n",
    "    trade_dates = sorted(trade_dates)\n",
    "    \n",
    "    # ç»˜åˆ¶é˜¶æ¢¯çŠ¶çš„ç­–ç•¥æƒç›Šæ›²çº¿\n",
    "    prev_equity = initial_capital\n",
    "    for date in trade_dates:\n",
    "        equity = df.loc[date, 'equity_curve']\n",
    "        # ç»˜åˆ¶æ°´å¹³çº¿ï¼ˆå‰ä¸€ç‚¹åˆ°å½“å‰ç‚¹ï¼‰\n",
    "        prev_date = df.index[df.index.get_loc(date) - 1] if date != df.index[0] else date\n",
    "        ax.hlines(y=prev_equity, xmin=prev_date, xmax=date, color='royalblue', linewidth=2)\n",
    "        # ç»˜åˆ¶å‚ç›´çº¿ï¼ˆå½“å‰ç‚¹ï¼‰\n",
    "        ax.vlines(x=date, ymin=prev_equity, ymax=equity, color='royalblue', linewidth=2)\n",
    "        prev_equity = equity\n",
    "    \n",
    "    # ç»˜åˆ¶æœ€åä¸€æ®µ\n",
    "    last_trade_date = trade_dates[-1] if trade_dates else df.index[0]\n",
    "    ax.hlines(y=prev_equity, xmin=last_trade_date, xmax=df.index[-1], color='royalblue', linewidth=2)\n",
    "    \n",
    "    # ç»˜åˆ¶ç­–ç•¥æƒç›Šæ›²çº¿ (ä½¿ç”¨é˜¶æ¢¯å›¾)\n",
    "    # é˜¶æ¢¯å›¾(step plot)èƒ½å®Œç¾å±•ç¤ºå·²å®ç°ç›ˆäºæ›²çº¿çš„ç‰¹æ€§ï¼šæƒç›Šåªåœ¨äº¤æ˜“å¹³ä»“æ—¶å‘ç”Ÿé˜¶è·ƒå¼å˜åŒ–ã€‚\n",
    "    ax.step(df.index, df['equity_curve'], where='post', label='Strategy Equity', color='royalblue', linewidth=2)\n",
    "\n",
    "    # ç»˜åˆ¶ç†è®ºåŸºå‡†æ›²çº¿\n",
    "    theoretical_curve = initial_capital * (1 + theoretical_benchmark)\n",
    "    ax.plot(df.index, theoretical_curve, label='Theoretical Benchmark (signalÃ—return)', color='purple', linestyle='--', alpha=0.7)\n",
    "\n",
    "    # ç»˜åˆ¶ä¹°å…¥å¹¶æŒæœ‰åŸºå‡†æ›²çº¿\n",
    "    ax.plot(df.index, buy_hold_curve, label='Buy & Hold BTC', color='darkorange', linestyle=':', alpha=0.7)\n",
    "\n",
    "    # è®¾ç½®å›¾è¡¨æ ‡é¢˜å’Œæ ‡ç­¾\n",
    "    ax.set_title('Strategy Equity Curve vs. Benchmarks (Realized PnL Only)', fontsize=16)\n",
    "    ax.set_xlabel('Date', fontsize=12)\n",
    "    ax.set_ylabel('Net Asset Value', fontsize=12)\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    logging.info(\"âœ… ç­–ç•¥è¯„ä¼°æŠ¥å‘Šç”Ÿæˆå®Œæ¯•ã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa116caf",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. ä¸»ç¨‹åºæ‰§è¡Œ (æ›´æ–°)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44e9a745",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-30 23:52:27,439 - INFO - ğŸ“‚ ä» /public/data/factor_data/BTCUSDT_15m_2020_2025_factor_data.pkl åŠ è½½å› å­æ•°æ®...\n",
      "/tmp/ipykernel_349609/126136614.py:20: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  factor_data = pickle.load(f)\n",
      "2025-07-30 23:52:27,516 - INFO - âœ… æ•°æ®åŠ è½½æˆåŠŸ - å½¢çŠ¶: (128448, 141)\n",
      "2025-07-30 23:52:27,517 - INFO - ğŸ“… æ—¶é—´èŒƒå›´: 2021-10-01 00:00:00 è‡³ 2025-05-30 23:45:00\n",
      "2025-07-30 23:52:27,517 - INFO - ğŸ“ˆ ç‰¹å¾æ•°é‡: 91\n",
      "2025-07-30 23:52:27,518 - INFO - ğŸ“Š å‡†å¤‡æ»šåŠ¨è®­ç»ƒæ•°æ®...\n",
      "2025-07-30 23:52:27,518 - INFO - âœ… ä½¿ç”¨ 91 ä¸ªå› å­ç‰¹å¾\n",
      "2025-07-30 23:52:29,143 - INFO - âœ… æ•°æ®å‡†å¤‡å®Œæˆ - æ ·æœ¬æ•°: 128388, æ—¶é—´æ­¥é•¿: 60, ç‰¹å¾æ•°: 91\n",
      "2025-07-30 23:52:29,164 - INFO - ğŸš€ å¼€å§‹æ»šåŠ¨è®­ç»ƒ (n_splits=5)...\n",
      "2025-07-30 23:52:29,165 - INFO - \n",
      "ğŸ” å¤„ç†æŠ˜å  1/5\n",
      "2025-07-30 23:52:29,166 - INFO -   è®­ç»ƒé›†: 2021-10-01 15:00:00 åˆ° 2022-05-12 12:15:00\n",
      "2025-07-30 23:52:29,166 - INFO -   æµ‹è¯•é›†: 2022-05-12 12:30:00 åˆ° 2022-12-21 09:45:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 608ms/step - accuracy: 0.5225 - loss: 1.0673 - val_accuracy: 0.5870 - val_loss: 0.9689 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 587ms/step - accuracy: 0.5210 - loss: 1.0248 - val_accuracy: 0.5870 - val_loss: 0.9726 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 582ms/step - accuracy: 0.5199 - loss: 1.0252 - val_accuracy: 0.5870 - val_loss: 0.9720 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 576ms/step - accuracy: 0.5207 - loss: 1.0248 - val_accuracy: 0.5870 - val_loss: 0.9728 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 588ms/step - accuracy: 0.5194 - loss: 1.0256 - val_accuracy: 0.5870 - val_loss: 0.9726 - learning_rate: 2.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 589ms/step - accuracy: 0.5198 - loss: 1.0254 - val_accuracy: 0.5870 - val_loss: 0.9725 - learning_rate: 2.0000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-30 23:55:28,253 - INFO -   æµ‹è¯•å‡†ç¡®ç‡: 0.5870, æµ‹è¯•æŸå¤±: 0.9689\n",
      "2025-07-30 23:55:29,351 - INFO - \n",
      "ğŸ” å¤„ç†æŠ˜å  2/5\n",
      "2025-07-30 23:55:29,353 - INFO -   è®­ç»ƒé›†: 2021-10-01 15:00:00 åˆ° 2022-12-21 09:45:00\n",
      "2025-07-30 23:55:29,354 - INFO -   æµ‹è¯•é›†: 2022-12-21 10:00:00 åˆ° 2023-08-01 07:15:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m84/84\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 488ms/step - accuracy: 0.5544 - loss: 1.0400 - val_accuracy: 0.7411 - val_loss: 0.8329 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m84/84\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 476ms/step - accuracy: 0.5562 - loss: 0.9947 - val_accuracy: 0.7411 - val_loss: 0.8282 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m84/84\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 476ms/step - accuracy: 0.5512 - loss: 0.9992 - val_accuracy: 0.7411 - val_loss: 0.8317 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m84/84\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 475ms/step - accuracy: 0.5526 - loss: 0.9983 - val_accuracy: 0.7411 - val_loss: 0.8204 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m84/84\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 452ms/step - accuracy: 0.5523 - loss: 0.9984 - val_accuracy: 0.7411 - val_loss: 0.8271 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m84/84\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 465ms/step - accuracy: 0.5560 - loss: 0.9946 - val_accuracy: 0.7411 - val_loss: 0.8252 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m84/84\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 474ms/step - accuracy: 0.5506 - loss: 0.9999 - val_accuracy: 0.7411 - val_loss: 0.8246 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m84/84\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 474ms/step - accuracy: 0.5529 - loss: 0.9976 - val_accuracy: 0.7411 - val_loss: 0.8271 - learning_rate: 2.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m84/84\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 479ms/step - accuracy: 0.5528 - loss: 0.9974 - val_accuracy: 0.7411 - val_loss: 0.8284 - learning_rate: 2.0000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-31 00:02:02,006 - INFO -   æµ‹è¯•å‡†ç¡®ç‡: 0.7411, æµ‹è¯•æŸå¤±: 0.8204\n",
      "2025-07-31 00:02:03,162 - INFO - \n",
      "ğŸ” å¤„ç†æŠ˜å  3/5\n",
      "2025-07-31 00:02:03,163 - INFO -   è®­ç»ƒé›†: 2021-10-01 15:00:00 åˆ° 2023-08-01 07:15:00\n",
      "2025-07-31 00:02:03,164 - INFO -   æµ‹è¯•é›†: 2023-08-01 07:30:00 åˆ° 2024-03-11 04:45:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 446ms/step - accuracy: 0.6168 - loss: 0.9977 - val_accuracy: 0.7166 - val_loss: 0.8156 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 438ms/step - accuracy: 0.6195 - loss: 0.9291 - val_accuracy: 0.7166 - val_loss: 0.8202 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 440ms/step - accuracy: 0.6175 - loss: 0.9311 - val_accuracy: 0.7166 - val_loss: 0.8145 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 436ms/step - accuracy: 0.6181 - loss: 0.9303 - val_accuracy: 0.7166 - val_loss: 0.8209 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 439ms/step - accuracy: 0.6154 - loss: 0.9335 - val_accuracy: 0.7166 - val_loss: 0.8153 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 442ms/step - accuracy: 0.6175 - loss: 0.9311 - val_accuracy: 0.7166 - val_loss: 0.8177 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 439ms/step - accuracy: 0.6198 - loss: 0.9283 - val_accuracy: 0.7166 - val_loss: 0.8172 - learning_rate: 2.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 440ms/step - accuracy: 0.6171 - loss: 0.9320 - val_accuracy: 0.7166 - val_loss: 0.8144 - learning_rate: 2.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 441ms/step - accuracy: 0.6157 - loss: 0.9331 - val_accuracy: 0.7166 - val_loss: 0.8160 - learning_rate: 2.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 438ms/step - accuracy: 0.6187 - loss: 0.9295 - val_accuracy: 0.7166 - val_loss: 0.8170 - learning_rate: 2.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 441ms/step - accuracy: 0.6148 - loss: 0.9342 - val_accuracy: 0.7166 - val_loss: 0.8127 - learning_rate: 2.0000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 441ms/step - accuracy: 0.6159 - loss: 0.9327 - val_accuracy: 0.7166 - val_loss: 0.8145 - learning_rate: 2.0000e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 439ms/step - accuracy: 0.6190 - loss: 0.9293 - val_accuracy: 0.7166 - val_loss: 0.8166 - learning_rate: 2.0000e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 442ms/step - accuracy: 0.6133 - loss: 0.9362 - val_accuracy: 0.7166 - val_loss: 0.8145 - learning_rate: 2.0000e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 442ms/step - accuracy: 0.6159 - loss: 0.9328 - val_accuracy: 0.7166 - val_loss: 0.8151 - learning_rate: 4.0000e-05\n",
      "Epoch 16/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 441ms/step - accuracy: 0.6189 - loss: 0.9292 - val_accuracy: 0.7166 - val_loss: 0.8153 - learning_rate: 4.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-31 00:17:28,500 - INFO -   æµ‹è¯•å‡†ç¡®ç‡: 0.7166, æµ‹è¯•æŸå¤±: 0.8126\n",
      "2025-07-31 00:17:29,843 - INFO - \n",
      "ğŸ” å¤„ç†æŠ˜å  4/5\n",
      "2025-07-31 00:17:29,844 - INFO -   è®­ç»ƒé›†: 2021-10-01 15:00:00 åˆ° 2024-03-11 04:45:00\n",
      "2025-07-31 00:17:29,845 - INFO -   æµ‹è¯•é›†: 2024-03-11 05:00:00 åˆ° 2024-10-20 02:15:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m168/168\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 406ms/step - accuracy: 0.6398 - loss: 0.9668 - val_accuracy: 0.6177 - val_loss: 0.9315 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m168/168\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 417ms/step - accuracy: 0.6412 - loss: 0.9023 - val_accuracy: 0.6177 - val_loss: 0.9316 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m168/168\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 418ms/step - accuracy: 0.6405 - loss: 0.9035 - val_accuracy: 0.6177 - val_loss: 0.9317 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m168/168\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 420ms/step - accuracy: 0.6410 - loss: 0.9023 - val_accuracy: 0.6177 - val_loss: 0.9304 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m168/168\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 418ms/step - accuracy: 0.6408 - loss: 0.9029 - val_accuracy: 0.6177 - val_loss: 0.9327 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m168/168\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 420ms/step - accuracy: 0.6414 - loss: 0.9022 - val_accuracy: 0.6177 - val_loss: 0.9307 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m168/168\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 418ms/step - accuracy: 0.6439 - loss: 0.8991 - val_accuracy: 0.6177 - val_loss: 0.9303 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m168/168\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 416ms/step - accuracy: 0.6393 - loss: 0.9048 - val_accuracy: 0.6177 - val_loss: 0.9315 - learning_rate: 2.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m168/168\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 418ms/step - accuracy: 0.6424 - loss: 0.9004 - val_accuracy: 0.6177 - val_loss: 0.9311 - learning_rate: 2.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m168/168\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 422ms/step - accuracy: 0.6432 - loss: 0.8994 - val_accuracy: 0.6177 - val_loss: 0.9309 - learning_rate: 2.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m168/168\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 417ms/step - accuracy: 0.6430 - loss: 0.9001 - val_accuracy: 0.6177 - val_loss: 0.9312 - learning_rate: 4.0000e-05\n",
      "Epoch 12/30\n",
      "\u001b[1m168/168\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 417ms/step - accuracy: 0.6432 - loss: 0.8994 - val_accuracy: 0.6177 - val_loss: 0.9311 - learning_rate: 4.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-31 00:32:14,262 - INFO -   æµ‹è¯•å‡†ç¡®ç‡: 0.6177, æµ‹è¯•æŸå¤±: 0.9303\n",
      "2025-07-31 00:32:15,503 - INFO - \n",
      "ğŸ” å¤„ç†æŠ˜å  5/5\n",
      "2025-07-31 00:32:15,505 - INFO -   è®­ç»ƒé›†: 2021-10-01 15:00:00 åˆ° 2024-10-20 02:15:00\n",
      "2025-07-31 00:32:15,506 - INFO -   æµ‹è¯•é›†: 2024-10-20 02:30:00 åˆ° 2025-05-30 23:45:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m209/209\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 421ms/step - accuracy: 0.6358 - loss: 0.9624 - val_accuracy: 0.6094 - val_loss: 0.9416 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m209/209\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 410ms/step - accuracy: 0.6350 - loss: 0.9101 - val_accuracy: 0.6094 - val_loss: 0.9445 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m209/209\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 410ms/step - accuracy: 0.6367 - loss: 0.9080 - val_accuracy: 0.6094 - val_loss: 0.9413 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m209/209\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 412ms/step - accuracy: 0.6367 - loss: 0.9079 - val_accuracy: 0.6094 - val_loss: 0.9405 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m209/209\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 408ms/step - accuracy: 0.6359 - loss: 0.9089 - val_accuracy: 0.6094 - val_loss: 0.9419 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m209/209\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 408ms/step - accuracy: 0.6387 - loss: 0.9055 - val_accuracy: 0.6094 - val_loss: 0.9409 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m209/209\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 407ms/step - accuracy: 0.6355 - loss: 0.9094 - val_accuracy: 0.6094 - val_loss: 0.9413 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m209/209\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 396ms/step - accuracy: 0.6390 - loss: 0.9052 - val_accuracy: 0.6094 - val_loss: 0.9406 - learning_rate: 2.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m209/209\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 409ms/step - accuracy: 0.6345 - loss: 0.9107 - val_accuracy: 0.6094 - val_loss: 0.9409 - learning_rate: 2.0000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-31 00:45:50,643 - INFO -   æµ‹è¯•å‡†ç¡®ç‡: 0.6094, æµ‹è¯•æŸå¤±: 0.9405\n",
      "2025-07-31 00:45:52,009 - INFO - \n",
      "âœ… æ»šåŠ¨è®­ç»ƒå®Œæˆ - å¹³å‡å‡†ç¡®ç‡: 0.6544, å¹³å‡æŸå¤±: 0.8946\n",
      "2025-07-31 00:45:52,023 - INFO - ğŸ“¡ ä¿¡å·ç”Ÿæˆå®Œæˆ - åšå¤šæ¯”ä¾‹: 0.00%, åšç©ºæ¯”ä¾‹: 0.00%\n",
      "2025-07-31 00:45:52,060 - INFO - ğŸ’¾ å›æµ‹æ•°æ®å·²ä¿å­˜è‡³ ./_test_backtest_intern.pkl\n",
      "2025-07-31 00:45:52,060 - INFO - ğŸ” ä» ./_test_backtest_intern.pkl åŠ è½½å›æµ‹æ•°æ®...\n",
      "2025-07-31 00:45:52,062 - INFO - ğŸš€ å¼€å§‹æ‰§è¡Œä¼˜åŒ–ç‰ˆå›æµ‹ (åŸºäºå·²å®ç°ç›ˆäº)...\n",
      "2025-07-31 00:45:52,138 - INFO - âœ… ä¼˜åŒ–ç‰ˆå›æµ‹å®Œæˆã€‚\n",
      "2025-07-31 00:45:52,140 - INFO - ğŸ“Š å¼€å§‹è¿›è¡Œå…¨é¢çš„ç­–ç•¥æ€§èƒ½è¯„ä¼°...\n",
      "/tmp/ipykernel_349609/2128235333.py:38: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_returns = df['equity_curve'].resample('M').last().pct_change().dropna()\n",
      "/tmp/ipykernel_349609/2128235333.py:42: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  sharpe_ratio = (monthly_returns.mean() / monthly_returns.std()) * np.sqrt(12) if len(monthly_returns) > 1 else 0\n",
      "/home/wj/miniconda3/envs/tensor_flow/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2999: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/home/wj/miniconda3/envs/tensor_flow/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:3000: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "/home/wj/miniconda3/envs/tensor_flow/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2999: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "2025-07-31 00:45:52,174 - ERROR - âŒ å›æµ‹è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: cannot access local variable 'winning_trades' where it is not associated with a value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "\u001b[36m\u001b[1m                              ç­–ç•¥æ€§èƒ½è¯„ä¼°æŠ¥å‘Š                              \u001b[0m\n",
      "================================================================================\n",
      "\n",
      "\u001b[34m\u001b[1m============================== æ”¶ç›ŠæŒ‡æ ‡ ==============================\u001b[0m\n",
      "+-----------------------+------------+--------+-----------+\n",
      "|       æŒ‡æ ‡åç§°        |  è®¡ç®—ç»“æœ  |  è¦æ±‚  |   çŠ¶æ€    |\n",
      "+=======================+============+========+===========+\n",
      "|   å¤æ™®æ¯”ç‡ (Sharpe)   |    nan     | > 2.0  | \u001b[31mâŒ æœªè¾¾æ ‡\u001b[0m |\n",
      "+-----------------------+------------+--------+-----------+\n",
      "|   å¡ç›æ¯”ç‡ (Calmar)   |     0      | > 5.0  | \u001b[31mâŒ æœªè¾¾æ ‡\u001b[0m |\n",
      "+-----------------------+------------+--------+-----------+\n",
      "| æœŸæœ›æ”¶ç›Š (Expectancy) |     0      | > 0.25 | \u001b[31mâŒ æœªè¾¾æ ‡\u001b[0m |\n",
      "+-----------------------+------------+--------+-----------+\n",
      "\n",
      "\u001b[34m\u001b[1mç­–ç•¥æ–¹æ¡ˆè¯„ä¼°\u001b[0m\n",
      "+----------------------+-----------+\n",
      "|       ç­–ç•¥æ–¹æ¡ˆ       |   çŠ¶æ€    |\n",
      "+======================+===========+\n",
      "| æ–¹æ¡ˆä¸€ (å¤æ™® & å¡ç›) | \u001b[31mâŒ æœªè¾¾æ ‡\u001b[0m |\n",
      "+----------------------+-----------+\n",
      "|  æ–¹æ¡ˆäºŒ (æœŸæœ›æ”¶ç›Š)   | \u001b[31mâŒ æœªè¾¾æ ‡\u001b[0m |\n",
      "+----------------------+-----------+\n",
      "|     ç»¼åˆæ”¶ç›ŠæŒ‡æ ‡     | \u001b[31mâŒ æœªè¾¾æ ‡\u001b[0m |\n",
      "+----------------------+-----------+\n",
      "\n",
      "\u001b[34m\u001b[1mæŒä»“ç»Ÿè®¡\u001b[0m\n",
      "+--------------+-------+\n",
      "|     æŒ‡æ ‡     |  å€¼   |\n",
      "+==============+=======+\n",
      "| å¤šå¤´æŒä»“å æ¯” | 0.00% |\n",
      "+--------------+-------+\n",
      "| ç©ºå¤´æŒä»“å æ¯” | 0.00% |\n",
      "+--------------+-------+\n",
      "\n",
      "\u001b[33m\u001b[1m============================== é£æ§ä¸æ•ˆç‡æŒ‡æ ‡ ==============================\u001b[0m\n",
      "+----------------+------------+--------+-----------+\n",
      "|    æŒ‡æ ‡åç§°    |  è®¡ç®—ç»“æœ  |  è¦æ±‚  |   çŠ¶æ€    |\n",
      "+================+============+========+===========+\n",
      "| æœ€å¤§å›æ’¤ (MDD) |   0.000%   | < 0.2  |  âœ… è¾¾æ ‡  |\n",
      "+----------------+------------+--------+-----------+\n",
      "|  æ¯å‘¨å¼€ä»“é¢‘ç‡  |   0.0000   |  > 5   | \u001b[31mâŒ æœªè¾¾æ ‡\u001b[0m |\n",
      "+----------------+------------+--------+-----------+\n",
      "\n",
      "\u001b[33m\u001b[1mç»¼åˆæŒ‡æ ‡è¯„ä¼°\u001b[0m\n",
      "+--------------+-----------+\n",
      "|     æŒ‡æ ‡     |   çŠ¶æ€    |\n",
      "+==============+===========+\n",
      "| ç»¼åˆé£æ§æŒ‡æ ‡ |  âœ… è¾¾æ ‡  |\n",
      "+--------------+-----------+\n",
      "| ç»¼åˆæ•ˆç‡æŒ‡æ ‡ | \u001b[31mâŒ æœªè¾¾æ ‡\u001b[0m |\n",
      "+--------------+-----------+\n",
      "\n",
      "\u001b[32m\u001b[1m============================== è¯¦ç»†æŒ‡æ ‡ ==============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # --- 1. å‚æ•°é…ç½® ---\n",
    "    FACTOR_FILE = '/public/data/factor_data/BTCUSDT_15m_2020_2025_factor_data.pkl'\n",
    "    OUTPUT_FILE = \"./_test_backtest_intern.pkl\"  # ä¿®æ”¹ä¸ºå½“å‰ç›®å½•\n",
    "    \n",
    "    # å›æµ‹æ ¸å¿ƒå‚æ•°\n",
    "    COMMISSION_RATE = 0.0002     # å•è¾¹æ‰‹ç»­è´¹ (e.g., 0.02%)\n",
    "    INITIAL_CAPITAL = 100000     # åˆå§‹æ¨¡æ‹Ÿèµ„é‡‘\n",
    "    HOLDING_PERIOD = 10          # æ¯ä»½ä»“ä½çš„å›ºå®šæŒæœ‰å‘¨æœŸ (10ä¸ª15åˆ†é’Ÿbar)\n",
    "    \n",
    "    # ConvLSTMæ¨¡å‹å‚æ•°\n",
    "    LOOKBACK_PERIOD = 60         # å›çœ‹æ—¶é—´æ­¥é•¿ (60ä¸ª15åˆ†é’Ÿbar)\n",
    "    N_SPLITS = 5                 # æ—¶é—´åºåˆ—äº¤å‰éªŒè¯åˆ†å‰²æ•°\n",
    "\n",
    "    # --- 2. åŠ è½½å› å­æ•°æ® ---\n",
    "    logging.info(f\"ğŸ“‚ ä» {FACTOR_FILE} åŠ è½½å› å­æ•°æ®...\")\n",
    "    \n",
    "    try:\n",
    "        with open(FACTOR_FILE, 'rb') as f:\n",
    "            factor_data = pickle.load(f)\n",
    "        \n",
    "        # ç¡®ä¿ç´¢å¼•æ˜¯datetimeç±»å‹\n",
    "        factor_data.index = pd.to_datetime(factor_data.index)\n",
    "        \n",
    "        # æå–æ”¶ç›˜ä»·\n",
    "        close_prices = factor_data['close'].copy()\n",
    "        \n",
    "        logging.info(f\"âœ… æ•°æ®åŠ è½½æˆåŠŸ - å½¢çŠ¶: {factor_data.shape}\")\n",
    "        logging.info(f\"ğŸ“… æ—¶é—´èŒƒå›´: {factor_data.index[0]} è‡³ {factor_data.index[-1]}\")\n",
    "        logging.info(f\"ğŸ“ˆ ç‰¹å¾æ•°é‡: {len([col for col in factor_data.columns if col.startswith('c_chu') or col.startswith('c_hide')])}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"âŒ åŠ è½½æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}\")\n",
    "        factor_data = None\n",
    "\n",
    "    # --- 3. å‡†å¤‡æ•°æ®å¹¶æ‰§è¡Œæ»šåŠ¨è®­ç»ƒ ---\n",
    "    if factor_data is not None:\n",
    "        # å‡†å¤‡æ»šåŠ¨è®­ç»ƒæ•°æ®\n",
    "        X, y, indices = prepare_rolling_data(factor_data, lookback=LOOKBACK_PERIOD)\n",
    "        \n",
    "        # æ‰§è¡Œæ»šåŠ¨è®­ç»ƒå¹¶ç”Ÿæˆä¿¡å·\n",
    "        signals = rolling_train_and_predict(X, y, indices, lookback=LOOKBACK_PERIOD, n_splits=N_SPLITS)\n",
    "        \n",
    "        # åˆ›å»ºå®Œæ•´çš„ä¿¡å·åºåˆ—ï¼ˆä¸åŸå§‹æ•°æ®å¯¹é½ï¼‰\n",
    "        # æ³¨æ„ï¼šsignals ç°åœ¨æ˜¯å¸¦æœ‰ç´¢å¼•çš„ Pandas Series\n",
    "        full_signals = pd.Series(0, index=factor_data.index)\n",
    "        full_signals.loc[signals.index] = signals\n",
    "        \n",
    "        # åˆ›å»ºå›æµ‹æ•°æ®\n",
    "        backtest_data = pd.DataFrame({\n",
    "            'signal': full_signals,\n",
    "            'close': close_prices\n",
    "        }, index=factor_data.index)\n",
    "        \n",
    "        # ä¿å­˜å›æµ‹æ•°æ®ï¼ˆåˆ°å½“å‰ç›®å½•ï¼‰\n",
    "        backtest_data.to_pickle(OUTPUT_FILE)\n",
    "        logging.info(f\"ğŸ’¾ å›æµ‹æ•°æ®å·²ä¿å­˜è‡³ {OUTPUT_FILE}\")\n",
    "    else:\n",
    "        logging.warning(\"âš ï¸ ç”±äºæ•°æ®åŠ è½½å¤±è´¥ï¼Œè·³è¿‡æ¨¡å‹è®­ç»ƒå’Œä¿¡å·ç”Ÿæˆæ­¥éª¤\")\n",
    "\n",
    "    # --- 4. æ‰§è¡Œå›æµ‹ä¸è¯„ä¼° ---\n",
    "    if os.path.exists(OUTPUT_FILE):\n",
    "        logging.info(f\"ğŸ” ä» {OUTPUT_FILE} åŠ è½½å›æµ‹æ•°æ®...\")\n",
    "        \n",
    "        try:\n",
    "            with open(OUTPUT_FILE, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "            \n",
    "            # è°ƒç”¨æ ¸å¿ƒå›æµ‹å‡½æ•°\n",
    "            backtest_results, trade_history = run_realized_pnl_backtest(\n",
    "                prices=data['close'],\n",
    "                signals=data['signal'],\n",
    "                initial_capital=INITIAL_CAPITAL,\n",
    "                commission_rate=COMMISSION_RATE,\n",
    "                holding_period=HOLDING_PERIOD\n",
    "            )\n",
    "\n",
    "            # è°ƒç”¨æ ¸å¿ƒè¯„ä¼°å‡½æ•°\n",
    "            evaluate_realized_pnl_performance(\n",
    "                backtest_results,\n",
    "                trade_history,\n",
    "                INITIAL_CAPITAL\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logging.error(f\"âŒ å›æµ‹è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}\")\n",
    "    else:\n",
    "        logging.warning(\"âš ï¸ å›æµ‹æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡å›æµ‹æ­¥éª¤\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor_flow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
