{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "000141cc",
   "metadata": {},
   "source": [
    "# 量化策略回测框架 - ConvLSTM模型集成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "733e7c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 必要的库导入 ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import logging\n",
    "from pandas.tseries.offsets import Week\n",
    "from tabulate import tabulate\n",
    "from colorama import Fore, Style, Back\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from collections import deque\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Conv1D, LSTM, Dense, Dropout, BatchNormalization, Flatten, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import classification_report\n",
    "import gc  # 用于内存管理\n",
    "\n",
    "# 忽略Pandas在特定操作中可能产生的无害警告\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# 配置日志输出格式\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# 设置绘图风格\n",
    "plt.style.use('seaborn-v0_8-darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a587b5",
   "metadata": {},
   "source": [
    "---\n",
    "## ConvLSTM模型构建与训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62cf9228",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_conv_lstm_model(input_shape, num_features):\n",
    "    \"\"\"\n",
    "    构建ConvLSTM混合模型架构\n",
    "    \n",
    "    模型设计理念:\n",
    "    1. 使用1D卷积层提取局部特征模式\n",
    "    2. LSTM层捕捉时间序列依赖关系\n",
    "    3. 深度残差连接增强信息流动\n",
    "    4. 批归一化和Dropout提高泛化能力\n",
    "    \n",
    "    参数:\n",
    "    - input_shape: 输入数据形状 (时间步长, 特征数)\n",
    "    - num_features: 特征数量\n",
    "    \n",
    "    返回:\n",
    "    - 编译好的Keras模型\n",
    "    \"\"\"\n",
    "    # 输入层\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # 1D卷积分支 - 提取局部特征\n",
    "    conv1 = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Dropout(0.2)(conv1)\n",
    "    \n",
    "    conv2 = Conv1D(filters=128, kernel_size=5, activation='relu', padding='same')(conv1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Dropout(0.2)(conv2)\n",
    "    \n",
    "    # LSTM分支 - 捕捉时序依赖\n",
    "    lstm1 = LSTM(64, return_sequences=True)(inputs)\n",
    "    lstm1 = BatchNormalization()(lstm1)\n",
    "    lstm1 = Dropout(0.2)(lstm1)\n",
    "    \n",
    "    lstm2 = LSTM(128, return_sequences=False)(lstm1)\n",
    "    lstm2 = BatchNormalization()(lstm2)\n",
    "    lstm2 = Dropout(0.3)(lstm2)\n",
    "    \n",
    "    # 合并分支\n",
    "    merged = concatenate([Flatten()(conv2), lstm2])\n",
    "    \n",
    "    # 全连接层\n",
    "    dense1 = Dense(256, activation='relu')(merged)\n",
    "    dense1 = BatchNormalization()(dense1)\n",
    "    dense1 = Dropout(0.4)(dense1)\n",
    "    \n",
    "    dense2 = Dense(128, activation='relu')(dense1)\n",
    "    dense2 = BatchNormalization()(dense2)\n",
    "    dense2 = Dropout(0.3)(dense2)\n",
    "    \n",
    "    # 输出层 - 三分类(做多/做空/中性)\n",
    "    outputs = Dense(3, activation='softmax')(dense2)\n",
    "    \n",
    "    # 创建模型\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # 编译模型\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "084031ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_rolling_data(factor_data, lookback=60, test_size=0.2):\n",
    "    \"\"\"\n",
    "    准备滚动训练数据\n",
    "    \n",
    "    参数:\n",
    "    - factor_data: 因子数据DataFrame\n",
    "    - lookback: 回看时间步长\n",
    "    - test_size: 测试集比例（用于验证）\n",
    "    \n",
    "    返回:\n",
    "    - 特征、标签和标准化器\n",
    "    \"\"\"\n",
    "    logging.info(\"📊 准备滚动训练数据...\")\n",
    "    \n",
    "    # 提取特征和目标\n",
    "    feature_columns = [col for col in factor_data.columns \n",
    "                      if col.startswith('c_chu') or col.startswith('c_hide')]\n",
    "    \n",
    "    logging.info(f\"✅ 使用 {len(feature_columns)} 个因子特征\")\n",
    "    \n",
    "    # 特征预处理 - 填充缺失值\n",
    "    features = factor_data[feature_columns].values\n",
    "    \n",
    "    # 创建目标变量 - 未来10期收益率方向\n",
    "    future_returns = factor_data['close'].pct_change(10).shift(-10)\n",
    "    y = np.zeros(len(future_returns))\n",
    "    \n",
    "    # 分类标签: 1(做多), -1(做空), 0(中性)\n",
    "    y[future_returns > 0.005] = 1    # 显著上涨\n",
    "    y[future_returns < -0.005] = 2   # 显著下跌\n",
    "    y = tf.keras.utils.to_categorical(y, num_classes=3)\n",
    "    \n",
    "    # 创建时间序列样本\n",
    "    X = []\n",
    "    valid_indices = []\n",
    "    \n",
    "    for i in range(lookback, len(features)):\n",
    "        X.append(features[i-lookback:i])\n",
    "        valid_indices.append(i)\n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = y[valid_indices]\n",
    "    indices = factor_data.index[valid_indices]\n",
    "    \n",
    "    logging.info(f\"✅ 数据准备完成 - 样本数: {X.shape[0]}, 时间步长: {X.shape[1]}, 特征数: {X.shape[2]}\")\n",
    "    return X, y, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f69690be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_train_and_predict(X, y, indices, lookback=60, n_splits=5):\n",
    "    \"\"\"\n",
    "    执行滚动训练和预测\n",
    "    \n",
    "    参数:\n",
    "    - X: 特征数据\n",
    "    - y: 标签数据\n",
    "    - indices: 时间索引\n",
    "    - lookback: 回看时间步长\n",
    "    - n_splits: 时间序列分割数\n",
    "    \n",
    "    返回:\n",
    "    - 预测信号Series\n",
    "    \"\"\"\n",
    "    logging.info(f\"🚀 开始滚动训练 (n_splits={n_splits})...\")\n",
    "    \n",
    "    # 初始化预测结果数组\n",
    "    all_predictions = np.zeros((len(y), 3))\n",
    "    \n",
    "    # 创建时间序列交叉验证器\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    \n",
    "    # 用于存储每个折叠的性能\n",
    "    fold_accuracies = []\n",
    "    fold_losses = []\n",
    "    \n",
    "    for fold, (train_index, test_index) in enumerate(tscv.split(X)):\n",
    "        logging.info(f\"\\n🔁 处理折叠 {fold+1}/{n_splits}\")\n",
    "        logging.info(f\"  训练集: {indices[train_index[0]]} 到 {indices[train_index[-1]]}\")\n",
    "        logging.info(f\"  测试集: {indices[test_index[0]]} 到 {indices[test_index[-1]]}\")\n",
    "        \n",
    "        # 划分训练集和测试集\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # 标准化 - 使用训练集的统计量\n",
    "        scaler = StandardScaler()\n",
    "        X_train_2d = X_train.reshape(-1, X_train.shape[-1])\n",
    "        X_test_2d = X_test.reshape(-1, X_test.shape[-1])\n",
    "        \n",
    "        scaler.fit(X_train_2d)\n",
    "        X_train_scaled = scaler.transform(X_train_2d).reshape(X_train.shape)\n",
    "        X_test_scaled = scaler.transform(X_test_2d).reshape(X_test.shape)\n",
    "        \n",
    "        # 构建模型\n",
    "        model = build_conv_lstm_model((lookback, X_train.shape[2]), X_train.shape[2])\n",
    "        \n",
    "        # 回调函数\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
    "        ]\n",
    "        \n",
    "        # 训练模型\n",
    "        history = model.fit(\n",
    "            X_train_scaled, y_train,\n",
    "            epochs=30,\n",
    "            batch_size=512,\n",
    "            validation_data=(X_test_scaled, y_test),\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # 在测试集上预测\n",
    "        test_pred = model.predict(X_test_scaled, batch_size=1024, verbose=0)\n",
    "        all_predictions[test_index] = test_pred\n",
    "        \n",
    "        # 评估性能\n",
    "        test_loss, test_acc = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "        fold_accuracies.append(test_acc)\n",
    "        fold_losses.append(test_loss)\n",
    "        logging.info(f\"  测试准确率: {test_acc:.4f}, 测试损失: {test_loss:.4f}\")\n",
    "        \n",
    "        # 清理内存\n",
    "        del model, X_train, X_test, y_train, y_test\n",
    "        gc.collect()\n",
    "        tf.keras.backend.clear_session()\n",
    "    \n",
    "    # 打印整体性能\n",
    "    logging.info(f\"\\n✅ 滚动训练完成 - 平均准确率: {np.mean(fold_accuracies):.4f}, 平均损失: {np.mean(fold_losses):.4f}\")\n",
    "    \n",
    "    # 转换预测结果为信号\n",
    "    signal_labels = np.argmax(all_predictions, axis=1)\n",
    "    signals = np.zeros(len(indices))\n",
    "    signals = np.where(signal_labels == 1, 1, np.where(signal_labels == 2, -1, 0))\n",
    "    \n",
    "    # 创建信号Series并设置索引\n",
    "    signal_series = pd.Series(signals, index=indices)\n",
    "    \n",
    "    # 平滑信号 - 避免频繁变动\n",
    "    signal_series = signal_series.rolling(window=4, min_periods=1).mean()\n",
    "    signal_series = pd.Series(\n",
    "        np.where(signal_series > 0.33, 1, np.where(signal_series < -0.33, -1, 0)),\n",
    "        index=indices\n",
    "    )\n",
    "    \n",
    "    logging.info(f\"📡 信号生成完成 - 做多比例: {(signal_series == 1).mean():.2%}, \"\n",
    "                 f\"做空比例: {(signal_series == -1).mean():.2%}\")\n",
    "    \n",
    "    return signal_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63784ec",
   "metadata": {},
   "source": [
    "## 2. 核心回测与评估函数 (保持不变)\n",
    "(此处保留原有的run_realized_pnl_backtest和evaluate_realized_pnl_performance函数)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f3d8a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_realized_pnl_backtest(prices, signals, initial_capital=100000, commission_rate=0.0002, holding_period=10):\n",
    "    \"\"\"\n",
    "    执行基于已实现盈亏的高性能回测。\n",
    "\n",
    "    本函数为回测框架的核心，其设计严格遵循以下交易逻辑：\n",
    "    1. **资金管理**: 初始资金被等分为10份，每次开仓使用一份，用于模拟分批建仓。\n",
    "    2. **单向持仓**: 在任何时间点，所有持仓的方向必须一致（全为多头或全为空头），不允许锁仓或同时持有多空。\n",
    "    3. **事件驱动**: 交易信号在t-1时刻产生，在t时刻执行。\n",
    "    4. **固定持有期**: 每份独立的仓位最多持有`holding_period`个周期，到期后自动平仓。\n",
    "    5. **渐进式调仓**: 当收到与当前持仓方向相反的信号时，仅平掉**最早开立**的一份仓位，而非全部平仓，以实现更平滑的调仓，减少交易冲击。\n",
    "    6. **已实现盈亏**: 权益曲线的计算完全基于已关闭仓位的真实盈亏，忽略未平仓位的浮动盈亏，使结果更保守稳健。\n",
    "\n",
    "    性能优化关键点:\n",
    "    - **预分配数组**: 使用NumPy数组预先分配内存来存储回测结果，避免在循环中动态修改Pandas DataFrame，这是主要的性能提升来源。\n",
    "    - **高效队列操作**: 利用`collections.deque`的O(1)时间复杂度的`popleft()`和`append()`操作管理活跃仓位。\n",
    "    - **算法优化**: 检查到期仓位时，仅需检查队列头部的最早仓位，无需遍历整个队列。\n",
    "\n",
    "    参数:\n",
    "    - prices (pd.Series): 资产的收盘价序列。\n",
    "    - signals (pd.Series): 交易信号序列 (1: 做多, -1: 做空, 0: 中性)。\n",
    "    - initial_capital (float): 初始总资本。\n",
    "    - commission_rate (float): 单边交易手续费率。\n",
    "    - holding_period (int): 每份仓位的最大持有周期（单位：K线数量）。\n",
    "\n",
    "    返回:\n",
    "    - pd.DataFrame: 包含回测详细过程（如持仓、成本、权益等）的DataFrame。\n",
    "    - pd.DataFrame: 包含每一笔已完成交易的详细历史记录。\n",
    "    \"\"\"\n",
    "    logging.info(\"🚀 开始执行优化版回测 (基于已实现盈亏)...\")\n",
    "\n",
    "    n = len(prices)\n",
    "    # --- 性能优化: 预分配结果存储 ---\n",
    "    # 将结果存储在字典包裹的NumPy数组中，循环结束后一次性生成DataFrame。\n",
    "    # 这比在循环中逐行填充DataFrame（如使用.at或.loc）快几个数量级。\n",
    "    results = {\n",
    "        'position': np.zeros(n, dtype=np.int8),\n",
    "        'position_count': np.zeros(n, dtype=np.int8),\n",
    "        'cost_basis': np.zeros(n),\n",
    "        'transaction_costs': np.zeros(n),\n",
    "        'net_returns': np.zeros(n),\n",
    "        'equity_curve': np.full(n, initial_capital)\n",
    "    }\n",
    "\n",
    "    # --- 性能优化: 预提取数据到NumPy数组 ---\n",
    "    # 在循环开始前将Pandas Series转换为NumPy数组，后续在循环中访问数组元素比访问Series元素更快。\n",
    "    close_arr = prices.values\n",
    "    signal_arr = signals.values\n",
    "    indices = prices.index # 预存索引，用于记录交易历史\n",
    "\n",
    "    # --- 初始化交易状态变量 ---\n",
    "    active_positions = deque()  # 使用双端队列(deque)高效管理先进先出的持仓\n",
    "    realized_pnl = 0.0          # 累计已实现盈亏\n",
    "    position_direction = 0      # 当前整体持仓方向 (1: 多, -1: 空, 0: 无)\n",
    "    position_cost = 0.0         # 当前持仓的平均成本价\n",
    "    trade_history = []          # 记录每一笔完整交易的列表\n",
    "    capital_per_position = initial_capital / 10 # 每份仓位分配的资金\n",
    "\n",
    "    # --- 主回测循环 ---\n",
    "    # 从第二个时间点开始遍历，因为交易决策基于前一天的信号\n",
    "    for i in range(1, n):\n",
    "        current_close = close_arr[i]\n",
    "        prev_signal = signal_arr[i-1]  # 使用t-1的信号决定t时刻的操作\n",
    "        trades_occurred = False        # 标记当日是否有交易（平仓）发生\n",
    "\n",
    "        # 1. 处理到期强制平仓\n",
    "        # --- 性能优化: O(1)复杂度的到期检查 ---\n",
    "        # 由于active_positions是先进先出队列，我们只需检查队头（最早的仓位）。\n",
    "        # 如果队头没到期，那么队列中所有其他仓位也一定没到期。\n",
    "        while active_positions:\n",
    "            oldest_pos = active_positions[0] # 只看不取\n",
    "            if i - oldest_pos['entry_index'] >= holding_period:\n",
    "                # 仓位已到期，执行平仓\n",
    "                pos_to_close = active_positions.popleft() # 从队列中移除\n",
    "                exit_price = current_close\n",
    "                \n",
    "                # 计算盈亏\n",
    "                pnl = (exit_price - pos_to_close['entry_price']) * pos_to_close['direction'] * pos_to_close['quantity']\n",
    "                exit_commission = commission_rate * exit_price * pos_to_close['quantity']\n",
    "                net_pnl = pnl - exit_commission\n",
    "                \n",
    "                # 更新累计已实现盈亏\n",
    "                realized_pnl += net_pnl\n",
    "                trades_occurred = True\n",
    "                \n",
    "                # 记录交易成本\n",
    "                results['transaction_costs'][i] += exit_commission\n",
    "                \n",
    "                # 记录交易历史\n",
    "                trade_history.append({\n",
    "                    'entry_time': indices[pos_to_close['entry_index']], 'exit_time': indices[i],\n",
    "                    'direction': pos_to_close['direction'], 'entry_price': pos_to_close['entry_price'],\n",
    "                    'exit_price': exit_price, 'quantity': pos_to_close['quantity'],\n",
    "                    'pnl': pnl, 'commission': exit_commission, 'net_pnl': net_pnl,\n",
    "                    'duration': i - pos_to_close['entry_index'], 'type': 'expired'\n",
    "                })\n",
    "            else:\n",
    "                # 最早的仓位都未到期，则无需继续检查\n",
    "                break\n",
    "\n",
    "        # 2. 根据新信号处理交易\n",
    "        if prev_signal != 0:  # 只对非中性信号做出反应\n",
    "            # 情况A: 当前无任何持仓，且有新信号\n",
    "            if position_direction == 0:\n",
    "                # 开立第一份仓位\n",
    "                quantity = capital_per_position / current_close\n",
    "                active_positions.append({\n",
    "                    'direction': prev_signal,\n",
    "                    'entry_price': current_close,\n",
    "                    'quantity': quantity,\n",
    "                    'entry_index': i\n",
    "                })\n",
    "                position_direction = prev_signal\n",
    "                position_cost = current_close\n",
    "                entry_commission = commission_rate * current_close * quantity\n",
    "                results['transaction_costs'][i] += entry_commission\n",
    "                results['position'][i] = prev_signal\n",
    "\n",
    "            # 情况B: 新信号与当前持仓方向相同 (加仓)\n",
    "            elif position_direction == prev_signal and len(active_positions) < 10:\n",
    "                # 如果仓位未满10份，则加开一份新仓\n",
    "                quantity = capital_per_position / current_close\n",
    "                active_positions.append({\n",
    "                    'direction': prev_signal, 'entry_price': current_close,\n",
    "                    'quantity': quantity, 'entry_index': i\n",
    "                })\n",
    "                # 更新平均持仓成本\n",
    "                total_quantity = sum(p['quantity'] for p in active_positions)\n",
    "                total_cost = sum(p['entry_price'] * p['quantity'] for p in active_positions)\n",
    "                position_cost = total_cost / total_quantity\n",
    "                entry_commission = commission_rate * current_close * quantity\n",
    "                results['transaction_costs'][i] += entry_commission\n",
    "                results['position'][i] = prev_signal\n",
    "\n",
    "            # 情况C: 新信号与当前持仓方向相反 (部分平仓)\n",
    "            elif position_direction != prev_signal and active_positions:\n",
    "                # 核心逻辑：只平掉最早的一份仓位，实现渐进式调仓\n",
    "                pos_to_close = active_positions.popleft()\n",
    "                exit_price = current_close\n",
    "                pnl = (exit_price - pos_to_close['entry_price']) * pos_to_close['direction'] * pos_to_close['quantity']\n",
    "                exit_commission = commission_rate * exit_price * pos_to_close['quantity']\n",
    "                net_pnl = pnl - exit_commission\n",
    "\n",
    "                realized_pnl += net_pnl\n",
    "                trades_occurred = True\n",
    "                results['transaction_costs'][i] += exit_commission\n",
    "\n",
    "                trade_history.append({\n",
    "                    'entry_time': indices[pos_to_close['entry_index']], 'exit_time': indices[i],\n",
    "                    'direction': pos_to_close['direction'], 'entry_price': pos_to_close['entry_price'],\n",
    "                    'exit_price': exit_price, 'quantity': pos_to_close['quantity'],\n",
    "                    'pnl': pnl, 'commission': exit_commission, 'net_pnl': net_pnl,\n",
    "                    'duration': i - pos_to_close['entry_index'], 'type': 'signal'\n",
    "                })\n",
    "\n",
    "                # 更新持仓状态\n",
    "                if active_positions:\n",
    "                    # 如果平仓后仍有持仓，重新计算平均成本\n",
    "                    total_quantity = sum(p['quantity'] for p in active_positions)\n",
    "                    total_cost = sum(p['entry_price'] * p['quantity'] for p in active_positions)\n",
    "                    position_cost = total_cost / total_quantity\n",
    "                else:\n",
    "                    # 如果所有仓位都已平掉，重置持仓状态\n",
    "                    position_direction = 0\n",
    "                    position_cost = 0.0\n",
    "                results['position'][i] = position_direction\n",
    "\n",
    "        # 3. 更新每日状态\n",
    "        results['position_count'][i] = len(active_positions)\n",
    "        results['cost_basis'][i] = position_cost\n",
    "        results['equity_curve'][i] = initial_capital + realized_pnl # 权益曲线仅随已实现盈亏变化\n",
    "\n",
    "        # 4. 计算当日净收益率 (仅在有平仓交易时发生变化)\n",
    "        if i > 0: # 从第二天开始计算\n",
    "            prev_equity = results['equity_curve'][i-1]\n",
    "            if trades_occurred:\n",
    "                results['net_returns'][i] = (results['equity_curve'][i] - prev_equity) / prev_equity\n",
    "            # 如果没有交易，净收益为0，数组默认就是0，无需操作\n",
    "\n",
    "    # --- 回测期末处理 ---\n",
    "    # 将所有剩余的未平仓头寸在最后一个交易日强制平仓\n",
    "    if active_positions:\n",
    "        last_close = close_arr[-1]\n",
    "        for pos in active_positions:\n",
    "            exit_price = last_close\n",
    "            pnl = (exit_price - pos['entry_price']) * pos['direction'] * pos['quantity']\n",
    "            exit_commission = commission_rate * exit_price * pos['quantity']\n",
    "            net_pnl = pnl - exit_commission\n",
    "            realized_pnl += net_pnl\n",
    "            results['transaction_costs'][-1] += exit_commission\n",
    "\n",
    "            trade_history.append({\n",
    "                'entry_time': indices[pos['entry_index']],\n",
    "                'exit_time': indices[-1],\n",
    "                'direction': pos['direction'],\n",
    "                'entry_price': pos['entry_price'],\n",
    "                'exit_price': exit_price,\n",
    "                'quantity': pos['quantity'],\n",
    "                'pnl': pnl,\n",
    "                'commission': exit_commission,\n",
    "                'net_pnl': net_pnl,\n",
    "                'duration': n - 1 - pos['entry_index'],\n",
    "                'type': 'forced_close'\n",
    "            })\n",
    "            \n",
    "        # 更新最终的权益和收益率\n",
    "        results['equity_curve'][-1] = initial_capital + realized_pnl\n",
    "        prev_equity = results['equity_curve'][-2] if n > 1 else initial_capital\n",
    "        results['net_returns'][-1] = (results['equity_curve'][-1] - prev_equity) / prev_equity\n",
    "\n",
    "    # --- 整合结果 ---\n",
    "    # 使用预先计算好的NumPy数组，一次性创建最终的DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'close': prices,\n",
    "        'signal': signals,\n",
    "        'position': results['position'],\n",
    "        'position_count': results['position_count'],\n",
    "        'cost_basis': results['cost_basis'],\n",
    "        'transaction_costs': results['transaction_costs'],\n",
    "        'net_returns': results['net_returns'],\n",
    "        'equity_curve': results['equity_curve']\n",
    "    }, index=prices.index)\n",
    "\n",
    "    logging.info(\"✅ 优化版回测完成。\")\n",
    "    return df, pd.DataFrame(trade_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94dc0e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_realized_pnl_performance(backtest_results, trade_history, initial_capital):\n",
    "    \"\"\"\n",
    "    全面评估基于已实现盈亏的策略表现，并生成标准化报告。\n",
    "\n",
    "    关键评估逻辑:\n",
    "    - **标准化指标**: 夏普比率等关键风险指标基于月度收益率计算，以提供更稳健、更具可比性的评估。\n",
    "    - **向量化计算**: 尽可能使用Pandas和NumPy的向量化功能，以提高计算效率。\n",
    "    - **精确交易统计**: 所有交易相关指标（胜率、盈亏比等）均基于`trade_history` DataFrame进行精确计算。\n",
    "    - **可视化报告**: 生成清晰的权益曲线图和多维度、格式化的性能指标表格。\n",
    "    \"\"\"\n",
    "    logging.info(\"📊 开始进行全面的策略性能评估...\")\n",
    "\n",
    "    df = backtest_results.copy()\n",
    "    trade_df = trade_history.copy()\n",
    "\n",
    "    # --- 1. 核心收益与风险指标 ---\n",
    "    final_equity = df['equity_curve'].iloc[-1]\n",
    "    total_return = (final_equity - initial_capital) / initial_capital\n",
    "\n",
    "    # 向量化计算回撤 (Drawdown)\n",
    "    equity_curve = df['equity_curve']\n",
    "    peak = equity_curve.expanding(min_periods=1).max() # 计算滚动最高点\n",
    "    drawdown = (peak - equity_curve) / peak            # 计算回撤百分比\n",
    "    max_drawdown = drawdown.max()                      # 获取最大回撤\n",
    "    \n",
    "    # 找到最大回撤\n",
    "    mdd_end = drawdown.idxmax() if not drawdown.empty else None # 最大回撤结束点\n",
    "    mdd_start = peak[:mdd_end].idxmax() if mdd_end is not None else None # 最大回撤开始点\n",
    "\n",
    "    # 计算年化指标\n",
    "    total_days = (df.index[-1] - df.index[0]).days\n",
    "    duration_years = max(total_days / 365.25, 0.001)  # 避免除以零，最短为0.001年\n",
    "    annualized_return = total_return / duration_years\n",
    "\n",
    "    # --- 2. 标准化风险调整后收益 (Standardized Risk-Adjusted Metrics) ---\n",
    "    # 关键修正：为遵循行业稳健标准，避免高频数据对指标的扭曲，\n",
    "    # 夏普比率等指标应基于频率较低（如月度）的收益率计算。\n",
    "    monthly_returns = df['equity_curve'].resample('M').last().pct_change().dropna()\n",
    "\n",
    "    # 夏普比率 (Sharpe Ratio)\n",
    "    # 公式: 年化(月度平均收益 / 月度收益标准差)\n",
    "    sharpe_ratio = (monthly_returns.mean() / monthly_returns.std()) * np.sqrt(12) if len(monthly_returns) > 1 else 0\n",
    "\n",
    "    # 卡玛比率 (Calmar Ratio)\n",
    "    # 公式: 年化收益率 / 最大回撤\n",
    "    calmar_ratio = annualized_return / max_drawdown if max_drawdown > 0 else 0\n",
    "    \n",
    "    # 年化波动率 (基于日净收益率计算)\n",
    "    annualized_volatility = df['net_returns'].std() * np.sqrt(365.25) # 假设一年有365.25个交易日\n",
    "\n",
    "    # --- 3. 交易统计 (基于精确的交易历史) ---\n",
    "    total_trades = len(trade_df)\n",
    "    if total_trades > 0:\n",
    "        winning_trades = trade_df[trade_df['net_pnl'] > 0]\n",
    "        losing_trades = trade_df[trade_df['net_pnl'] <= 0]\n",
    "\n",
    "        win_rate = len(winning_trades) / total_trades\n",
    "        # 平均盈/亏计算的是占初始资本的百分比\n",
    "        avg_win = winning_trades['net_pnl'].mean() / initial_capital if len(winning_trades) > 0 else 0\n",
    "        avg_loss = losing_trades['net_pnl'].mean() / initial_capital if len(losing_trades) > 0 else 0\n",
    "        # 盈亏比\n",
    "        profit_factor = abs(winning_trades['net_pnl'].sum() / losing_trades['net_pnl'].abs().sum()) if len(losing_trades) > 0 and losing_trades['net_pnl'].abs().sum() > 0 else float('inf')\n",
    "        # 期望收益\n",
    "        expectancy = (win_rate * avg_win) + ((1 - win_rate) * avg_loss)\n",
    "    else:\n",
    "        # 如果没有交易，所有指标设为0\n",
    "        win_rate = avg_win = avg_loss = profit_factor = expectancy = 0\n",
    "\n",
    "    # --- 4. 其他辅助指标 ---\n",
    "    # 持仓比例 (向量化计算)\n",
    "    long_ratio = (df['position'] > 0).mean()\n",
    "    short_ratio = (df['position'] < 0).mean()\n",
    "\n",
    "    # 每周开仓频率\n",
    "    weekly_trades = trade_df.resample('W', on='entry_time').size().mean() if not trade_df.empty else 0\n",
    "\n",
    "    # 年化换手率 (Annualized Turnover)\n",
    "    if total_trades > 0:\n",
    "        # 名义本金 = 价格 * 数量\n",
    "        trade_df['entry_notional'] = trade_df['entry_price'] * trade_df['quantity']\n",
    "        trade_df['exit_notional'] = trade_df['exit_price'] * trade_df['quantity']\n",
    "        # 总交易额 = (买入总额 + 卖出总额) / 2\n",
    "        total_turnover = (trade_df['entry_notional'].sum() + trade_df['exit_notional'].sum()) / 2\n",
    "        avg_net_assets = df['equity_curve'].mean()\n",
    "        # 年化换手率 = (总交易额 / 平均净资产) / 年数\n",
    "        annualized_turnover = (total_turnover / avg_net_assets) / duration_years\n",
    "    else:\n",
    "        annualized_turnover = 0\n",
    "\n",
    "    # 信息系数 (Information Coefficient, IC)\n",
    "    # 衡量信号对下一期收益的预测能力\n",
    "    forward_returns = df['close'].pct_change().shift(-1)\n",
    "    # 确保信号和未来收益对齐，且无空值\n",
    "    valid_idx = df['signal'].shift(1).notna() & forward_returns.notna()\n",
    "    ic = np.corrcoef(df['signal'].shift(1)[valid_idx], forward_returns[valid_idx])[0, 1]\n",
    "\n",
    "    # 逐年收益率\n",
    "    yearly_returns = []\n",
    "    for year, group in df.groupby(df.index.year):\n",
    "        if len(group) > 1:\n",
    "            start_equity = group['equity_curve'].iloc[0]\n",
    "            end_equity = group['equity_curve'].iloc[-1]\n",
    "            yearly_return = (end_equity - start_equity) / start_equity\n",
    "            yearly_returns.append((year, yearly_return))\n",
    "\n",
    "    # --- 5. 基准计算 ---\n",
    "    # 理论基准: 完美预测下的理论收益 (信号 * 未来10期收益)，用于衡量信号质量\n",
    "    future_return = (df['close'].shift(-10) - df['close']) / df['close']\n",
    "    # 乘以0.1是因为策略每次只投入1/10的资金\n",
    "    theoretical_benchmark = (df['signal'].shift(1) * future_return * 0.1).fillna(0).cumsum()\n",
    "    strategy_cumulative = (df['equity_curve'] - initial_capital) / initial_capital\n",
    "    correlation = strategy_cumulative.corr(theoretical_benchmark)\n",
    "\n",
    "    # 买入并持有基准 (Buy & Hold)\n",
    "    buy_hold_curve = initial_capital * (df['close'] / df['close'].iloc[0])\n",
    "\n",
    "    # --- 6. 生成格式化报告 ---\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(Fore.CYAN + Style.BRIGHT + \" \" * 30 + \"策略性能评估报告\" + \" \" * 30 + Style.RESET_ALL)\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(\"\\n\" + Fore.BLUE + Style.BRIGHT + \"=\"*30 + \" 收益指标 \" + \"=\"*30 + Style.RESET_ALL)\n",
    "    detail_headers = [\"指标名称\", \"计算结果\", \"要求\", \"状态\"]\n",
    "    \n",
    "    sharpe_status = \"✅ 达标\" if sharpe_ratio >= 2.0 else Fore.RED + \"❌ 未达标\" + Style.RESET_ALL\n",
    "    calmar_status = \"✅ 达标\" if calmar_ratio >= 5.0 else Fore.RED + \"❌ 未达标\" + Style.RESET_ALL\n",
    "    expectancy_status = \"✅ 达标\" if expectancy >= 0.25 else Fore.RED + \"❌ 未达标\" + Style.RESET_ALL\n",
    "    \n",
    "    detail_table = [\n",
    "        [\"夏普比率 (Sharpe)\", f\"{sharpe_ratio:.4f}\", \"> 2.0\", sharpe_status],\n",
    "        [\"卡玛比率 (Calmar)\", f\"{calmar_ratio:.4f}\", \"> 5.0\", calmar_status],\n",
    "        [\"期望收益 (Expectancy)\", f\"{expectancy:.4f}\", \"> 0.25\", expectancy_status]\n",
    "    ]\n",
    "    print(tabulate(detail_table, headers=detail_headers, tablefmt=\"grid\", stralign=\"center\", numalign=\"center\"))\n",
    "    \n",
    "    print(\"\\n\" + Fore.BLUE + Style.BRIGHT + \"策略方案评估\" + Style.RESET_ALL)\n",
    "    scheme_table = [\n",
    "        [\"方案一 (夏普 & 卡玛)\", \"✅ 达标\" if sharpe_ratio >= 2.0 and calmar_ratio >= 5.0 else Fore.RED + \"❌ 未达标\" + Style.RESET_ALL],\n",
    "        [\"方案二 (期望收益)\", \"✅ 达标\" if expectancy >= 0.25 else Fore.RED + \"❌ 未达标\" + Style.RESET_ALL],\n",
    "        [\"综合收益指标\", \"✅ 达标\" if sharpe_ratio >= 2.0 and calmar_ratio >= 5.0 and expectancy >= 0.25 else Fore.RED + \"❌ 未达标\" + Style.RESET_ALL]\n",
    "    ]\n",
    "    print(tabulate(scheme_table, headers=[\"策略方案\", \"状态\"], tablefmt=\"grid\", stralign=\"center\", numalign=\"center\"))\n",
    "    \n",
    "    print(\"\\n\" + Fore.BLUE + Style.BRIGHT + \"持仓统计\" + Style.RESET_ALL)\n",
    "    position_table = [\n",
    "        [\"多头持仓占比\", f\"{long_ratio:.2%}\"],\n",
    "        [\"空头持仓占比\", f\"{short_ratio:.2%}\"]\n",
    "    ]\n",
    "    print(tabulate(position_table, headers=[\"指标\", \"值\"], tablefmt=\"grid\", stralign=\"center\", numalign=\"center\"))\n",
    "    \n",
    "    print(\"\\n\" + Fore.YELLOW + Style.BRIGHT + \"=\"*30 + \" 风控与效率指标 \" + \"=\"*30 + Style.RESET_ALL)\n",
    "    risk_headers = [\"指标名称\", \"计算结果\", \"要求\", \"状态\"]\n",
    "    mdd_status = \"✅ 达标\" if max_drawdown < 0.2 else Fore.RED + \"❌ 未达标\" + Style.RESET_ALL\n",
    "    trade_freq_status = \"✅ 达标\" if weekly_trades > 5 else Fore.RED + \"❌ 未达标\" + Style.RESET_ALL\n",
    "    \n",
    "    risk_table = [\n",
    "        [\"最大回撤 (MDD)\", f\"{max_drawdown:.3%}\", \"< 0.2\", mdd_status],\n",
    "        [\"每周开仓频率\", f\"{weekly_trades:.4f}\", \"> 5\", trade_freq_status]\n",
    "    ]\n",
    "    print(tabulate(risk_table, headers=risk_headers, tablefmt=\"grid\", stralign=\"center\", numalign=\"center\"))\n",
    "    \n",
    "    print(\"\\n\" + Fore.YELLOW + Style.BRIGHT + \"综合指标评估\" + Style.RESET_ALL)\n",
    "    risk_summary_table = [\n",
    "        [\"综合风控指标\", \"✅ 达标\" if max_drawdown < 0.2 else Fore.RED + \"❌ 未达标\" + Style.RESET_ALL],\n",
    "        [\"综合效率指标\", \"✅ 达标\" if weekly_trades > 5 else Fore.RED + \"❌ 未达标\" + Style.RESET_ALL]\n",
    "    ]\n",
    "    print(tabulate(risk_summary_table, headers=[\"指标\", \"状态\"], tablefmt=\"grid\", stralign=\"center\", numalign=\"center\"))\n",
    "    \n",
    "    print(\"\\n\" + Fore.GREEN + Style.BRIGHT + \"=\"*30 + \" 详细指标 \" + \"=\"*30 + Style.RESET_ALL)\n",
    "    detailed_headers = [\"指标名称\", \"值\"]\n",
    "    detailed_table = [\n",
    "        [Fore.YELLOW + \"与'signal × return'基准的相关性\" + Style.RESET_ALL, f\"{correlation:.3%}\"],\n",
    "        [\"总收益率 (Total Return)\", f\"{total_return:.3%}\"],\n",
    "        [\"年化收益率 (Annualized Return)\", f\"{annualized_return:.3%}\"],\n",
    "        [\"年化波动率 (Annualized Vol)\", f\"{annualized_volatility:.3%}\"],\n",
    "        [\"总盈亏 (Total PnL)\", f\"${final_equity - initial_capital:,.2f}\"],\n",
    "        [\"总交易笔数 (Total Trades)\", f\"{total_trades}\"],\n",
    "        [\"盈利交易笔数 (Winning Trades)\", f\"{len(winning_trades)}\"],\n",
    "        [\"亏损交易笔数 (Losing Trades)\", f\"{len(losing_trades)}\"],\n",
    "        [\"胜率 (Win Rate)\", f\"{win_rate:.3%}\"],\n",
    "        [\"盈亏比 (Profit Factor)\", f\"{profit_factor:.3f}\"],\n",
    "        [\"平均盈利 (Average Win)\", f\"{avg_win:.3%}\"],\n",
    "        [\"平均亏损 (Average Loss)\", f\"{avg_loss:.3%}\"],\n",
    "        [\"年化换手率 (Annualized Turnover)\", f\"{annualized_turnover:.3%}\"],\n",
    "        [\"最大回撤起始日期\", f\"{mdd_start}\"],\n",
    "        [\"最大回撤结束日期\", f\"{mdd_end}\"],\n",
    "        [\"信息系数 (IC)\", f\"{ic:.3f}\"]\n",
    "    ]\n",
    "    print(tabulate(detailed_table, headers=detailed_headers, tablefmt=\"grid\", stralign=\"center\", numalign=\"center\"))\n",
    "    \n",
    "    print(\"\\n\" + Fore.MAGENTA + Style.BRIGHT + \"=\"*30 + \" 逐年收益率 \" + \"=\"*30 + Style.RESET_ALL)\n",
    "    yearly_table = []\n",
    "    for year, return_val in yearly_returns:\n",
    "        yearly_table.append([year, f\"{return_val:.3%}\"])\n",
    "    print(tabulate(yearly_table, headers=[\"年份\", \"收益率\"], tablefmt=\"grid\", stralign=\"center\", numalign=\"center\"))\n",
    "\n",
    "    # --- 7. 绘制权益曲线图 ---\n",
    "    fig, ax = plt.subplots(figsize=(15, 10))\n",
    "    \n",
    "    # 仅在有交易发生时绘制垂直线条\n",
    "    trade_dates = trade_df['exit_time'].unique()\n",
    "    trade_dates = sorted(trade_dates)\n",
    "    \n",
    "    # 绘制阶梯状的策略权益曲线\n",
    "    prev_equity = initial_capital\n",
    "    for date in trade_dates:\n",
    "        equity = df.loc[date, 'equity_curve']\n",
    "        # 绘制水平线（前一点到当前点）\n",
    "        prev_date = df.index[df.index.get_loc(date) - 1] if date != df.index[0] else date\n",
    "        ax.hlines(y=prev_equity, xmin=prev_date, xmax=date, color='royalblue', linewidth=2)\n",
    "        # 绘制垂直线（当前点）\n",
    "        ax.vlines(x=date, ymin=prev_equity, ymax=equity, color='royalblue', linewidth=2)\n",
    "        prev_equity = equity\n",
    "    \n",
    "    # 绘制最后一段\n",
    "    last_trade_date = trade_dates[-1] if trade_dates else df.index[0]\n",
    "    ax.hlines(y=prev_equity, xmin=last_trade_date, xmax=df.index[-1], color='royalblue', linewidth=2)\n",
    "    \n",
    "    # 绘制策略权益曲线 (使用阶梯图)\n",
    "    # 阶梯图(step plot)能完美展示已实现盈亏曲线的特性：权益只在交易平仓时发生阶跃式变化。\n",
    "    ax.step(df.index, df['equity_curve'], where='post', label='Strategy Equity', color='royalblue', linewidth=2)\n",
    "\n",
    "    # 绘制理论基准曲线\n",
    "    theoretical_curve = initial_capital * (1 + theoretical_benchmark)\n",
    "    ax.plot(df.index, theoretical_curve, label='Theoretical Benchmark (signal×return)', color='purple', linestyle='--', alpha=0.7)\n",
    "\n",
    "    # 绘制买入并持有基准曲线\n",
    "    ax.plot(df.index, buy_hold_curve, label='Buy & Hold BTC', color='darkorange', linestyle=':', alpha=0.7)\n",
    "\n",
    "    # 设置图表标题和标签\n",
    "    ax.set_title('Strategy Equity Curve vs. Benchmarks (Realized PnL Only)', fontsize=16)\n",
    "    ax.set_xlabel('Date', fontsize=12)\n",
    "    ax.set_ylabel('Net Asset Value', fontsize=12)\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    logging.info(\"✅ 策略评估报告生成完毕。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa116caf",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. 主程序执行 (更新)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44e9a745",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-30 23:52:27,439 - INFO - 📂 从 /public/data/factor_data/BTCUSDT_15m_2020_2025_factor_data.pkl 加载因子数据...\n",
      "/tmp/ipykernel_349609/126136614.py:20: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  factor_data = pickle.load(f)\n",
      "2025-07-30 23:52:27,516 - INFO - ✅ 数据加载成功 - 形状: (128448, 141)\n",
      "2025-07-30 23:52:27,517 - INFO - 📅 时间范围: 2021-10-01 00:00:00 至 2025-05-30 23:45:00\n",
      "2025-07-30 23:52:27,517 - INFO - 📈 特征数量: 91\n",
      "2025-07-30 23:52:27,518 - INFO - 📊 准备滚动训练数据...\n",
      "2025-07-30 23:52:27,518 - INFO - ✅ 使用 91 个因子特征\n",
      "2025-07-30 23:52:29,143 - INFO - ✅ 数据准备完成 - 样本数: 128388, 时间步长: 60, 特征数: 91\n",
      "2025-07-30 23:52:29,164 - INFO - 🚀 开始滚动训练 (n_splits=5)...\n",
      "2025-07-30 23:52:29,165 - INFO - \n",
      "🔁 处理折叠 1/5\n",
      "2025-07-30 23:52:29,166 - INFO -   训练集: 2021-10-01 15:00:00 到 2022-05-12 12:15:00\n",
      "2025-07-30 23:52:29,166 - INFO -   测试集: 2022-05-12 12:30:00 到 2022-12-21 09:45:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 608ms/step - accuracy: 0.5225 - loss: 1.0673 - val_accuracy: 0.5870 - val_loss: 0.9689 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 587ms/step - accuracy: 0.5210 - loss: 1.0248 - val_accuracy: 0.5870 - val_loss: 0.9726 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 582ms/step - accuracy: 0.5199 - loss: 1.0252 - val_accuracy: 0.5870 - val_loss: 0.9720 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 576ms/step - accuracy: 0.5207 - loss: 1.0248 - val_accuracy: 0.5870 - val_loss: 0.9728 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 588ms/step - accuracy: 0.5194 - loss: 1.0256 - val_accuracy: 0.5870 - val_loss: 0.9726 - learning_rate: 2.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 589ms/step - accuracy: 0.5198 - loss: 1.0254 - val_accuracy: 0.5870 - val_loss: 0.9725 - learning_rate: 2.0000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-30 23:55:28,253 - INFO -   测试准确率: 0.5870, 测试损失: 0.9689\n",
      "2025-07-30 23:55:29,351 - INFO - \n",
      "🔁 处理折叠 2/5\n",
      "2025-07-30 23:55:29,353 - INFO -   训练集: 2021-10-01 15:00:00 到 2022-12-21 09:45:00\n",
      "2025-07-30 23:55:29,354 - INFO -   测试集: 2022-12-21 10:00:00 到 2023-08-01 07:15:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 488ms/step - accuracy: 0.5544 - loss: 1.0400 - val_accuracy: 0.7411 - val_loss: 0.8329 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 476ms/step - accuracy: 0.5562 - loss: 0.9947 - val_accuracy: 0.7411 - val_loss: 0.8282 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 476ms/step - accuracy: 0.5512 - loss: 0.9992 - val_accuracy: 0.7411 - val_loss: 0.8317 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 475ms/step - accuracy: 0.5526 - loss: 0.9983 - val_accuracy: 0.7411 - val_loss: 0.8204 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 452ms/step - accuracy: 0.5523 - loss: 0.9984 - val_accuracy: 0.7411 - val_loss: 0.8271 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 465ms/step - accuracy: 0.5560 - loss: 0.9946 - val_accuracy: 0.7411 - val_loss: 0.8252 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 474ms/step - accuracy: 0.5506 - loss: 0.9999 - val_accuracy: 0.7411 - val_loss: 0.8246 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 474ms/step - accuracy: 0.5529 - loss: 0.9976 - val_accuracy: 0.7411 - val_loss: 0.8271 - learning_rate: 2.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 479ms/step - accuracy: 0.5528 - loss: 0.9974 - val_accuracy: 0.7411 - val_loss: 0.8284 - learning_rate: 2.0000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-31 00:02:02,006 - INFO -   测试准确率: 0.7411, 测试损失: 0.8204\n",
      "2025-07-31 00:02:03,162 - INFO - \n",
      "🔁 处理折叠 3/5\n",
      "2025-07-31 00:02:03,163 - INFO -   训练集: 2021-10-01 15:00:00 到 2023-08-01 07:15:00\n",
      "2025-07-31 00:02:03,164 - INFO -   测试集: 2023-08-01 07:30:00 到 2024-03-11 04:45:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 446ms/step - accuracy: 0.6168 - loss: 0.9977 - val_accuracy: 0.7166 - val_loss: 0.8156 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 438ms/step - accuracy: 0.6195 - loss: 0.9291 - val_accuracy: 0.7166 - val_loss: 0.8202 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 440ms/step - accuracy: 0.6175 - loss: 0.9311 - val_accuracy: 0.7166 - val_loss: 0.8145 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 436ms/step - accuracy: 0.6181 - loss: 0.9303 - val_accuracy: 0.7166 - val_loss: 0.8209 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 439ms/step - accuracy: 0.6154 - loss: 0.9335 - val_accuracy: 0.7166 - val_loss: 0.8153 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 442ms/step - accuracy: 0.6175 - loss: 0.9311 - val_accuracy: 0.7166 - val_loss: 0.8177 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 439ms/step - accuracy: 0.6198 - loss: 0.9283 - val_accuracy: 0.7166 - val_loss: 0.8172 - learning_rate: 2.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 440ms/step - accuracy: 0.6171 - loss: 0.9320 - val_accuracy: 0.7166 - val_loss: 0.8144 - learning_rate: 2.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 441ms/step - accuracy: 0.6157 - loss: 0.9331 - val_accuracy: 0.7166 - val_loss: 0.8160 - learning_rate: 2.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 438ms/step - accuracy: 0.6187 - loss: 0.9295 - val_accuracy: 0.7166 - val_loss: 0.8170 - learning_rate: 2.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 441ms/step - accuracy: 0.6148 - loss: 0.9342 - val_accuracy: 0.7166 - val_loss: 0.8127 - learning_rate: 2.0000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 441ms/step - accuracy: 0.6159 - loss: 0.9327 - val_accuracy: 0.7166 - val_loss: 0.8145 - learning_rate: 2.0000e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 439ms/step - accuracy: 0.6190 - loss: 0.9293 - val_accuracy: 0.7166 - val_loss: 0.8166 - learning_rate: 2.0000e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 442ms/step - accuracy: 0.6133 - loss: 0.9362 - val_accuracy: 0.7166 - val_loss: 0.8145 - learning_rate: 2.0000e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 442ms/step - accuracy: 0.6159 - loss: 0.9328 - val_accuracy: 0.7166 - val_loss: 0.8151 - learning_rate: 4.0000e-05\n",
      "Epoch 16/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 441ms/step - accuracy: 0.6189 - loss: 0.9292 - val_accuracy: 0.7166 - val_loss: 0.8153 - learning_rate: 4.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-31 00:17:28,500 - INFO -   测试准确率: 0.7166, 测试损失: 0.8126\n",
      "2025-07-31 00:17:29,843 - INFO - \n",
      "🔁 处理折叠 4/5\n",
      "2025-07-31 00:17:29,844 - INFO -   训练集: 2021-10-01 15:00:00 到 2024-03-11 04:45:00\n",
      "2025-07-31 00:17:29,845 - INFO -   测试集: 2024-03-11 05:00:00 到 2024-10-20 02:15:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 406ms/step - accuracy: 0.6398 - loss: 0.9668 - val_accuracy: 0.6177 - val_loss: 0.9315 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 417ms/step - accuracy: 0.6412 - loss: 0.9023 - val_accuracy: 0.6177 - val_loss: 0.9316 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 418ms/step - accuracy: 0.6405 - loss: 0.9035 - val_accuracy: 0.6177 - val_loss: 0.9317 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 420ms/step - accuracy: 0.6410 - loss: 0.9023 - val_accuracy: 0.6177 - val_loss: 0.9304 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 418ms/step - accuracy: 0.6408 - loss: 0.9029 - val_accuracy: 0.6177 - val_loss: 0.9327 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 420ms/step - accuracy: 0.6414 - loss: 0.9022 - val_accuracy: 0.6177 - val_loss: 0.9307 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 418ms/step - accuracy: 0.6439 - loss: 0.8991 - val_accuracy: 0.6177 - val_loss: 0.9303 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 416ms/step - accuracy: 0.6393 - loss: 0.9048 - val_accuracy: 0.6177 - val_loss: 0.9315 - learning_rate: 2.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 418ms/step - accuracy: 0.6424 - loss: 0.9004 - val_accuracy: 0.6177 - val_loss: 0.9311 - learning_rate: 2.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 422ms/step - accuracy: 0.6432 - loss: 0.8994 - val_accuracy: 0.6177 - val_loss: 0.9309 - learning_rate: 2.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 417ms/step - accuracy: 0.6430 - loss: 0.9001 - val_accuracy: 0.6177 - val_loss: 0.9312 - learning_rate: 4.0000e-05\n",
      "Epoch 12/30\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 417ms/step - accuracy: 0.6432 - loss: 0.8994 - val_accuracy: 0.6177 - val_loss: 0.9311 - learning_rate: 4.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-31 00:32:14,262 - INFO -   测试准确率: 0.6177, 测试损失: 0.9303\n",
      "2025-07-31 00:32:15,503 - INFO - \n",
      "🔁 处理折叠 5/5\n",
      "2025-07-31 00:32:15,505 - INFO -   训练集: 2021-10-01 15:00:00 到 2024-10-20 02:15:00\n",
      "2025-07-31 00:32:15,506 - INFO -   测试集: 2024-10-20 02:30:00 到 2025-05-30 23:45:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 421ms/step - accuracy: 0.6358 - loss: 0.9624 - val_accuracy: 0.6094 - val_loss: 0.9416 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 410ms/step - accuracy: 0.6350 - loss: 0.9101 - val_accuracy: 0.6094 - val_loss: 0.9445 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 410ms/step - accuracy: 0.6367 - loss: 0.9080 - val_accuracy: 0.6094 - val_loss: 0.9413 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 412ms/step - accuracy: 0.6367 - loss: 0.9079 - val_accuracy: 0.6094 - val_loss: 0.9405 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 408ms/step - accuracy: 0.6359 - loss: 0.9089 - val_accuracy: 0.6094 - val_loss: 0.9419 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 408ms/step - accuracy: 0.6387 - loss: 0.9055 - val_accuracy: 0.6094 - val_loss: 0.9409 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 407ms/step - accuracy: 0.6355 - loss: 0.9094 - val_accuracy: 0.6094 - val_loss: 0.9413 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 396ms/step - accuracy: 0.6390 - loss: 0.9052 - val_accuracy: 0.6094 - val_loss: 0.9406 - learning_rate: 2.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 409ms/step - accuracy: 0.6345 - loss: 0.9107 - val_accuracy: 0.6094 - val_loss: 0.9409 - learning_rate: 2.0000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-31 00:45:50,643 - INFO -   测试准确率: 0.6094, 测试损失: 0.9405\n",
      "2025-07-31 00:45:52,009 - INFO - \n",
      "✅ 滚动训练完成 - 平均准确率: 0.6544, 平均损失: 0.8946\n",
      "2025-07-31 00:45:52,023 - INFO - 📡 信号生成完成 - 做多比例: 0.00%, 做空比例: 0.00%\n",
      "2025-07-31 00:45:52,060 - INFO - 💾 回测数据已保存至 ./_test_backtest_intern.pkl\n",
      "2025-07-31 00:45:52,060 - INFO - 🔍 从 ./_test_backtest_intern.pkl 加载回测数据...\n",
      "2025-07-31 00:45:52,062 - INFO - 🚀 开始执行优化版回测 (基于已实现盈亏)...\n",
      "2025-07-31 00:45:52,138 - INFO - ✅ 优化版回测完成。\n",
      "2025-07-31 00:45:52,140 - INFO - 📊 开始进行全面的策略性能评估...\n",
      "/tmp/ipykernel_349609/2128235333.py:38: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_returns = df['equity_curve'].resample('M').last().pct_change().dropna()\n",
      "/tmp/ipykernel_349609/2128235333.py:42: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  sharpe_ratio = (monthly_returns.mean() / monthly_returns.std()) * np.sqrt(12) if len(monthly_returns) > 1 else 0\n",
      "/home/wj/miniconda3/envs/tensor_flow/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2999: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/home/wj/miniconda3/envs/tensor_flow/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:3000: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "/home/wj/miniconda3/envs/tensor_flow/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2999: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "2025-07-31 00:45:52,174 - ERROR - ❌ 回测过程中发生错误: cannot access local variable 'winning_trades' where it is not associated with a value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "\u001b[36m\u001b[1m                              策略性能评估报告                              \u001b[0m\n",
      "================================================================================\n",
      "\n",
      "\u001b[34m\u001b[1m============================== 收益指标 ==============================\u001b[0m\n",
      "+-----------------------+------------+--------+-----------+\n",
      "|       指标名称        |  计算结果  |  要求  |   状态    |\n",
      "+=======================+============+========+===========+\n",
      "|   夏普比率 (Sharpe)   |    nan     | > 2.0  | \u001b[31m❌ 未达标\u001b[0m |\n",
      "+-----------------------+------------+--------+-----------+\n",
      "|   卡玛比率 (Calmar)   |     0      | > 5.0  | \u001b[31m❌ 未达标\u001b[0m |\n",
      "+-----------------------+------------+--------+-----------+\n",
      "| 期望收益 (Expectancy) |     0      | > 0.25 | \u001b[31m❌ 未达标\u001b[0m |\n",
      "+-----------------------+------------+--------+-----------+\n",
      "\n",
      "\u001b[34m\u001b[1m策略方案评估\u001b[0m\n",
      "+----------------------+-----------+\n",
      "|       策略方案       |   状态    |\n",
      "+======================+===========+\n",
      "| 方案一 (夏普 & 卡玛) | \u001b[31m❌ 未达标\u001b[0m |\n",
      "+----------------------+-----------+\n",
      "|  方案二 (期望收益)   | \u001b[31m❌ 未达标\u001b[0m |\n",
      "+----------------------+-----------+\n",
      "|     综合收益指标     | \u001b[31m❌ 未达标\u001b[0m |\n",
      "+----------------------+-----------+\n",
      "\n",
      "\u001b[34m\u001b[1m持仓统计\u001b[0m\n",
      "+--------------+-------+\n",
      "|     指标     |  值   |\n",
      "+==============+=======+\n",
      "| 多头持仓占比 | 0.00% |\n",
      "+--------------+-------+\n",
      "| 空头持仓占比 | 0.00% |\n",
      "+--------------+-------+\n",
      "\n",
      "\u001b[33m\u001b[1m============================== 风控与效率指标 ==============================\u001b[0m\n",
      "+----------------+------------+--------+-----------+\n",
      "|    指标名称    |  计算结果  |  要求  |   状态    |\n",
      "+================+============+========+===========+\n",
      "| 最大回撤 (MDD) |   0.000%   | < 0.2  |  ✅ 达标  |\n",
      "+----------------+------------+--------+-----------+\n",
      "|  每周开仓频率  |   0.0000   |  > 5   | \u001b[31m❌ 未达标\u001b[0m |\n",
      "+----------------+------------+--------+-----------+\n",
      "\n",
      "\u001b[33m\u001b[1m综合指标评估\u001b[0m\n",
      "+--------------+-----------+\n",
      "|     指标     |   状态    |\n",
      "+==============+===========+\n",
      "| 综合风控指标 |  ✅ 达标  |\n",
      "+--------------+-----------+\n",
      "| 综合效率指标 | \u001b[31m❌ 未达标\u001b[0m |\n",
      "+--------------+-----------+\n",
      "\n",
      "\u001b[32m\u001b[1m============================== 详细指标 ==============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # --- 1. 参数配置 ---\n",
    "    FACTOR_FILE = '/public/data/factor_data/BTCUSDT_15m_2020_2025_factor_data.pkl'\n",
    "    OUTPUT_FILE = \"./_test_backtest_intern.pkl\"  # 修改为当前目录\n",
    "    \n",
    "    # 回测核心参数\n",
    "    COMMISSION_RATE = 0.0002     # 单边手续费 (e.g., 0.02%)\n",
    "    INITIAL_CAPITAL = 100000     # 初始模拟资金\n",
    "    HOLDING_PERIOD = 10          # 每份仓位的固定持有周期 (10个15分钟bar)\n",
    "    \n",
    "    # ConvLSTM模型参数\n",
    "    LOOKBACK_PERIOD = 60         # 回看时间步长 (60个15分钟bar)\n",
    "    N_SPLITS = 5                 # 时间序列交叉验证分割数\n",
    "\n",
    "    # --- 2. 加载因子数据 ---\n",
    "    logging.info(f\"📂 从 {FACTOR_FILE} 加载因子数据...\")\n",
    "    \n",
    "    try:\n",
    "        with open(FACTOR_FILE, 'rb') as f:\n",
    "            factor_data = pickle.load(f)\n",
    "        \n",
    "        # 确保索引是datetime类型\n",
    "        factor_data.index = pd.to_datetime(factor_data.index)\n",
    "        \n",
    "        # 提取收盘价\n",
    "        close_prices = factor_data['close'].copy()\n",
    "        \n",
    "        logging.info(f\"✅ 数据加载成功 - 形状: {factor_data.shape}\")\n",
    "        logging.info(f\"📅 时间范围: {factor_data.index[0]} 至 {factor_data.index[-1]}\")\n",
    "        logging.info(f\"📈 特征数量: {len([col for col in factor_data.columns if col.startswith('c_chu') or col.startswith('c_hide')])}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ 加载数据时发生错误: {e}\")\n",
    "        factor_data = None\n",
    "\n",
    "    # --- 3. 准备数据并执行滚动训练 ---\n",
    "    if factor_data is not None:\n",
    "        # 准备滚动训练数据\n",
    "        X, y, indices = prepare_rolling_data(factor_data, lookback=LOOKBACK_PERIOD)\n",
    "        \n",
    "        # 执行滚动训练并生成信号\n",
    "        signals = rolling_train_and_predict(X, y, indices, lookback=LOOKBACK_PERIOD, n_splits=N_SPLITS)\n",
    "        \n",
    "        # 创建完整的信号序列（与原始数据对齐）\n",
    "        # 注意：signals 现在是带有索引的 Pandas Series\n",
    "        full_signals = pd.Series(0, index=factor_data.index)\n",
    "        full_signals.loc[signals.index] = signals\n",
    "        \n",
    "        # 创建回测数据\n",
    "        backtest_data = pd.DataFrame({\n",
    "            'signal': full_signals,\n",
    "            'close': close_prices\n",
    "        }, index=factor_data.index)\n",
    "        \n",
    "        # 保存回测数据（到当前目录）\n",
    "        backtest_data.to_pickle(OUTPUT_FILE)\n",
    "        logging.info(f\"💾 回测数据已保存至 {OUTPUT_FILE}\")\n",
    "    else:\n",
    "        logging.warning(\"⚠️ 由于数据加载失败，跳过模型训练和信号生成步骤\")\n",
    "\n",
    "    # --- 4. 执行回测与评估 ---\n",
    "    if os.path.exists(OUTPUT_FILE):\n",
    "        logging.info(f\"🔍 从 {OUTPUT_FILE} 加载回测数据...\")\n",
    "        \n",
    "        try:\n",
    "            with open(OUTPUT_FILE, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "            \n",
    "            # 调用核心回测函数\n",
    "            backtest_results, trade_history = run_realized_pnl_backtest(\n",
    "                prices=data['close'],\n",
    "                signals=data['signal'],\n",
    "                initial_capital=INITIAL_CAPITAL,\n",
    "                commission_rate=COMMISSION_RATE,\n",
    "                holding_period=HOLDING_PERIOD\n",
    "            )\n",
    "\n",
    "            # 调用核心评估函数\n",
    "            evaluate_realized_pnl_performance(\n",
    "                backtest_results,\n",
    "                trade_history,\n",
    "                INITIAL_CAPITAL\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logging.error(f\"❌ 回测过程中发生错误: {e}\")\n",
    "    else:\n",
    "        logging.warning(\"⚠️ 回测数据文件不存在，跳过回测步骤\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor_flow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
